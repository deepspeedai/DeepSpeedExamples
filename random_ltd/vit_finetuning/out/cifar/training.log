Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.20326876640319824 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 05:16:20,118] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 05:16:20,121] [INFO] [comm.py:617:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[1669076180.993959] [BINGHYPC064:69690:0]          ib_md.c:348  UCX  ERROR ibv_reg_mr(address=0x7f8fdd800000, length=39845888, access=0xf) failed: Cannot allocate memory. Please set max locked memory (ulimit -l) to 'unlimited' (current: 65536 kbytes)
[1669076180.994037] [BINGHYPC064:69690:0]          mpool.c:192  UCX  ERROR Failed to allocate memory pool (name=rc_recv_desc) chunk: Input/output error
[1669076181.031204] [BINGHYPC064:69690:0]          ib_md.c:348  UCX  ERROR ibv_reg_mr(address=0x7f8fdd800000, length=39845888, access=0xf) failed: Cannot allocate memory. Please set max locked memory (ulimit -l) to 'unlimited' (current: 65536 kbytes)
[1669076181.031254] [BINGHYPC064:69690:0]          mpool.c:192  UCX  ERROR Failed to allocate memory pool (name=rc_recv_desc) chunk: Input/output error
[1669076181.049053] [BINGHYPC064:69690:0]        dc_mlx5.c:301  UCX  ERROR mlx5dv_create_qp(mlx5_3:1, DCI): failed: Cannot allocate memory
[2022-11-22 05:16:21,258] [INFO] [comm.py:669:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.228.58.174, master_port=29500
[2022-11-22 05:16:21,259] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.18459820747375488 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 05:17:22,370] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 05:17:22,374] [INFO] [comm.py:617:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[1669076243.321602] [BINGHYPC064:69927:0]          ib_md.c:348  UCX  ERROR ibv_reg_mr(address=0x7f2dd9800000, length=39845888, access=0xf) failed: Cannot allocate memory. Please set max locked memory (ulimit -l) to 'unlimited' (current: 65536 kbytes)
[1669076243.321673] [BINGHYPC064:69927:0]          mpool.c:192  UCX  ERROR Failed to allocate memory pool (name=rc_recv_desc) chunk: Input/output error
[1669076243.361832] [BINGHYPC064:69927:0]          ib_md.c:348  UCX  ERROR ibv_reg_mr(address=0x7f2dd9800000, length=39845888, access=0xf) failed: Cannot allocate memory. Please set max locked memory (ulimit -l) to 'unlimited' (current: 65536 kbytes)
[1669076243.361896] [BINGHYPC064:69927:0]          mpool.c:192  UCX  ERROR Failed to allocate memory pool (name=rc_recv_desc) chunk: Input/output error
[1669076243.382201] [BINGHYPC064:69927:0]        dc_mlx5.c:301  UCX  ERROR mlx5dv_create_qp(mlx5_3:1, DCI): failed: Cannot allocate memory
[2022-11-22 05:17:23,653] [INFO] [comm.py:669:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.228.58.174, master_port=29500
[2022-11-22 05:17:23,653] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.16631770133972168 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 05:18:31,076] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 05:18:31,079] [INFO] [comm.py:617:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[1669076311.878570] [BINGHYPC064:70170:0]          ib_md.c:348  UCX  ERROR ibv_reg_mr(address=0x7f41e4600000, length=39845888, access=0xf) failed: Cannot allocate memory. Please set max locked memory (ulimit -l) to 'unlimited' (current: 65536 kbytes)
[1669076311.878699] [BINGHYPC064:70170:0]          mpool.c:192  UCX  ERROR Failed to allocate memory pool (name=rc_recv_desc) chunk: Input/output error
[1669076311.913996] [BINGHYPC064:70170:0]          ib_md.c:348  UCX  ERROR ibv_reg_mr(address=0x7f41e4600000, length=39845888, access=0xf) failed: Cannot allocate memory. Please set max locked memory (ulimit -l) to 'unlimited' (current: 65536 kbytes)
[1669076311.914052] [BINGHYPC064:70170:0]          mpool.c:192  UCX  ERROR Failed to allocate memory pool (name=rc_recv_desc) chunk: Input/output error
[1669076311.932354] [BINGHYPC064:70170:0]        dc_mlx5.c:301  UCX  ERROR mlx5dv_create_qp(mlx5_3:1, DCI): failed: Cannot allocate memory
[2022-11-22 05:18:32,143] [INFO] [comm.py:669:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.228.58.174, master_port=29500
[2022-11-22 05:18:32,143] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 05:19:14,316] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 05:19:14,317] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswLCAxLCAyLCAzLCA0LCA1LCA2LCA3LCA4LCA5LCAxMCwgMTEsIDEyLCAxMywgMTQsIDE1XX0= --master_addr=10.228.58.174 --master_port=29500 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --data_outdir check/cifar/
[2022-11-22 05:19:15,885] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 05:19:15,885] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}
[2022-11-22 05:19:15,885] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=16, node_rank=0
[2022-11-22 05:19:15,885] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]})
[2022-11-22 05:19:15,885] [INFO] [launch.py:162:main] dist_world_size=16
[2022-11-22 05:19:15,885] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 1.8692100048065186 seconds
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
[2022-11-22 05:19:24,329] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 70639
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 1.9956367015838623 seconds
[2022-11-22 05:19:24,869] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 70640
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
[2022-11-22 05:19:25,248] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 70641
[2022-11-22 05:19:25,259] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 70642
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 1.090017318725586 seconds
[2022-11-22 05:19:25,676] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 70738
[2022-11-22 05:19:26,137] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 70834
[2022-11-22 05:19:26,436] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 70835
[2022-11-22 05:19:26,774] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 70887
[2022-11-22 05:19:26,952] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 70954
[2022-11-22 05:19:26,957] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 71028
[2022-11-22 05:19:26,957] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 71029
[2022-11-22 05:19:27,134] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 71095
[2022-11-22 05:19:27,272] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 71153
[2022-11-22 05:19:27,410] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 71415
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
[2022-11-22 05:19:27,547] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 71416
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
[2022-11-22 05:19:27,645] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 71417
Loading extension module random_ltd...
[2022-11-22 05:19:27,742] [ERROR] [launch.py:324:sigkill_handler] ['/opt/conda/bin/python', '-u', 'main_cifar.py', '--local_rank=15', '--deepspeed_config', 'config/ds_config.json', '--deepspeed', '--random_ltd', '--dataset', 'cifar10vit224', '--seed', '1234', '--printfreq', '400', '--arch', 'lvits16r224', '--optimizer', 'sgd', '--lr', '0.0001', '--seq_len', '197', '--scheduler', 'constant', '--epochs', '14', '--data_outdir', 'check/cifar/'] exits with return code = 2
[2022-11-22 05:33:16,707] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 05:33:16,708] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswLCAxLCAyLCAzLCA0LCA1LCA2LCA3LCA4LCA5LCAxMCwgMTEsIDEyLCAxMywgMTQsIDE1XX0= --master_addr=10.228.58.174 --master_port=29500 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --data_outdir check/cifar/
[2022-11-22 05:33:18,288] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 05:33:18,289] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}
[2022-11-22 05:33:18,289] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=16, node_rank=0
[2022-11-22 05:33:18,289] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]})
[2022-11-22 05:33:18,289] [INFO] [launch.py:162:main] dist_world_size=16
[2022-11-22 05:33:18,289] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 2.026155710220337 seconds
Files already downloaded and verified
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.8300094604492188 seconds
cifar10
Files already downloaded and verified
Files already downloaded and verified
cifar10
cifar10
=> creating model 'lvits16r224'
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 1.2984414100646973 seconds
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 1.4122552871704102 seconds
Loading extension module random_ltd...
Time to load random_ltd op: 1.3812103271484375 seconds
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
cifar10
cifar10
cifar10
Files already downloaded and verified
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 1.9391489028930664 seconds
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
cifar10
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
=> creating model 'lvits16r224'
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Files already downloaded and verifiedFiles already downloaded and verified

Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 1.9992985725402832 seconds
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Files already downloaded and verified
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
cifar10
cifar10
ninja: no work to do.
Files already downloaded and verified
Loading extension module random_ltd...
Loading extension module random_ltd...
Time to load random_ltd op: 2.230618953704834 seconds
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Time to load random_ltd op: 2.2203657627105713 seconds
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
=> creating model 'lvits16r224'
=> creating model 'lvits16r224'
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 2.296427011489868 seconds
Loading extension module random_ltd...
Time to load random_ltd op: 2.778456687927246 seconds
Loading extension module random_ltd...
Time to load random_ltd op: 2.2553114891052246 seconds
Loading extension module random_ltd...
Loading extension module random_ltd...
Time to load random_ltd op: 2.730457305908203 seconds
Loading extension module random_ltd...
Time to load random_ltd op: 2.5006015300750732 seconds
Loading extension module random_ltd...
Time to load random_ltd op: 2.535637378692627 seconds
Time to load random_ltd op: 2.611722946166992 seconds
Files already downloaded and verified
Files already downloaded and verified
cifar10
cifar10
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verifiedFiles already downloaded and verified

Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
cifar10
cifar10
cifar10
cifar10
cifar10
cifar10
cifar10
=> creating model 'lvits16r224'
Files already downloaded and verified
cifar10
cifar10
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
cifar10
Files already downloaded and verified
=> creating model 'lvits16r224'
Files already downloaded and verified
=> creating model 'lvits16r224'
Files already downloaded and verified
cifar10
cifar10
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
=> creating model 'lvits16r224'
cifar10
cifar10
cifar10
=> creating model 'lvits16r224'
=> creating model 'lvits16r224'
cifar10
=> creating model 'lvits16r224'
=> creating model 'lvits16r224'
=> creating model 'lvits16r224'
=> creating model 'lvits16r224'
[2022-11-22 05:38:51,392] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 05:38:51,392] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=29500 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --data_outdir check/cifar/
[2022-11-22 05:38:53,128] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 05:38:53,128] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 05:38:53,128] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 05:38:53,129] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 05:38:53,129] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 05:38:53,129] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.17612147331237793 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 05:39:12,508] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 05:39:12,511] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 05:39:14,174] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 76654
[2022-11-22 05:39:14,175] [ERROR] [launch.py:324:sigkill_handler] ['/opt/conda/bin/python', '-u', 'main_cifar.py', '--local_rank=0', '--deepspeed_config', 'config/ds_config.json', '--deepspeed', '--random_ltd', '--dataset', 'cifar10vit224', '--seed', '1234', '--printfreq', '400', '--arch', 'lvits16r224', '--optimizer', 'sgd', '--lr', '0.0001', '--seq_len', '197', '--scheduler', 'constant', '--epochs', '14', '--data_outdir', 'check/cifar/'] exits with return code = 1
[2022-11-22 05:40:00,974] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 05:40:00,974] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --data_outdir check/cifar/
[2022-11-22 05:40:02,581] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 05:40:02,581] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 05:40:02,581] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 05:40:02,581] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 05:40:02,581] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 05:40:02,581] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.18047380447387695 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 05:40:22,783] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 05:40:22,786] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 05:40:24,617] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 77112
[2022-11-22 05:40:24,618] [ERROR] [launch.py:324:sigkill_handler] ['/opt/conda/bin/python', '-u', 'main_cifar.py', '--local_rank=0', '--deepspeed_config', 'config/ds_config.json', '--deepspeed', '--random_ltd', '--dataset', 'cifar10vit224', '--seed', '1234', '--printfreq', '400', '--arch', 'lvits16r224', '--optimizer', 'sgd', '--lr', '0.0001', '--seq_len', '197', '--scheduler', 'constant', '--epochs', '14', '--data_outdir', 'check/cifar/'] exits with return code = 1
[2022-11-22 05:59:18,072] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 05:59:18,073] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --data_outdir check/cifar/
[2022-11-22 05:59:19,783] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 05:59:19,783] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 05:59:19,783] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 05:59:19,783] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 05:59:19,783] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 05:59:19,783] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.16895580291748047 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 05:59:42,204] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 05:59:42,206] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 05:59:42,797] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 05:59:42,797] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 05:59:42,797] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 05:59:42,811] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 05:59:42,811] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 05:59:42,811] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 05:59:42,812] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7f81ca08f310>
[2022-11-22 05:59:42,812] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 05:59:42,812] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 05:59:42,813] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 05:59:42,813] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 05:59:42,813] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 05:59:42,813] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f81ca08faf0>
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': 'attention_mask', 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 500, 'seq_per_step': 2}}, 'global_batch_size': 4, 'micro_batch_size': 2}}}
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 05:59:42,899] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 2
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f81ca08fbb0>
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   steps_per_print .............. 2
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   train_batch_size ............. 4
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  2
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 05:59:42,900] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 05:59:42,901] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 4, 
    "train_micro_batch_size_per_gpu": 2, 
    "steps_per_print": 2, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": "attention_mask", 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 500, 
                        "seq_per_step": 2
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.8887803554534912 seconds
[2022-11-22 05:59:46,822] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 78259
[2022-11-22 05:59:46,823] [ERROR] [launch.py:324:sigkill_handler] ['/opt/conda/bin/python', '-u', 'main_cifar.py', '--local_rank=0', '--deepspeed_config', 'config/ds_config.json', '--deepspeed', '--random_ltd', '--dataset', 'cifar10vit224', '--seed', '1234', '--printfreq', '400', '--arch', 'lvits16r224', '--optimizer', 'sgd', '--lr', '0.0001', '--seq_len', '197', '--scheduler', 'constant', '--epochs', '14', '--data_outdir', 'check/cifar/'] exits with return code = 1
[2022-11-22 06:01:16,012] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 06:01:16,012] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --data_outdir check/cifar/
[2022-11-22 06:01:17,654] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 06:01:17,654] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 06:01:17,654] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 06:01:17,654] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 06:01:17,654] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 06:01:17,654] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.1705951690673828 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 06:01:37,477] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 06:01:37,480] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 06:01:38,092] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 06:01:38,093] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 06:01:38,093] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 06:01:38,107] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 06:01:38,107] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 06:01:38,107] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 06:01:38,108] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7f32c09d1340>
[2022-11-22 06:01:38,108] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:01:38,108] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 06:01:38,109] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 06:01:38,109] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 06:01:38,109] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 06:01:38,109] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f32c09d1b20>
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': 'none', 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 500, 'seq_per_step': 2}}, 'global_batch_size': 4, 'micro_batch_size': 2}}}
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 06:01:38,204] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 2
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f32c09d1be0>
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   steps_per_print .............. 2
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   train_batch_size ............. 4
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  2
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 06:01:38,205] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 06:01:38,206] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 4, 
    "train_micro_batch_size_per_gpu": 2, 
    "steps_per_print": 2, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": "none", 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 500, 
                        "seq_per_step": 2
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.940906286239624 seconds
[2022-11-22 06:01:42,693] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 79267
[2022-11-22 06:01:42,693] [ERROR] [launch.py:324:sigkill_handler] ['/opt/conda/bin/python', '-u', 'main_cifar.py', '--local_rank=0', '--deepspeed_config', 'config/ds_config.json', '--deepspeed', '--random_ltd', '--dataset', 'cifar10vit224', '--seed', '1234', '--printfreq', '400', '--arch', 'lvits16r224', '--optimizer', 'sgd', '--lr', '0.0001', '--seq_len', '197', '--scheduler', 'constant', '--epochs', '14', '--data_outdir', 'check/cifar/'] exits with return code = 1
[2022-11-22 06:02:33,172] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 06:02:33,172] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --data_outdir check/cifar/
[2022-11-22 06:02:34,783] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 06:02:34,783] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 06:02:34,783] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 06:02:34,783] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 06:02:34,783] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 06:02:34,784] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.16823744773864746 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 06:02:55,435] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 06:02:55,438] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 06:02:56,820] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 80251
[2022-11-22 06:02:56,821] [ERROR] [launch.py:324:sigkill_handler] ['/opt/conda/bin/python', '-u', 'main_cifar.py', '--local_rank=0', '--deepspeed_config', 'config/ds_config.json', '--deepspeed', '--random_ltd', '--dataset', 'cifar10vit224', '--seed', '1234', '--printfreq', '400', '--arch', 'lvits16r224', '--optimizer', 'sgd', '--lr', '0.0001', '--seq_len', '197', '--scheduler', 'constant', '--epochs', '14', '--data_outdir', 'check/cifar/'] exits with return code = 1
[2022-11-22 06:03:27,360] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 06:03:27,360] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --data_outdir check/cifar/
[2022-11-22 06:03:29,020] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 06:03:29,020] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 06:03:29,020] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 06:03:29,020] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 06:03:29,020] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 06:03:29,020] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.19778919219970703 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 06:03:50,068] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 06:03:50,071] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 06:03:50,744] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 06:03:50,744] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 06:03:50,745] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 06:03:50,759] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 06:03:50,759] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 06:03:50,759] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 06:03:50,759] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7f31f7b57340>
[2022-11-22 06:03:50,759] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:03:50,760] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 06:03:50,761] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 06:03:50,761] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 06:03:50,761] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 06:03:50,761] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f31f7b57b20>
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 500, 'seq_per_step': 2}}, 'global_batch_size': 4, 'micro_batch_size': 2}}}
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 06:03:50,859] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 2
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f31f7b57be0>
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   steps_per_print .............. 2
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   train_batch_size ............. 4
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  2
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 06:03:50,860] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 06:03:50,861] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 4, 
    "train_micro_batch_size_per_gpu": 2, 
    "steps_per_print": 2, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 500, 
                        "seq_per_step": 2
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.5985910892486572 seconds
[2022-11-22 06:03:56,062] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 80705
[2022-11-22 06:03:56,062] [ERROR] [launch.py:324:sigkill_handler] ['/opt/conda/bin/python', '-u', 'main_cifar.py', '--local_rank=0', '--deepspeed_config', 'config/ds_config.json', '--deepspeed', '--random_ltd', '--dataset', 'cifar10vit224', '--seed', '1234', '--printfreq', '400', '--arch', 'lvits16r224', '--optimizer', 'sgd', '--lr', '0.0001', '--seq_len', '197', '--scheduler', 'constant', '--epochs', '14', '--data_outdir', 'check/cifar/'] exits with return code = 1
[2022-11-22 06:04:47,104] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 06:04:47,105] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 256 --data_outdir check/cifar/
[2022-11-22 06:04:55,962] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 06:04:55,963] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 64 --data_outdir check/cifar/
[2022-11-22 06:04:57,566] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 06:04:57,566] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 06:04:57,566] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 06:04:57,566] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 06:04:57,566] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 06:04:57,567] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.19693946838378906 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 06:05:17,781] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 06:05:17,784] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 06:05:18,459] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 06:05:18,460] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 06:05:18,460] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 06:05:18,473] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 06:05:18,473] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 06:05:18,474] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 06:05:18,474] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7f9683664340>
[2022-11-22 06:05:18,474] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:05:18,475] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 06:05:18,475] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 06:05:18,475] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 06:05:18,475] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 06:05:18,475] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 06:05:18,586] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 06:05:18,586] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 06:05:18,586] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 06:05:18,586] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 06:05:18,586] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 06:05:18,586] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9683664b20>
[2022-11-22 06:05:18,586] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 500, 'seq_per_step': 2}}, 'global_batch_size': 4, 'micro_batch_size': 2}}}
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 2
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f9683664be0>
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 06:05:18,587] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   steps_per_print .............. 2
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   train_batch_size ............. 4
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  2
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 06:05:18,588] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 06:05:18,588] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 4, 
    "train_micro_batch_size_per_gpu": 2, 
    "steps_per_print": 2, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 500, 
                        "seq_per_step": 2
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.9519879817962646 seconds
Epoch: [0][  0/782]	Time  4.126 ( 4.126)	Loss 2.9208e+00 (2.9208e+00)	Acc@1  10.94 ( 10.94)	Acc@5  39.06 ( 39.06)
[2022-11-22 06:05:32,618] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 82139
[2022-11-22 06:05:32,619] [ERROR] [launch.py:324:sigkill_handler] ['/opt/conda/bin/python', '-u', 'main_cifar.py', '--local_rank=0', '--deepspeed_config', 'config/ds_config.json', '--deepspeed', '--random_ltd', '--dataset', 'cifar10vit224', '--seed', '1234', '--printfreq', '400', '--arch', 'lvits16r224', '--optimizer', 'sgd', '--lr', '0.0001', '--seq_len', '197', '--scheduler', 'constant', '--epochs', '14', '--batchsize', '64', '--data_outdir', 'check/cifar/'] exits with return code = 1
[2022-11-22 06:05:40,378] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 06:05:40,379] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 32 --data_outdir check/cifar/
[2022-11-22 06:05:41,972] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 06:05:41,972] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 06:05:41,972] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 06:05:41,972] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 06:05:41,972] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 06:05:41,972] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.17146062850952148 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 06:06:03,215] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 06:06:03,220] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 06:06:04,058] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 06:06:04,058] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 06:06:04,058] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 06:06:04,072] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 06:06:04,072] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 06:06:04,072] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 06:06:04,072] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7eff64f22340>
[2022-11-22 06:06:04,072] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:06:04,073] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 06:06:04,073] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 06:06:04,074] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 06:06:04,074] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 06:06:04,074] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 06:06:04,177] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7eff64f22b20>
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 500, 'seq_per_step': 2}}, 'global_batch_size': 4, 'micro_batch_size': 2}}}
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 2
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 06:06:04,178] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7eff64f22be0>
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   steps_per_print .............. 2
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   train_batch_size ............. 4
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  2
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 06:06:04,179] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 06:06:04,179] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 4, 
    "train_micro_batch_size_per_gpu": 2, 
    "steps_per_print": 2, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 500, 
                        "seq_per_step": 2
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.739495038986206 seconds
Epoch: [0][   0/1563]	Time  2.207 ( 2.207)	Loss 3.3179e+00 (3.3179e+00)	Acc@1   0.00 (  0.00)	Acc@5  37.50 ( 37.50)
[2022-11-22 06:06:12,318] [INFO] [logging.py:68:log_dist] [Rank 0] step=2, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:06:12,345] [INFO] [timer.py:198:stop] 0/4, RunningAvgSamplesPerSec=1.2139964455405832, CurrSamplesPerSec=1.0422253302284195, MemAllocated=2.28GB, MaxMemAllocated=10.86GB
[2022-11-22 06:06:15,570] [INFO] [timer.py:198:stop] 0/6, RunningAvgSamplesPerSec=1.2294352632477785, CurrSamplesPerSec=1.0909509911354303, MemAllocated=2.28GB, MaxMemAllocated=10.86GB
[2022-11-22 06:06:18,835] [INFO] [logging.py:68:log_dist] [Rank 0] step=4, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:06:18,866] [INFO] [timer.py:198:stop] 0/8, RunningAvgSamplesPerSec=1.2258911124294347, CurrSamplesPerSec=1.063707235423905, MemAllocated=2.28GB, MaxMemAllocated=10.86GB
[2022-11-22 06:06:22,130] [INFO] [timer.py:198:stop] 0/10, RunningAvgSamplesPerSec=1.2270800433052673, CurrSamplesPerSec=1.0744261561027542, MemAllocated=2.28GB, MaxMemAllocated=10.86GB
[2022-11-22 06:06:25,341] [INFO] [logging.py:68:log_dist] [Rank 0] step=6, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:06:25,372] [INFO] [timer.py:198:stop] 0/12, RunningAvgSamplesPerSec=1.2294763020156425, CurrSamplesPerSec=1.0889267242296934, MemAllocated=2.28GB, MaxMemAllocated=10.86GB
[2022-11-22 06:06:28,619] [INFO] [timer.py:198:stop] 0/14, RunningAvgSamplesPerSec=1.230703865227448, CurrSamplesPerSec=1.0816500182260549, MemAllocated=2.28GB, MaxMemAllocated=10.86GB
[2022-11-22 06:06:31,869] [INFO] [logging.py:68:log_dist] [Rank 0] step=8, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:06:31,901] [INFO] [timer.py:198:stop] 0/16, RunningAvgSamplesPerSec=1.2297158835720883, CurrSamplesPerSec=1.0708388740462815, MemAllocated=2.28GB, MaxMemAllocated=10.91GB
[2022-11-22 06:06:35,170] [INFO] [timer.py:198:stop] 0/18, RunningAvgSamplesPerSec=1.2296513556906643, CurrSamplesPerSec=1.077654347251898, MemAllocated=2.28GB, MaxMemAllocated=10.91GB
[2022-11-22 06:06:38,429] [INFO] [logging.py:68:log_dist] [Rank 0] step=10, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:06:38,461] [INFO] [timer.py:198:stop] 0/20, RunningAvgSamplesPerSec=1.2286222757084089, CurrSamplesPerSec=1.0616852918518016, MemAllocated=2.28GB, MaxMemAllocated=10.91GB
[2022-11-22 06:06:41,786] [INFO] [timer.py:198:stop] 0/22, RunningAvgSamplesPerSec=1.226560221979027, CurrSamplesPerSec=1.0487713336608944, MemAllocated=2.28GB, MaxMemAllocated=10.91GB
[2022-11-22 06:06:45,053] [INFO] [logging.py:68:log_dist] [Rank 0] step=12, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:06:45,087] [INFO] [timer.py:198:stop] 0/24, RunningAvgSamplesPerSec=1.2256577097095975, CurrSamplesPerSec=1.058753533024582, MemAllocated=2.28GB, MaxMemAllocated=10.91GB
[2022-11-22 06:06:48,399] [INFO] [timer.py:198:stop] 0/26, RunningAvgSamplesPerSec=1.2245855988266554, CurrSamplesPerSec=1.0493475327734716, MemAllocated=2.28GB, MaxMemAllocated=10.91GB
[2022-11-22 06:06:51,701] [INFO] [logging.py:68:log_dist] [Rank 0] step=14, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:06:51,736] [INFO] [timer.py:198:stop] 0/28, RunningAvgSamplesPerSec=1.2229533080037454, CurrSamplesPerSec=1.033856468529314, MemAllocated=2.28GB, MaxMemAllocated=10.98GB
[2022-11-22 06:06:55,053] [INFO] [timer.py:198:stop] 0/30, RunningAvgSamplesPerSec=1.2221154182455853, CurrSamplesPerSec=1.048163940550871, MemAllocated=2.28GB, MaxMemAllocated=10.98GB
[2022-11-22 06:06:58,448] [INFO] [logging.py:68:log_dist] [Rank 0] step=16, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:06:58,483] [INFO] [timer.py:198:stop] 0/32, RunningAvgSamplesPerSec=1.2185744585723866, CurrSamplesPerSec=0.9910096141521226, MemAllocated=2.28GB, MaxMemAllocated=10.98GB
[2022-11-22 06:07:01,798] [INFO] [timer.py:198:stop] 0/34, RunningAvgSamplesPerSec=1.2181279862145729, CurrSamplesPerSec=1.053905203399138, MemAllocated=2.28GB, MaxMemAllocated=10.98GB
[2022-11-22 06:07:05,084] [INFO] [logging.py:68:log_dist] [Rank 0] step=18, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:07:05,119] [INFO] [timer.py:198:stop] 0/36, RunningAvgSamplesPerSec=1.2176517019879833, CurrSamplesPerSec=1.0422746679263841, MemAllocated=2.28GB, MaxMemAllocated=10.98GB
[2022-11-22 06:07:08,444] [INFO] [timer.py:198:stop] 0/38, RunningAvgSamplesPerSec=1.2171105534865394, CurrSamplesPerSec=1.0429369701694153, MemAllocated=2.28GB, MaxMemAllocated=10.98GB
[2022-11-22 06:07:11,772] [INFO] [logging.py:68:log_dist] [Rank 0] step=20, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:07:11,806] [INFO] [timer.py:198:stop] 0/40, RunningAvgSamplesPerSec=1.2159020855216014, CurrSamplesPerSec=1.0245248939184297, MemAllocated=2.28GB, MaxMemAllocated=11.0GB
[2022-11-22 06:07:15,114] [INFO] [timer.py:198:stop] 0/42, RunningAvgSamplesPerSec=1.2158360545651818, CurrSamplesPerSec=1.0579950655700034, MemAllocated=2.28GB, MaxMemAllocated=11.0GB
[2022-11-22 06:07:18,367] [INFO] [logging.py:68:log_dist] [Rank 0] step=22, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:07:18,400] [INFO] [timer.py:198:stop] 0/44, RunningAvgSamplesPerSec=1.2161416417757744, CurrSamplesPerSec=1.0738457379043655, MemAllocated=2.28GB, MaxMemAllocated=11.0GB
[2022-11-22 06:07:21,732] [INFO] [timer.py:198:stop] 0/46, RunningAvgSamplesPerSec=1.2156487037786512, CurrSamplesPerSec=1.047808872928907, MemAllocated=2.28GB, MaxMemAllocated=11.0GB
[2022-11-22 06:07:25,043] [INFO] [logging.py:68:log_dist] [Rank 0] step=24, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:07:25,077] [INFO] [timer.py:198:stop] 0/48, RunningAvgSamplesPerSec=1.2149937653776617, CurrSamplesPerSec=1.0425630177948682, MemAllocated=2.28GB, MaxMemAllocated=11.0GB
[2022-11-22 06:07:28,402] [INFO] [timer.py:198:stop] 0/50, RunningAvgSamplesPerSec=1.214711511359353, CurrSamplesPerSec=1.0435729806839784, MemAllocated=2.28GB, MaxMemAllocated=11.0GB
[2022-11-22 06:07:31,719] [INFO] [logging.py:68:log_dist] [Rank 0] step=26, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:07:31,753] [INFO] [timer.py:198:stop] 0/52, RunningAvgSamplesPerSec=1.214065365277136, CurrSamplesPerSec=1.0330600832126973, MemAllocated=2.28GB, MaxMemAllocated=11.04GB
[2022-11-22 06:07:35,090] [INFO] [timer.py:198:stop] 0/54, RunningAvgSamplesPerSec=1.2136614650114965, CurrSamplesPerSec=1.0368478254286422, MemAllocated=2.28GB, MaxMemAllocated=11.04GB
[2022-11-22 06:07:38,413] [INFO] [logging.py:68:log_dist] [Rank 0] step=28, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:07:38,447] [INFO] [timer.py:198:stop] 0/56, RunningAvgSamplesPerSec=1.2130535455452602, CurrSamplesPerSec=1.0384144654465646, MemAllocated=2.28GB, MaxMemAllocated=11.04GB
[2022-11-22 06:07:41,732] [INFO] [timer.py:198:stop] 0/58, RunningAvgSamplesPerSec=1.2133925417200861, CurrSamplesPerSec=1.0712161534021545, MemAllocated=2.28GB, MaxMemAllocated=11.04GB
[2022-11-22 06:07:45,040] [INFO] [logging.py:68:log_dist] [Rank 0] step=30, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:07:45,074] [INFO] [timer.py:198:stop] 0/60, RunningAvgSamplesPerSec=1.2130149949413753, CurrSamplesPerSec=1.04290701817595, MemAllocated=2.28GB, MaxMemAllocated=11.04GB
[2022-11-22 06:07:48,339] [INFO] [timer.py:198:stop] 0/62, RunningAvgSamplesPerSec=1.2135393340162783, CurrSamplesPerSec=1.0869650230730088, MemAllocated=2.28GB, MaxMemAllocated=11.04GB
[2022-11-22 06:07:51,585] [INFO] [logging.py:68:log_dist] [Rank 0] step=32, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:07:51,617] [INFO] [timer.py:198:stop] 0/64, RunningAvgSamplesPerSec=1.2139265337881582, CurrSamplesPerSec=1.0868605261770197, MemAllocated=2.28GB, MaxMemAllocated=11.08GB
[2022-11-22 06:07:54,958] [INFO] [timer.py:198:stop] 0/66, RunningAvgSamplesPerSec=1.2135541610718428, CurrSamplesPerSec=1.0570555676315947, MemAllocated=2.28GB, MaxMemAllocated=11.08GB
[2022-11-22 06:07:58,263] [INFO] [logging.py:68:log_dist] [Rank 0] step=34, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:07:58,297] [INFO] [timer.py:198:stop] 0/68, RunningAvgSamplesPerSec=1.213226550511842, CurrSamplesPerSec=1.0573877407374355, MemAllocated=2.28GB, MaxMemAllocated=11.08GB
[2022-11-22 06:08:01,694] [INFO] [timer.py:198:stop] 0/70, RunningAvgSamplesPerSec=1.2122926813933366, CurrSamplesPerSec=1.0204422788177108, MemAllocated=2.28GB, MaxMemAllocated=11.08GB
[2022-11-22 06:08:05,035] [INFO] [logging.py:68:log_dist] [Rank 0] step=36, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:08:05,069] [INFO] [timer.py:198:stop] 0/72, RunningAvgSamplesPerSec=1.2116448799890789, CurrSamplesPerSec=1.0330786579177438, MemAllocated=2.28GB, MaxMemAllocated=11.08GB
[2022-11-22 06:08:08,433] [INFO] [timer.py:198:stop] 0/74, RunningAvgSamplesPerSec=1.211147840555165, CurrSamplesPerSec=1.0380992429156841, MemAllocated=2.28GB, MaxMemAllocated=11.08GB
[2022-11-22 06:08:11,814] [INFO] [logging.py:68:log_dist] [Rank 0] step=38, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:08:11,849] [INFO] [timer.py:198:stop] 0/76, RunningAvgSamplesPerSec=1.21015965260054, CurrSamplesPerSec=1.0153108625546894, MemAllocated=2.28GB, MaxMemAllocated=11.13GB
[2022-11-22 06:08:15,250] [INFO] [timer.py:198:stop] 0/78, RunningAvgSamplesPerSec=1.2093839440407195, CurrSamplesPerSec=1.0244535758202515, MemAllocated=2.28GB, MaxMemAllocated=11.13GB
[2022-11-22 06:08:18,639] [INFO] [logging.py:68:log_dist] [Rank 0] step=40, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:08:18,672] [INFO] [timer.py:198:stop] 0/80, RunningAvgSamplesPerSec=1.2084587354414338, CurrSamplesPerSec=1.0122082434934918, MemAllocated=2.28GB, MaxMemAllocated=11.13GB
[2022-11-22 06:08:22,008] [INFO] [timer.py:198:stop] 0/82, RunningAvgSamplesPerSec=1.2083545923584231, CurrSamplesPerSec=1.0611056683703253, MemAllocated=2.28GB, MaxMemAllocated=11.13GB
[2022-11-22 06:08:25,337] [INFO] [logging.py:68:log_dist] [Rank 0] step=42, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:08:25,370] [INFO] [timer.py:198:stop] 0/84, RunningAvgSamplesPerSec=1.2080033465408366, CurrSamplesPerSec=1.048160928272404, MemAllocated=2.28GB, MaxMemAllocated=11.13GB
[2022-11-22 06:08:28,679] [INFO] [timer.py:198:stop] 0/86, RunningAvgSamplesPerSec=1.2081492252150199, CurrSamplesPerSec=1.0772650495078369, MemAllocated=2.28GB, MaxMemAllocated=11.13GB
[2022-11-22 06:08:32,026] [INFO] [logging.py:68:log_dist] [Rank 0] step=44, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:08:32,053] [INFO] [timer.py:198:stop] 0/88, RunningAvgSamplesPerSec=1.2077357535092368, CurrSamplesPerSec=1.042363642983275, MemAllocated=2.28GB, MaxMemAllocated=11.16GB
[2022-11-22 06:08:35,469] [INFO] [timer.py:198:stop] 0/90, RunningAvgSamplesPerSec=1.2069826744278127, CurrSamplesPerSec=1.0246352688635936, MemAllocated=2.28GB, MaxMemAllocated=11.16GB
[2022-11-22 06:08:38,848] [INFO] [logging.py:68:log_dist] [Rank 0] step=46, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:08:38,881] [INFO] [timer.py:198:stop] 0/92, RunningAvgSamplesPerSec=1.206294947964901, CurrSamplesPerSec=1.0238241552018592, MemAllocated=2.28GB, MaxMemAllocated=11.16GB
[2022-11-22 06:08:42,299] [INFO] [timer.py:198:stop] 0/94, RunningAvgSamplesPerSec=1.20559753022261, CurrSamplesPerSec=1.0161617116020345, MemAllocated=2.28GB, MaxMemAllocated=11.16GB
[2022-11-22 06:08:45,673] [INFO] [logging.py:68:log_dist] [Rank 0] step=48, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:08:45,707] [INFO] [timer.py:198:stop] 0/96, RunningAvgSamplesPerSec=1.2050060473097837, CurrSamplesPerSec=1.0201432061477536, MemAllocated=2.28GB, MaxMemAllocated=11.16GB
[2022-11-22 06:08:49,050] [INFO] [timer.py:198:stop] 0/98, RunningAvgSamplesPerSec=1.2049122307680407, CurrSamplesPerSec=1.053713114863237, MemAllocated=2.28GB, MaxMemAllocated=11.16GB
[2022-11-22 06:08:52,385] [INFO] [logging.py:68:log_dist] [Rank 0] step=50, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:08:52,416] [INFO] [timer.py:198:stop] 0/100, RunningAvgSamplesPerSec=1.2046683879334577, CurrSamplesPerSec=1.0521352420068038, MemAllocated=2.28GB, MaxMemAllocated=11.2GB
[2022-11-22 06:08:55,855] [INFO] [timer.py:198:stop] 0/102, RunningAvgSamplesPerSec=1.2039062093690474, CurrSamplesPerSec=1.0123889174378713, MemAllocated=2.28GB, MaxMemAllocated=11.2GB
[2022-11-22 06:08:59,237] [INFO] [logging.py:68:log_dist] [Rank 0] step=52, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:08:59,271] [INFO] [timer.py:198:stop] 0/104, RunningAvgSamplesPerSec=1.2033331099334132, CurrSamplesPerSec=1.0190277615132801, MemAllocated=2.28GB, MaxMemAllocated=11.2GB
[2022-11-22 06:09:02,684] [INFO] [timer.py:198:stop] 0/106, RunningAvgSamplesPerSec=1.2028051396769617, CurrSamplesPerSec=1.0246988516215831, MemAllocated=2.28GB, MaxMemAllocated=11.2GB
[2022-11-22 06:09:06,083] [INFO] [logging.py:68:log_dist] [Rank 0] step=54, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:09:06,118] [INFO] [timer.py:198:stop] 0/108, RunningAvgSamplesPerSec=1.2021567616348425, CurrSamplesPerSec=1.0103216848843803, MemAllocated=2.28GB, MaxMemAllocated=11.2GB
[2022-11-22 06:09:09,489] [INFO] [timer.py:198:stop] 0/110, RunningAvgSamplesPerSec=1.2019609287978776, CurrSamplesPerSec=1.047218673696555, MemAllocated=2.28GB, MaxMemAllocated=11.2GB
[2022-11-22 06:09:12,861] [INFO] [logging.py:68:log_dist] [Rank 0] step=56, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:09:12,895] [INFO] [timer.py:198:stop] 0/112, RunningAvgSamplesPerSec=1.2015090124001593, CurrSamplesPerSec=1.028608018269344, MemAllocated=2.28GB, MaxMemAllocated=11.25GB
[2022-11-22 06:09:16,347] [INFO] [timer.py:198:stop] 0/114, RunningAvgSamplesPerSec=1.2008095439423405, CurrSamplesPerSec=1.007007727996051, MemAllocated=2.28GB, MaxMemAllocated=11.25GB
[2022-11-22 06:09:19,701] [INFO] [logging.py:68:log_dist] [Rank 0] step=58, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:09:19,735] [INFO] [timer.py:198:stop] 0/116, RunningAvgSamplesPerSec=1.200522728697471, CurrSamplesPerSec=1.0443405463716215, MemAllocated=2.28GB, MaxMemAllocated=11.25GB
[2022-11-22 06:09:23,194] [INFO] [timer.py:198:stop] 0/118, RunningAvgSamplesPerSec=1.199817994530756, CurrSamplesPerSec=1.0047268324425633, MemAllocated=2.28GB, MaxMemAllocated=11.25GB
[2022-11-22 06:09:26,425] [INFO] [logging.py:68:log_dist] [Rank 0] step=60, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:09:26,459] [INFO] [timer.py:198:stop] 0/120, RunningAvgSamplesPerSec=1.200319275677578, CurrSamplesPerSec=1.1117306382313261, MemAllocated=2.28GB, MaxMemAllocated=11.25GB
[2022-11-22 06:09:29,903] [INFO] [timer.py:198:stop] 0/122, RunningAvgSamplesPerSec=1.1997472075004338, CurrSamplesPerSec=1.010945694771724, MemAllocated=2.28GB, MaxMemAllocated=11.25GB
[2022-11-22 06:09:33,240] [INFO] [logging.py:68:log_dist] [Rank 0] step=62, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:09:33,272] [INFO] [timer.py:198:stop] 0/124, RunningAvgSamplesPerSec=1.1996042489372463, CurrSamplesPerSec=1.0537317778726587, MemAllocated=2.28GB, MaxMemAllocated=11.29GB
[2022-11-22 06:09:36,710] [INFO] [timer.py:198:stop] 0/126, RunningAvgSamplesPerSec=1.1990856488764412, CurrSamplesPerSec=1.0234460498309386, MemAllocated=2.28GB, MaxMemAllocated=11.29GB
[2022-11-22 06:09:40,154] [INFO] [logging.py:68:log_dist] [Rank 0] step=64, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:09:40,186] [INFO] [timer.py:198:stop] 0/128, RunningAvgSamplesPerSec=1.198360340544461, CurrSamplesPerSec=1.0039399513169893, MemAllocated=2.28GB, MaxMemAllocated=11.29GB
[2022-11-22 06:09:43,613] [INFO] [timer.py:198:stop] 0/130, RunningAvgSamplesPerSec=1.1979109011129265, CurrSamplesPerSec=1.0225385886479625, MemAllocated=2.28GB, MaxMemAllocated=11.29GB
[2022-11-22 06:09:47,027] [INFO] [logging.py:68:log_dist] [Rank 0] step=66, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:09:47,060] [INFO] [timer.py:198:stop] 0/132, RunningAvgSamplesPerSec=1.1973880250461268, CurrSamplesPerSec=1.0165561336924065, MemAllocated=2.28GB, MaxMemAllocated=11.29GB
[2022-11-22 06:09:50,483] [INFO] [timer.py:198:stop] 0/134, RunningAvgSamplesPerSec=1.1970190926131323, CurrSamplesPerSec=1.0288417857083285, MemAllocated=2.28GB, MaxMemAllocated=11.29GB
[2022-11-22 06:09:53,944] [INFO] [logging.py:68:log_dist] [Rank 0] step=68, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:09:53,976] [INFO] [timer.py:198:stop] 0/136, RunningAvgSamplesPerSec=1.1962589451147125, CurrSamplesPerSec=0.9995785344509658, MemAllocated=2.28GB, MaxMemAllocated=11.33GB
[2022-11-22 06:09:57,486] [INFO] [timer.py:198:stop] 0/138, RunningAvgSamplesPerSec=1.1954619555928374, CurrSamplesPerSec=0.9906105476316523, MemAllocated=2.28GB, MaxMemAllocated=11.33GB
[2022-11-22 06:10:00,943] [INFO] [logging.py:68:log_dist] [Rank 0] step=70, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:10:00,978] [INFO] [timer.py:198:stop] 0/140, RunningAvgSamplesPerSec=1.1947753674781803, CurrSamplesPerSec=0.9996367820606564, MemAllocated=2.28GB, MaxMemAllocated=11.33GB
[2022-11-22 06:10:04,487] [INFO] [timer.py:198:stop] 0/142, RunningAvgSamplesPerSec=1.1940430675202351, CurrSamplesPerSec=0.9902120361535766, MemAllocated=2.28GB, MaxMemAllocated=11.33GB
[2022-11-22 06:10:07,924] [INFO] [logging.py:68:log_dist] [Rank 0] step=72, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:10:07,958] [INFO] [timer.py:198:stop] 0/144, RunningAvgSamplesPerSec=1.1934916193538128, CurrSamplesPerSec=1.0031108772123671, MemAllocated=2.28GB, MaxMemAllocated=11.33GB
[2022-11-22 06:10:11,423] [INFO] [timer.py:198:stop] 0/146, RunningAvgSamplesPerSec=1.192995797362709, CurrSamplesPerSec=1.0043808568922077, MemAllocated=2.28GB, MaxMemAllocated=11.33GB
[2022-11-22 06:10:14,888] [INFO] [logging.py:68:log_dist] [Rank 0] step=74, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:10:14,921] [INFO] [timer.py:198:stop] 0/148, RunningAvgSamplesPerSec=1.1923522762838903, CurrSamplesPerSec=0.9992628766678785, MemAllocated=2.28GB, MaxMemAllocated=11.38GB
[2022-11-22 06:10:18,408] [INFO] [timer.py:198:stop] 0/150, RunningAvgSamplesPerSec=1.1917807744467295, CurrSamplesPerSec=0.9993957358393458, MemAllocated=2.28GB, MaxMemAllocated=11.38GB
[2022-11-22 06:10:21,809] [INFO] [logging.py:68:log_dist] [Rank 0] step=76, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:10:21,843] [INFO] [timer.py:198:stop] 0/152, RunningAvgSamplesPerSec=1.1914726105640816, CurrSamplesPerSec=1.0292072206634322, MemAllocated=2.28GB, MaxMemAllocated=11.38GB
[2022-11-22 06:10:25,370] [INFO] [timer.py:198:stop] 0/154, RunningAvgSamplesPerSec=1.190754997235547, CurrSamplesPerSec=0.9837725647031615, MemAllocated=2.28GB, MaxMemAllocated=11.38GB
[2022-11-22 06:10:28,777] [INFO] [logging.py:68:log_dist] [Rank 0] step=78, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:10:28,810] [INFO] [timer.py:198:stop] 0/156, RunningAvgSamplesPerSec=1.1904480261618464, CurrSamplesPerSec=1.0326457610858883, MemAllocated=2.28GB, MaxMemAllocated=11.38GB
[2022-11-22 06:10:32,317] [INFO] [timer.py:198:stop] 0/158, RunningAvgSamplesPerSec=1.1898235605751613, CurrSamplesPerSec=0.9945711590289146, MemAllocated=2.28GB, MaxMemAllocated=11.38GB
[2022-11-22 06:10:35,726] [INFO] [logging.py:68:log_dist] [Rank 0] step=80, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:10:35,761] [INFO] [timer.py:198:stop] 0/160, RunningAvgSamplesPerSec=1.1895184137019734, CurrSamplesPerSec=1.0270363517337207, MemAllocated=2.28GB, MaxMemAllocated=11.42GB
[2022-11-22 06:10:39,282] [INFO] [timer.py:198:stop] 0/162, RunningAvgSamplesPerSec=1.1888733586515856, CurrSamplesPerSec=0.9874968510221523, MemAllocated=2.28GB, MaxMemAllocated=11.42GB
[2022-11-22 06:10:42,733] [INFO] [logging.py:68:log_dist] [Rank 0] step=82, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:10:42,766] [INFO] [timer.py:198:stop] 0/164, RunningAvgSamplesPerSec=1.188410499294238, CurrSamplesPerSec=1.0095210381668291, MemAllocated=2.28GB, MaxMemAllocated=11.42GB
[2022-11-22 06:10:46,155] [INFO] [timer.py:198:stop] 0/166, RunningAvgSamplesPerSec=1.1883581725577517, CurrSamplesPerSec=1.057716788486097, MemAllocated=2.28GB, MaxMemAllocated=11.42GB
[2022-11-22 06:10:49,728] [INFO] [logging.py:68:log_dist] [Rank 0] step=84, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:10:49,762] [INFO] [timer.py:198:stop] 0/168, RunningAvgSamplesPerSec=1.187394779696875, CurrSamplesPerSec=0.9468636680609732, MemAllocated=2.28GB, MaxMemAllocated=11.42GB
[2022-11-22 06:10:53,265] [INFO] [timer.py:198:stop] 0/170, RunningAvgSamplesPerSec=1.1868883027848682, CurrSamplesPerSec=0.9989766828256225, MemAllocated=2.28GB, MaxMemAllocated=11.42GB
[2022-11-22 06:10:56,760] [INFO] [logging.py:68:log_dist] [Rank 0] step=86, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:10:56,794] [INFO] [timer.py:198:stop] 0/172, RunningAvgSamplesPerSec=1.18628756788856, CurrSamplesPerSec=0.9915157555421809, MemAllocated=2.28GB, MaxMemAllocated=11.46GB
[2022-11-22 06:11:00,162] [INFO] [timer.py:198:stop] 0/174, RunningAvgSamplesPerSec=1.1863628878775216, CurrSamplesPerSec=1.0739909211582899, MemAllocated=2.28GB, MaxMemAllocated=11.46GB
[2022-11-22 06:11:03,644] [INFO] [logging.py:68:log_dist] [Rank 0] step=88, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:11:03,678] [INFO] [timer.py:198:stop] 0/176, RunningAvgSamplesPerSec=1.185837975840001, CurrSamplesPerSec=0.9980322771273363, MemAllocated=2.28GB, MaxMemAllocated=11.46GB
[2022-11-22 06:11:07,175] [INFO] [timer.py:198:stop] 0/178, RunningAvgSamplesPerSec=1.1853958658455181, CurrSamplesPerSec=0.9980144663537767, MemAllocated=2.28GB, MaxMemAllocated=11.46GB
[2022-11-22 06:11:10,625] [INFO] [logging.py:68:log_dist] [Rank 0] step=90, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:11:10,659] [INFO] [timer.py:198:stop] 0/180, RunningAvgSamplesPerSec=1.1850066531361658, CurrSamplesPerSec=1.0079264521746047, MemAllocated=2.28GB, MaxMemAllocated=11.46GB
[2022-11-22 06:11:14,165] [INFO] [timer.py:198:stop] 0/182, RunningAvgSamplesPerSec=1.1845506924402902, CurrSamplesPerSec=0.9982876347569801, MemAllocated=2.28GB, MaxMemAllocated=11.46GB
[2022-11-22 06:11:17,655] [INFO] [logging.py:68:log_dist] [Rank 0] step=92, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:11:17,689] [INFO] [timer.py:198:stop] 0/184, RunningAvgSamplesPerSec=1.184035640558267, CurrSamplesPerSec=0.9991839636165217, MemAllocated=2.28GB, MaxMemAllocated=11.5GB
[2022-11-22 06:11:21,226] [INFO] [timer.py:198:stop] 0/186, RunningAvgSamplesPerSec=1.1834821224896521, CurrSamplesPerSec=0.99259559370616, MemAllocated=2.28GB, MaxMemAllocated=11.5GB
[2022-11-22 06:11:24,745] [INFO] [logging.py:68:log_dist] [Rank 0] step=94, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:11:24,779] [INFO] [timer.py:198:stop] 0/188, RunningAvgSamplesPerSec=1.1828624806606691, CurrSamplesPerSec=0.9821847319513805, MemAllocated=2.28GB, MaxMemAllocated=11.5GB
[2022-11-22 06:11:28,200] [INFO] [timer.py:198:stop] 0/190, RunningAvgSamplesPerSec=1.1827561814050211, CurrSamplesPerSec=1.0520862858928817, MemAllocated=2.28GB, MaxMemAllocated=11.5GB
[2022-11-22 06:11:31,825] [INFO] [logging.py:68:log_dist] [Rank 0] step=96, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:11:31,859] [INFO] [timer.py:198:stop] 0/192, RunningAvgSamplesPerSec=1.181785274997129, CurrSamplesPerSec=0.9358744849883806, MemAllocated=2.28GB, MaxMemAllocated=11.5GB
[2022-11-22 06:11:35,427] [INFO] [timer.py:198:stop] 0/194, RunningAvgSamplesPerSec=1.1811694639250876, CurrSamplesPerSec=0.9788509766563063, MemAllocated=2.28GB, MaxMemAllocated=11.5GB
[2022-11-22 06:11:38,984] [INFO] [logging.py:68:log_dist] [Rank 0] step=98, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:11:39,020] [INFO] [timer.py:198:stop] 0/196, RunningAvgSamplesPerSec=1.1804776747171914, CurrSamplesPerSec=0.9703999717739114, MemAllocated=2.28GB, MaxMemAllocated=11.55GB
[2022-11-22 06:11:42,614] [INFO] [timer.py:198:stop] 0/198, RunningAvgSamplesPerSec=1.1797944124489639, CurrSamplesPerSec=0.9608503619536333, MemAllocated=2.28GB, MaxMemAllocated=11.55GB
[2022-11-22 06:11:46,143] [INFO] [logging.py:68:log_dist] [Rank 0] step=100, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:11:46,177] [INFO] [timer.py:198:stop] 0/200, RunningAvgSamplesPerSec=1.1792336509635122, CurrSamplesPerSec=0.9832318838473321, MemAllocated=2.28GB, MaxMemAllocated=11.55GB
[2022-11-22 06:11:49,707] [INFO] [timer.py:198:stop] 0/202, RunningAvgSamplesPerSec=1.1788015415687068, CurrSamplesPerSec=1.0047008399087882, MemAllocated=2.28GB, MaxMemAllocated=11.55GB
[2022-11-22 06:11:53,221] [INFO] [logging.py:68:log_dist] [Rank 0] step=102, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:11:53,256] [INFO] [timer.py:198:stop] 0/204, RunningAvgSamplesPerSec=1.1783151337247415, CurrSamplesPerSec=0.9907497748002847, MemAllocated=2.28GB, MaxMemAllocated=11.55GB
[2022-11-22 06:11:56,844] [INFO] [timer.py:198:stop] 0/206, RunningAvgSamplesPerSec=1.1776989804405025, CurrSamplesPerSec=0.9686185934271037, MemAllocated=2.28GB, MaxMemAllocated=11.55GB
[2022-11-22 06:12:00,409] [INFO] [logging.py:68:log_dist] [Rank 0] step=104, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:12:00,443] [INFO] [timer.py:198:stop] 0/208, RunningAvgSamplesPerSec=1.177070822005511, CurrSamplesPerSec=0.9713846740318876, MemAllocated=2.28GB, MaxMemAllocated=11.55GB
[2022-11-22 06:12:04,017] [INFO] [timer.py:198:stop] 0/210, RunningAvgSamplesPerSec=1.1765336987720216, CurrSamplesPerSec=0.9889785457433679, MemAllocated=2.28GB, MaxMemAllocated=11.59GB
[2022-11-22 06:12:07,432] [INFO] [logging.py:68:log_dist] [Rank 0] step=106, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:12:07,464] [INFO] [timer.py:198:stop] 0/212, RunningAvgSamplesPerSec=1.176422146748894, CurrSamplesPerSec=1.0534769062525, MemAllocated=2.28GB, MaxMemAllocated=11.6GB
[2022-11-22 06:12:11,030] [INFO] [timer.py:198:stop] 0/214, RunningAvgSamplesPerSec=1.1759289235332353, CurrSamplesPerSec=0.9878782882727986, MemAllocated=2.28GB, MaxMemAllocated=11.6GB
[2022-11-22 06:12:14,590] [INFO] [logging.py:68:log_dist] [Rank 0] step=108, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:12:14,624] [INFO] [timer.py:198:stop] 0/216, RunningAvgSamplesPerSec=1.1753516068123961, CurrSamplesPerSec=0.9728583156830952, MemAllocated=2.28GB, MaxMemAllocated=11.6GB
[2022-11-22 06:12:18,168] [INFO] [timer.py:198:stop] 0/218, RunningAvgSamplesPerSec=1.1749428488046152, CurrSamplesPerSec=1.002844054706271, MemAllocated=2.28GB, MaxMemAllocated=11.6GB
[2022-11-22 06:12:21,599] [INFO] [logging.py:68:log_dist] [Rank 0] step=110, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:12:21,631] [INFO] [timer.py:198:stop] 0/220, RunningAvgSamplesPerSec=1.174798778903855, CurrSamplesPerSec=1.0357684640005176, MemAllocated=2.28GB, MaxMemAllocated=11.6GB
[2022-11-22 06:12:25,235] [INFO] [timer.py:198:stop] 0/222, RunningAvgSamplesPerSec=1.1742215732627341, CurrSamplesPerSec=0.9749686685587374, MemAllocated=2.28GB, MaxMemAllocated=11.64GB
[2022-11-22 06:12:28,809] [INFO] [logging.py:68:log_dist] [Rank 0] step=112, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:12:28,841] [INFO] [timer.py:198:stop] 0/224, RunningAvgSamplesPerSec=1.1736461712357154, CurrSamplesPerSec=0.9745381444549337, MemAllocated=2.28GB, MaxMemAllocated=11.64GB
[2022-11-22 06:12:32,441] [INFO] [timer.py:198:stop] 0/226, RunningAvgSamplesPerSec=1.173098066598363, CurrSamplesPerSec=0.978179935914501, MemAllocated=2.28GB, MaxMemAllocated=11.64GB
[2022-11-22 06:12:35,978] [INFO] [logging.py:68:log_dist] [Rank 0] step=114, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:12:36,013] [INFO] [timer.py:198:stop] 0/228, RunningAvgSamplesPerSec=1.1726462754269895, CurrSamplesPerSec=0.9884674197626601, MemAllocated=2.28GB, MaxMemAllocated=11.64GB
[2022-11-22 06:12:39,650] [INFO] [timer.py:198:stop] 0/230, RunningAvgSamplesPerSec=1.172008712756948, CurrSamplesPerSec=0.9608997805371416, MemAllocated=2.28GB, MaxMemAllocated=11.64GB
[2022-11-22 06:12:43,101] [INFO] [logging.py:68:log_dist] [Rank 0] step=116, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:12:43,135] [INFO] [timer.py:198:stop] 0/232, RunningAvgSamplesPerSec=1.17183412408365, CurrSamplesPerSec=1.0369508733774249, MemAllocated=2.28GB, MaxMemAllocated=11.64GB
[2022-11-22 06:12:46,685] [INFO] [timer.py:198:stop] 0/234, RunningAvgSamplesPerSec=1.1714738820876527, CurrSamplesPerSec=1.0085396243305895, MemAllocated=2.28GB, MaxMemAllocated=11.68GB
[2022-11-22 06:12:50,257] [INFO] [logging.py:68:log_dist] [Rank 0] step=118, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:12:50,290] [INFO] [timer.py:198:stop] 0/236, RunningAvgSamplesPerSec=1.170958561403791, CurrSamplesPerSec=0.9769747423514874, MemAllocated=2.28GB, MaxMemAllocated=11.68GB
[2022-11-22 06:12:53,908] [INFO] [timer.py:198:stop] 0/238, RunningAvgSamplesPerSec=1.1704118316457726, CurrSamplesPerSec=0.9719022657885886, MemAllocated=2.28GB, MaxMemAllocated=11.68GB
[2022-11-22 06:12:57,497] [INFO] [logging.py:68:log_dist] [Rank 0] step=120, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:12:57,530] [INFO] [timer.py:198:stop] 0/240, RunningAvgSamplesPerSec=1.1698613722368485, CurrSamplesPerSec=0.9692751195705087, MemAllocated=2.28GB, MaxMemAllocated=11.68GB
[2022-11-22 06:13:01,147] [INFO] [timer.py:198:stop] 0/242, RunningAvgSamplesPerSec=1.1693367700904553, CurrSamplesPerSec=0.968013109003208, MemAllocated=2.28GB, MaxMemAllocated=11.68GB
[2022-11-22 06:13:04,732] [INFO] [logging.py:68:log_dist] [Rank 0] step=122, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:13:04,765] [INFO] [timer.py:198:stop] 0/244, RunningAvgSamplesPerSec=1.1688206315138296, CurrSamplesPerSec=0.9733214612501564, MemAllocated=2.28GB, MaxMemAllocated=11.68GB
[2022-11-22 06:13:08,401] [INFO] [timer.py:198:stop] 0/246, RunningAvgSamplesPerSec=1.1682575184464719, CurrSamplesPerSec=0.9637321533486806, MemAllocated=2.28GB, MaxMemAllocated=11.76GB
[2022-11-22 06:13:12,008] [INFO] [logging.py:68:log_dist] [Rank 0] step=124, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:13:12,042] [INFO] [timer.py:198:stop] 0/248, RunningAvgSamplesPerSec=1.1676971509973464, CurrSamplesPerSec=0.9607230417209668, MemAllocated=2.28GB, MaxMemAllocated=11.76GB
[2022-11-22 06:13:15,645] [INFO] [timer.py:198:stop] 0/250, RunningAvgSamplesPerSec=1.1672453394102897, CurrSamplesPerSec=0.9737879870807156, MemAllocated=2.28GB, MaxMemAllocated=11.76GB
[2022-11-22 06:13:19,296] [INFO] [logging.py:68:log_dist] [Rank 0] step=126, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:13:19,331] [INFO] [timer.py:198:stop] 0/252, RunningAvgSamplesPerSec=1.1665785171968732, CurrSamplesPerSec=0.9481767626948197, MemAllocated=2.28GB, MaxMemAllocated=11.76GB
[2022-11-22 06:13:22,911] [INFO] [timer.py:198:stop] 0/254, RunningAvgSamplesPerSec=1.1662103278310396, CurrSamplesPerSec=0.9898153634924309, MemAllocated=2.28GB, MaxMemAllocated=11.76GB
[2022-11-22 06:13:26,423] [INFO] [logging.py:68:log_dist] [Rank 0] step=128, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:13:26,457] [INFO] [timer.py:198:stop] 0/256, RunningAvgSamplesPerSec=1.1659354051540742, CurrSamplesPerSec=1.0091335121123335, MemAllocated=2.28GB, MaxMemAllocated=11.76GB
[2022-11-22 06:13:30,108] [INFO] [timer.py:198:stop] 0/258, RunningAvgSamplesPerSec=1.165380762988643, CurrSamplesPerSec=0.9635604585195349, MemAllocated=2.28GB, MaxMemAllocated=11.79GB
[2022-11-22 06:13:33,660] [INFO] [logging.py:68:log_dist] [Rank 0] step=130, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:13:33,692] [INFO] [timer.py:198:stop] 0/260, RunningAvgSamplesPerSec=1.165022925137947, CurrSamplesPerSec=0.9992919217130348, MemAllocated=2.28GB, MaxMemAllocated=11.79GB
[2022-11-22 06:13:37,343] [INFO] [timer.py:198:stop] 0/262, RunningAvgSamplesPerSec=1.1644925624848939, CurrSamplesPerSec=0.9671506219845027, MemAllocated=2.28GB, MaxMemAllocated=11.79GB
[2022-11-22 06:13:40,960] [INFO] [logging.py:68:log_dist] [Rank 0] step=132, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:13:40,993] [INFO] [timer.py:198:stop] 0/264, RunningAvgSamplesPerSec=1.1639686129431266, CurrSamplesPerSec=0.9628295311516135, MemAllocated=2.28GB, MaxMemAllocated=11.79GB
[2022-11-22 06:13:44,507] [INFO] [timer.py:198:stop] 0/266, RunningAvgSamplesPerSec=1.1637976930680174, CurrSamplesPerSec=1.0263417179015255, MemAllocated=2.28GB, MaxMemAllocated=11.79GB
[2022-11-22 06:13:48,142] [INFO] [logging.py:68:log_dist] [Rank 0] step=134, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:13:48,176] [INFO] [timer.py:198:stop] 0/268, RunningAvgSamplesPerSec=1.1632451207978338, CurrSamplesPerSec=0.9569648024925825, MemAllocated=2.28GB, MaxMemAllocated=11.79GB
[2022-11-22 06:13:51,836] [INFO] [timer.py:198:stop] 0/270, RunningAvgSamplesPerSec=1.1627254879813167, CurrSamplesPerSec=0.9597823369600972, MemAllocated=2.28GB, MaxMemAllocated=11.83GB
[2022-11-22 06:13:55,515] [INFO] [logging.py:68:log_dist] [Rank 0] step=136, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:13:55,541] [INFO] [timer.py:198:stop] 0/272, RunningAvgSamplesPerSec=1.1620994300578544, CurrSamplesPerSec=0.9441944746565528, MemAllocated=2.28GB, MaxMemAllocated=11.83GB
[2022-11-22 06:13:59,228] [INFO] [timer.py:198:stop] 0/274, RunningAvgSamplesPerSec=1.161520787876755, CurrSamplesPerSec=0.9469745126759291, MemAllocated=2.28GB, MaxMemAllocated=11.83GB
[2022-11-22 06:14:02,877] [INFO] [logging.py:68:log_dist] [Rank 0] step=138, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:14:02,908] [INFO] [timer.py:198:stop] 0/276, RunningAvgSamplesPerSec=1.160972669769948, CurrSamplesPerSec=0.9494392342379101, MemAllocated=2.28GB, MaxMemAllocated=11.83GB
[2022-11-22 06:14:06,534] [INFO] [timer.py:198:stop] 0/278, RunningAvgSamplesPerSec=1.1605687742485424, CurrSamplesPerSec=0.9834841045409568, MemAllocated=2.28GB, MaxMemAllocated=11.83GB
[2022-11-22 06:14:10,168] [INFO] [logging.py:68:log_dist] [Rank 0] step=140, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:14:10,204] [INFO] [timer.py:198:stop] 0/280, RunningAvgSamplesPerSec=1.1600604992233146, CurrSamplesPerSec=0.9543473240279458, MemAllocated=2.28GB, MaxMemAllocated=11.83GB
[2022-11-22 06:14:13,886] [INFO] [timer.py:198:stop] 0/282, RunningAvgSamplesPerSec=1.159535874902888, CurrSamplesPerSec=0.9555029644301415, MemAllocated=2.28GB, MaxMemAllocated=11.87GB
[2022-11-22 06:14:17,515] [INFO] [logging.py:68:log_dist] [Rank 0] step=142, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:14:17,550] [INFO] [timer.py:198:stop] 0/284, RunningAvgSamplesPerSec=1.159057476292782, CurrSamplesPerSec=0.9604656432289046, MemAllocated=2.28GB, MaxMemAllocated=11.87GB
[2022-11-22 06:14:21,202] [INFO] [timer.py:198:stop] 0/286, RunningAvgSamplesPerSec=1.158615222179919, CurrSamplesPerSec=0.9593066412760827, MemAllocated=2.28GB, MaxMemAllocated=11.87GB
[2022-11-22 06:14:24,845] [INFO] [logging.py:68:log_dist] [Rank 0] step=144, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:14:24,880] [INFO] [timer.py:198:stop] 0/288, RunningAvgSamplesPerSec=1.1581149769025192, CurrSamplesPerSec=0.9544177932997855, MemAllocated=2.28GB, MaxMemAllocated=11.87GB
[2022-11-22 06:14:28,569] [INFO] [timer.py:198:stop] 0/290, RunningAvgSamplesPerSec=1.1576041089652052, CurrSamplesPerSec=0.9546565323510993, MemAllocated=2.28GB, MaxMemAllocated=11.87GB
[2022-11-22 06:14:32,191] [INFO] [logging.py:68:log_dist] [Rank 0] step=146, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:14:32,225] [INFO] [timer.py:198:stop] 0/292, RunningAvgSamplesPerSec=1.157175752258966, CurrSamplesPerSec=0.9656003894352004, MemAllocated=2.28GB, MaxMemAllocated=11.87GB
[2022-11-22 06:14:35,908] [INFO] [timer.py:198:stop] 0/294, RunningAvgSamplesPerSec=1.1566877349071585, CurrSamplesPerSec=0.9547474757591615, MemAllocated=2.28GB, MaxMemAllocated=11.9GB
[2022-11-22 06:14:39,575] [INFO] [logging.py:68:log_dist] [Rank 0] step=148, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:14:39,610] [INFO] [timer.py:198:stop] 0/296, RunningAvgSamplesPerSec=1.1561667600327197, CurrSamplesPerSec=0.938208337615994, MemAllocated=2.28GB, MaxMemAllocated=11.91GB
[2022-11-22 06:14:43,320] [INFO] [timer.py:198:stop] 0/298, RunningAvgSamplesPerSec=1.1556329438130593, CurrSamplesPerSec=0.942784925076059, MemAllocated=2.28GB, MaxMemAllocated=11.91GB
[2022-11-22 06:14:46,976] [INFO] [logging.py:68:log_dist] [Rank 0] step=150, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:14:47,009] [INFO] [timer.py:198:stop] 0/300, RunningAvgSamplesPerSec=1.1551521596489467, CurrSamplesPerSec=0.9541643045569986, MemAllocated=2.28GB, MaxMemAllocated=11.91GB
[2022-11-22 06:14:50,610] [INFO] [timer.py:198:stop] 0/302, RunningAvgSamplesPerSec=1.1548676241028608, CurrSamplesPerSec=0.9886976290773897, MemAllocated=2.28GB, MaxMemAllocated=11.91GB
[2022-11-22 06:14:54,241] [INFO] [logging.py:68:log_dist] [Rank 0] step=152, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:14:54,274] [INFO] [timer.py:198:stop] 0/304, RunningAvgSamplesPerSec=1.1544599675212432, CurrSamplesPerSec=0.9642606841777417, MemAllocated=2.28GB, MaxMemAllocated=11.91GB
[2022-11-22 06:14:58,007] [INFO] [timer.py:198:stop] 0/306, RunningAvgSamplesPerSec=1.1539029670652075, CurrSamplesPerSec=0.9422400841978987, MemAllocated=2.28GB, MaxMemAllocated=11.95GB
[2022-11-22 06:15:01,706] [INFO] [logging.py:68:log_dist] [Rank 0] step=154, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:15:01,739] [INFO] [timer.py:198:stop] 0/308, RunningAvgSamplesPerSec=1.1533574972980034, CurrSamplesPerSec=0.9479837819280014, MemAllocated=2.28GB, MaxMemAllocated=11.95GB
[2022-11-22 06:15:05,476] [INFO] [timer.py:198:stop] 0/310, RunningAvgSamplesPerSec=1.152806620901578, CurrSamplesPerSec=0.9456044079917395, MemAllocated=2.28GB, MaxMemAllocated=11.95GB
[2022-11-22 06:15:09,167] [INFO] [logging.py:68:log_dist] [Rank 0] step=156, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:15:09,202] [INFO] [timer.py:198:stop] 0/312, RunningAvgSamplesPerSec=1.1522783557819485, CurrSamplesPerSec=0.9444822500197034, MemAllocated=2.28GB, MaxMemAllocated=11.95GB
[2022-11-22 06:15:12,909] [INFO] [timer.py:198:stop] 0/314, RunningAvgSamplesPerSec=1.1518071591830754, CurrSamplesPerSec=0.952534127160221, MemAllocated=2.28GB, MaxMemAllocated=11.95GB
[2022-11-22 06:15:16,627] [INFO] [logging.py:68:log_dist] [Rank 0] step=158, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:15:16,661] [INFO] [timer.py:198:stop] 0/316, RunningAvgSamplesPerSec=1.1512498709766725, CurrSamplesPerSec=0.9390365632409503, MemAllocated=2.28GB, MaxMemAllocated=11.95GB
[2022-11-22 06:15:20,416] [INFO] [timer.py:198:stop] 0/318, RunningAvgSamplesPerSec=1.150688708146875, CurrSamplesPerSec=0.935499070088983, MemAllocated=2.28GB, MaxMemAllocated=11.99GB
[2022-11-22 06:15:24,095] [INFO] [logging.py:68:log_dist] [Rank 0] step=160, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:15:24,127] [INFO] [timer.py:198:stop] 0/320, RunningAvgSamplesPerSec=1.1502304450386753, CurrSamplesPerSec=0.9596951529869491, MemAllocated=2.28GB, MaxMemAllocated=11.99GB
[2022-11-22 06:15:27,884] [INFO] [timer.py:198:stop] 0/322, RunningAvgSamplesPerSec=1.149681842435211, CurrSamplesPerSec=0.9372640599251338, MemAllocated=2.28GB, MaxMemAllocated=11.99GB
[2022-11-22 06:15:31,597] [INFO] [logging.py:68:log_dist] [Rank 0] step=162, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:15:31,632] [INFO] [timer.py:198:stop] 0/324, RunningAvgSamplesPerSec=1.1491489617391524, CurrSamplesPerSec=0.9355961042853063, MemAllocated=2.28GB, MaxMemAllocated=11.99GB
[2022-11-22 06:15:35,246] [INFO] [timer.py:198:stop] 0/326, RunningAvgSamplesPerSec=1.1489060389527799, CurrSamplesPerSec=1.0083649275996451, MemAllocated=2.28GB, MaxMemAllocated=11.99GB
[2022-11-22 06:15:38,973] [INFO] [logging.py:68:log_dist] [Rank 0] step=164, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:15:39,006] [INFO] [timer.py:198:stop] 0/328, RunningAvgSamplesPerSec=1.1483724862178704, CurrSamplesPerSec=0.9391305477091991, MemAllocated=2.28GB, MaxMemAllocated=11.99GB
[2022-11-22 06:15:42,782] [INFO] [timer.py:198:stop] 0/330, RunningAvgSamplesPerSec=1.1478109784149308, CurrSamplesPerSec=0.9297667959652287, MemAllocated=2.28GB, MaxMemAllocated=12.04GB
[2022-11-22 06:15:46,518] [INFO] [logging.py:68:log_dist] [Rank 0] step=166, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:15:46,556] [INFO] [timer.py:198:stop] 0/332, RunningAvgSamplesPerSec=1.147260168177732, CurrSamplesPerSec=0.9312181811057003, MemAllocated=2.28GB, MaxMemAllocated=12.04GB
[2022-11-22 06:15:50,330] [INFO] [timer.py:198:stop] 0/334, RunningAvgSamplesPerSec=1.1467206411531998, CurrSamplesPerSec=0.9351380293227239, MemAllocated=2.28GB, MaxMemAllocated=12.04GB
[2022-11-22 06:15:54,053] [INFO] [logging.py:68:log_dist] [Rank 0] step=168, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:15:54,088] [INFO] [timer.py:198:stop] 0/336, RunningAvgSamplesPerSec=1.1462077328906117, CurrSamplesPerSec=0.9349012412176864, MemAllocated=2.28GB, MaxMemAllocated=12.04GB
[2022-11-22 06:15:57,850] [INFO] [timer.py:198:stop] 0/338, RunningAvgSamplesPerSec=1.1457021509645855, CurrSamplesPerSec=0.931411945036466, MemAllocated=2.28GB, MaxMemAllocated=12.04GB
[2022-11-22 06:16:01,596] [INFO] [logging.py:68:log_dist] [Rank 0] step=170, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:16:01,631] [INFO] [timer.py:198:stop] 0/340, RunningAvgSamplesPerSec=1.1451677417594532, CurrSamplesPerSec=0.9254271019727335, MemAllocated=2.28GB, MaxMemAllocated=12.04GB
[2022-11-22 06:16:05,348] [INFO] [timer.py:198:stop] 0/342, RunningAvgSamplesPerSec=1.1447626450914257, CurrSamplesPerSec=0.9678136449987343, MemAllocated=2.28GB, MaxMemAllocated=12.11GB
[2022-11-22 06:16:09,026] [INFO] [logging.py:68:log_dist] [Rank 0] step=172, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:16:09,061] [INFO] [timer.py:198:stop] 0/344, RunningAvgSamplesPerSec=1.1443723628860312, CurrSamplesPerSec=0.9676352468698323, MemAllocated=2.28GB, MaxMemAllocated=12.11GB
[2022-11-22 06:16:12,827] [INFO] [timer.py:198:stop] 0/346, RunningAvgSamplesPerSec=1.1438834872254087, CurrSamplesPerSec=0.9402346426022302, MemAllocated=2.28GB, MaxMemAllocated=12.11GB
[2022-11-22 06:16:16,520] [INFO] [logging.py:68:log_dist] [Rank 0] step=174, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:16:16,552] [INFO] [timer.py:198:stop] 0/348, RunningAvgSamplesPerSec=1.1434796554131736, CurrSamplesPerSec=0.9621226640424689, MemAllocated=2.28GB, MaxMemAllocated=12.11GB
[2022-11-22 06:16:20,243] [INFO] [timer.py:198:stop] 0/350, RunningAvgSamplesPerSec=1.143144935473658, CurrSamplesPerSec=0.9809018638357124, MemAllocated=2.28GB, MaxMemAllocated=12.11GB
[2022-11-22 06:16:23,996] [INFO] [logging.py:68:log_dist] [Rank 0] step=176, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:16:24,021] [INFO] [timer.py:198:stop] 0/352, RunningAvgSamplesPerSec=1.142649970957144, CurrSamplesPerSec=0.9345204641026107, MemAllocated=2.28GB, MaxMemAllocated=12.11GB
[2022-11-22 06:16:27,788] [INFO] [timer.py:198:stop] 0/354, RunningAvgSamplesPerSec=1.1421821660411966, CurrSamplesPerSec=0.9439216381277094, MemAllocated=2.28GB, MaxMemAllocated=12.15GB
[2022-11-22 06:16:31,564] [INFO] [logging.py:68:log_dist] [Rank 0] step=178, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:16:31,599] [INFO] [timer.py:198:stop] 0/356, RunningAvgSamplesPerSec=1.1416342288259285, CurrSamplesPerSec=0.9268792971962055, MemAllocated=2.28GB, MaxMemAllocated=12.15GB
[2022-11-22 06:16:35,369] [INFO] [timer.py:198:stop] 0/358, RunningAvgSamplesPerSec=1.1411711508876192, CurrSamplesPerSec=0.938642012800323, MemAllocated=2.28GB, MaxMemAllocated=12.15GB
[2022-11-22 06:16:39,106] [INFO] [logging.py:68:log_dist] [Rank 0] step=180, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:16:39,141] [INFO] [timer.py:198:stop] 0/360, RunningAvgSamplesPerSec=1.1407130911084233, CurrSamplesPerSec=0.9360249651052467, MemAllocated=2.28GB, MaxMemAllocated=12.15GB
[2022-11-22 06:16:42,947] [INFO] [timer.py:198:stop] 0/362, RunningAvgSamplesPerSec=1.1401996237277172, CurrSamplesPerSec=0.930539712740537, MemAllocated=2.28GB, MaxMemAllocated=12.15GB
[2022-11-22 06:16:46,672] [INFO] [logging.py:68:log_dist] [Rank 0] step=182, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:16:46,706] [INFO] [timer.py:198:stop] 0/364, RunningAvgSamplesPerSec=1.1397654128949757, CurrSamplesPerSec=0.9419832903287966, MemAllocated=2.28GB, MaxMemAllocated=12.15GB
[2022-11-22 06:16:50,482] [INFO] [timer.py:198:stop] 0/366, RunningAvgSamplesPerSec=1.1393142124588198, CurrSamplesPerSec=0.9427368224204958, MemAllocated=2.28GB, MaxMemAllocated=12.18GB
[2022-11-22 06:16:54,171] [INFO] [logging.py:68:log_dist] [Rank 0] step=184, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:16:54,204] [INFO] [timer.py:198:stop] 0/368, RunningAvgSamplesPerSec=1.1389662539681424, CurrSamplesPerSec=0.9721176130703028, MemAllocated=2.28GB, MaxMemAllocated=12.19GB
[2022-11-22 06:16:58,004] [INFO] [timer.py:198:stop] 0/370, RunningAvgSamplesPerSec=1.138483122011616, CurrSamplesPerSec=0.9340189286572825, MemAllocated=2.28GB, MaxMemAllocated=12.19GB
[2022-11-22 06:17:01,770] [INFO] [logging.py:68:log_dist] [Rank 0] step=186, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:17:01,803] [INFO] [timer.py:198:stop] 0/372, RunningAvgSamplesPerSec=1.1379982308943852, CurrSamplesPerSec=0.925503269367025, MemAllocated=2.28GB, MaxMemAllocated=12.19GB
[2022-11-22 06:17:05,549] [INFO] [timer.py:198:stop] 0/374, RunningAvgSamplesPerSec=1.1376198231394816, CurrSamplesPerSec=0.9519236246733248, MemAllocated=2.28GB, MaxMemAllocated=12.19GB
[2022-11-22 06:17:09,341] [INFO] [logging.py:68:log_dist] [Rank 0] step=188, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:17:09,376] [INFO] [timer.py:198:stop] 0/376, RunningAvgSamplesPerSec=1.1371062657068962, CurrSamplesPerSec=0.9245351621373642, MemAllocated=2.28GB, MaxMemAllocated=12.19GB
[2022-11-22 06:17:13,196] [INFO] [timer.py:198:stop] 0/378, RunningAvgSamplesPerSec=1.1366127239544284, CurrSamplesPerSec=0.9214709468240612, MemAllocated=2.28GB, MaxMemAllocated=12.23GB
[2022-11-22 06:17:16,985] [INFO] [logging.py:68:log_dist] [Rank 0] step=190, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:17:17,020] [INFO] [timer.py:198:stop] 0/380, RunningAvgSamplesPerSec=1.1361150086766085, CurrSamplesPerSec=0.9174118001140885, MemAllocated=2.28GB, MaxMemAllocated=12.23GB
[2022-11-22 06:17:20,848] [INFO] [timer.py:198:stop] 0/382, RunningAvgSamplesPerSec=1.135616382258566, CurrSamplesPerSec=0.9278829067442398, MemAllocated=2.28GB, MaxMemAllocated=12.23GB
[2022-11-22 06:17:24,635] [INFO] [logging.py:68:log_dist] [Rank 0] step=192, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:17:24,670] [INFO] [timer.py:198:stop] 0/384, RunningAvgSamplesPerSec=1.1351297162683875, CurrSamplesPerSec=0.9272142073230244, MemAllocated=2.28GB, MaxMemAllocated=12.23GB
[2022-11-22 06:17:28,483] [INFO] [timer.py:198:stop] 0/386, RunningAvgSamplesPerSec=1.1346685008300097, CurrSamplesPerSec=0.9310843305025449, MemAllocated=2.28GB, MaxMemAllocated=12.23GB
[2022-11-22 06:17:32,312] [INFO] [logging.py:68:log_dist] [Rank 0] step=194, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:17:32,345] [INFO] [timer.py:198:stop] 0/388, RunningAvgSamplesPerSec=1.134132185236, CurrSamplesPerSec=0.9121813930657926, MemAllocated=2.28GB, MaxMemAllocated=12.23GB
[2022-11-22 06:17:36,159] [INFO] [timer.py:198:stop] 0/390, RunningAvgSamplesPerSec=1.1336799854251072, CurrSamplesPerSec=0.9263965675011214, MemAllocated=2.28GB, MaxMemAllocated=12.27GB
[2022-11-22 06:17:39,949] [INFO] [logging.py:68:log_dist] [Rank 0] step=196, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:17:39,982] [INFO] [timer.py:198:stop] 0/392, RunningAvgSamplesPerSec=1.1332120248991517, CurrSamplesPerSec=0.9208051873095722, MemAllocated=2.28GB, MaxMemAllocated=12.27GB
[2022-11-22 06:17:43,867] [INFO] [timer.py:198:stop] 0/394, RunningAvgSamplesPerSec=1.1326521726674086, CurrSamplesPerSec=0.8990805884585412, MemAllocated=2.28GB, MaxMemAllocated=12.27GB
[2022-11-22 06:17:47,684] [INFO] [logging.py:68:log_dist] [Rank 0] step=198, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:17:47,718] [INFO] [timer.py:198:stop] 0/396, RunningAvgSamplesPerSec=1.1321486180323643, CurrSamplesPerSec=0.9148654422957837, MemAllocated=2.28GB, MaxMemAllocated=12.27GB
[2022-11-22 06:17:51,562] [INFO] [timer.py:198:stop] 0/398, RunningAvgSamplesPerSec=1.1316678202263604, CurrSamplesPerSec=0.918365441133243, MemAllocated=2.28GB, MaxMemAllocated=12.27GB
[2022-11-22 06:17:55,348] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:17:55,381] [INFO] [timer.py:198:stop] 0/400, RunningAvgSamplesPerSec=1.1312292123015493, CurrSamplesPerSec=0.9279567073420304, MemAllocated=2.28GB, MaxMemAllocated=12.27GB
Epoch: [0][ 400/1563]	Time  1.657 ( 1.776)	Loss 2.6247e+00 (2.7301e+00)	Acc@1  15.62 ( 11.03)	Acc@5  59.38 ( 51.48)
[2022-11-22 06:17:59,267] [INFO] [timer.py:198:stop] 0/402, RunningAvgSamplesPerSec=1.1306922977451888, CurrSamplesPerSec=0.9001638484215921, MemAllocated=2.28GB, MaxMemAllocated=12.33GB
[2022-11-22 06:18:03,081] [INFO] [logging.py:68:log_dist] [Rank 0] step=202, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:18:03,120] [INFO] [timer.py:198:stop] 0/404, RunningAvgSamplesPerSec=1.1302165709041156, CurrSamplesPerSec=0.9220114836406482, MemAllocated=2.28GB, MaxMemAllocated=12.33GB
[2022-11-22 06:18:06,978] [INFO] [timer.py:198:stop] 0/406, RunningAvgSamplesPerSec=1.129737354686027, CurrSamplesPerSec=0.9198750209857324, MemAllocated=2.28GB, MaxMemAllocated=12.33GB
[2022-11-22 06:18:10,694] [INFO] [logging.py:68:log_dist] [Rank 0] step=204, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:18:10,728] [INFO] [timer.py:198:stop] 0/408, RunningAvgSamplesPerSec=1.1294299767324565, CurrSamplesPerSec=0.9597575197580964, MemAllocated=2.28GB, MaxMemAllocated=12.33GB
[2022-11-22 06:18:14,514] [INFO] [timer.py:198:stop] 0/410, RunningAvgSamplesPerSec=1.129072518870731, CurrSamplesPerSec=0.942716374981078, MemAllocated=2.28GB, MaxMemAllocated=12.33GB
[2022-11-22 06:18:18,325] [INFO] [logging.py:68:log_dist] [Rank 0] step=206, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:18:18,365] [INFO] [timer.py:198:stop] 0/412, RunningAvgSamplesPerSec=1.1286143820968784, CurrSamplesPerSec=0.9186223940578155, MemAllocated=2.28GB, MaxMemAllocated=12.33GB
[2022-11-22 06:18:22,200] [INFO] [timer.py:198:stop] 0/414, RunningAvgSamplesPerSec=1.1281886900221192, CurrSamplesPerSec=0.9229703495810405, MemAllocated=2.28GB, MaxMemAllocated=12.33GB
[2022-11-22 06:18:26,030] [INFO] [logging.py:68:log_dist] [Rank 0] step=208, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:18:26,065] [INFO] [timer.py:198:stop] 0/416, RunningAvgSamplesPerSec=1.1277197408500286, CurrSamplesPerSec=0.9164991875235786, MemAllocated=2.28GB, MaxMemAllocated=12.37GB
[2022-11-22 06:18:29,785] [INFO] [timer.py:198:stop] 0/418, RunningAvgSamplesPerSec=1.1274759913468606, CurrSamplesPerSec=0.9769011304004434, MemAllocated=2.28GB, MaxMemAllocated=12.37GB
[2022-11-22 06:18:33,606] [INFO] [logging.py:68:log_dist] [Rank 0] step=210, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:18:33,637] [INFO] [timer.py:198:stop] 0/420, RunningAvgSamplesPerSec=1.1270350495084536, CurrSamplesPerSec=0.9184377354639953, MemAllocated=2.28GB, MaxMemAllocated=12.37GB
[2022-11-22 06:18:37,476] [INFO] [timer.py:198:stop] 0/422, RunningAvgSamplesPerSec=1.1266133394344142, CurrSamplesPerSec=0.9255859854282632, MemAllocated=2.28GB, MaxMemAllocated=12.37GB
[2022-11-22 06:18:41,356] [INFO] [logging.py:68:log_dist] [Rank 0] step=212, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:18:41,383] [INFO] [timer.py:198:stop] 0/424, RunningAvgSamplesPerSec=1.1260986938155042, CurrSamplesPerSec=0.8975638066187644, MemAllocated=2.28GB, MaxMemAllocated=12.37GB
[2022-11-22 06:18:45,241] [INFO] [timer.py:198:stop] 0/426, RunningAvgSamplesPerSec=1.125661863694847, CurrSamplesPerSec=0.9212016747348333, MemAllocated=2.28GB, MaxMemAllocated=12.37GB
[2022-11-22 06:18:49,119] [INFO] [logging.py:68:log_dist] [Rank 0] step=214, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:18:49,152] [INFO] [timer.py:198:stop] 0/428, RunningAvgSamplesPerSec=1.1251492837940784, CurrSamplesPerSec=0.8985978797069464, MemAllocated=2.28GB, MaxMemAllocated=12.42GB
[2022-11-22 06:18:53,000] [INFO] [timer.py:198:stop] 0/430, RunningAvgSamplesPerSec=1.1247378600463642, CurrSamplesPerSec=0.9249889236524843, MemAllocated=2.28GB, MaxMemAllocated=12.42GB
[2022-11-22 06:18:56,871] [INFO] [logging.py:68:log_dist] [Rank 0] step=216, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:18:56,905] [INFO] [timer.py:198:stop] 0/432, RunningAvgSamplesPerSec=1.1242453812501851, CurrSamplesPerSec=0.90434866604225, MemAllocated=2.28GB, MaxMemAllocated=12.42GB
[2022-11-22 06:19:00,783] [INFO] [timer.py:198:stop] 0/434, RunningAvgSamplesPerSec=1.1237973614293206, CurrSamplesPerSec=0.9159437899351974, MemAllocated=2.28GB, MaxMemAllocated=12.42GB
[2022-11-22 06:19:04,469] [INFO] [logging.py:68:log_dist] [Rank 0] step=218, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:04,504] [INFO] [timer.py:198:stop] 0/436, RunningAvgSamplesPerSec=1.123584999681362, CurrSamplesPerSec=0.991089700231273, MemAllocated=2.28GB, MaxMemAllocated=12.42GB
[2022-11-22 06:19:08,390] [INFO] [timer.py:198:stop] 0/438, RunningAvgSamplesPerSec=1.1231330449271237, CurrSamplesPerSec=0.915331532118792, MemAllocated=2.28GB, MaxMemAllocated=12.42GB
[2022-11-22 06:19:12,249] [INFO] [logging.py:68:log_dist] [Rank 0] step=220, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:12,283] [INFO] [timer.py:198:stop] 0/440, RunningAvgSamplesPerSec=1.1226766569734463, CurrSamplesPerSec=0.9158632881607156, MemAllocated=2.28GB, MaxMemAllocated=12.47GB
[2022-11-22 06:19:16,158] [INFO] [timer.py:198:stop] 0/442, RunningAvgSamplesPerSec=1.1222462026766469, CurrSamplesPerSec=0.9152140914425502, MemAllocated=2.28GB, MaxMemAllocated=12.47GB
[2022-11-22 06:19:20,019] [INFO] [logging.py:68:log_dist] [Rank 0] step=222, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:20,053] [INFO] [timer.py:198:stop] 0/444, RunningAvgSamplesPerSec=1.1217903207024778, CurrSamplesPerSec=0.9063155067468506, MemAllocated=2.28GB, MaxMemAllocated=12.47GB
[2022-11-22 06:19:23,942] [INFO] [timer.py:198:stop] 0/446, RunningAvgSamplesPerSec=1.12135165180176, CurrSamplesPerSec=0.9124220940679459, MemAllocated=2.28GB, MaxMemAllocated=12.47GB
[2022-11-22 06:19:27,817] [INFO] [logging.py:68:log_dist] [Rank 0] step=224, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:27,850] [INFO] [timer.py:198:stop] 0/448, RunningAvgSamplesPerSec=1.1208842035283086, CurrSamplesPerSec=0.8992415423769022, MemAllocated=2.28GB, MaxMemAllocated=12.47GB
[2022-11-22 06:19:31,724] [INFO] [timer.py:198:stop] 0/450, RunningAvgSamplesPerSec=1.1204751466058287, CurrSamplesPerSec=0.9183731828192144, MemAllocated=2.28GB, MaxMemAllocated=12.47GB
[2022-11-22 06:19:35,611] [INFO] [logging.py:68:log_dist] [Rank 0] step=226, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:35,648] [INFO] [timer.py:198:stop] 0/452, RunningAvgSamplesPerSec=1.1199991918883325, CurrSamplesPerSec=0.9014123252001489, MemAllocated=2.28GB, MaxMemAllocated=12.51GB
[2022-11-22 06:19:39,573] [INFO] [timer.py:198:stop] 0/454, RunningAvgSamplesPerSec=1.119529281933341, CurrSamplesPerSec=0.9074749835026342, MemAllocated=2.28GB, MaxMemAllocated=12.51GB
[2022-11-22 06:19:42,701] [INFO] [logging.py:68:log_dist] [Rank 0] step=228, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:42,707] [INFO] [timer.py:198:stop] 0/456, RunningAvgSamplesPerSec=1.1201493345135431, CurrSamplesPerSec=1.4015791183189221, MemAllocated=2.28GB, MaxMemAllocated=12.51GB
[2022-11-22 06:19:44,301] [INFO] [timer.py:198:stop] 0/458, RunningAvgSamplesPerSec=1.122883311976549, CurrSamplesPerSec=2.444762371340882, MemAllocated=2.28GB, MaxMemAllocated=12.51GB
[2022-11-22 06:19:45,882] [INFO] [logging.py:68:log_dist] [Rank 0] step=230, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:45,892] [INFO] [timer.py:198:stop] 0/460, RunningAvgSamplesPerSec=1.1256110115534423, CurrSamplesPerSec=2.4511229554636826, MemAllocated=2.28GB, MaxMemAllocated=12.51GB
[2022-11-22 06:19:47,483] [INFO] [timer.py:198:stop] 0/462, RunningAvgSamplesPerSec=1.1283274828370877, CurrSamplesPerSec=2.4458330113958575, MemAllocated=2.28GB, MaxMemAllocated=12.51GB
[2022-11-22 06:19:49,076] [INFO] [logging.py:68:log_dist] [Rank 0] step=232, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:49,085] [INFO] [timer.py:198:stop] 0/464, RunningAvgSamplesPerSec=1.131017524074625, CurrSamplesPerSec=2.4322723019695975, MemAllocated=2.28GB, MaxMemAllocated=12.55GB
[2022-11-22 06:19:50,686] [INFO] [timer.py:198:stop] 0/466, RunningAvgSamplesPerSec=1.1336995081020242, CurrSamplesPerSec=2.432252555521245, MemAllocated=2.28GB, MaxMemAllocated=12.55GB
[2022-11-22 06:19:52,280] [INFO] [logging.py:68:log_dist] [Rank 0] step=234, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:52,289] [INFO] [timer.py:198:stop] 0/468, RunningAvgSamplesPerSec=1.1363687419753519, CurrSamplesPerSec=2.4267508774203552, MemAllocated=2.28GB, MaxMemAllocated=12.55GB
[2022-11-22 06:19:53,894] [INFO] [timer.py:198:stop] 0/470, RunningAvgSamplesPerSec=1.139024152568336, CurrSamplesPerSec=2.4230385728563095, MemAllocated=2.28GB, MaxMemAllocated=12.55GB
[2022-11-22 06:19:55,491] [INFO] [logging.py:68:log_dist] [Rank 0] step=236, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:55,500] [INFO] [timer.py:198:stop] 0/472, RunningAvgSamplesPerSec=1.1416682986393827, CurrSamplesPerSec=2.4200907208595375, MemAllocated=2.28GB, MaxMemAllocated=12.55GB
[2022-11-22 06:19:57,103] [INFO] [timer.py:198:stop] 0/474, RunningAvgSamplesPerSec=1.1443060914040326, CurrSamplesPerSec=2.4273891976277664, MemAllocated=2.28GB, MaxMemAllocated=12.55GB
[2022-11-22 06:19:59,860] [INFO] [logging.py:68:log_dist] [Rank 0] step=238, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:19:59,893] [INFO] [timer.py:198:stop] 0/476, RunningAvgSamplesPerSec=1.1452887452896359, CurrSamplesPerSec=0.996818681984652, MemAllocated=2.28GB, MaxMemAllocated=12.6GB
[2022-11-22 06:20:03,869] [INFO] [timer.py:198:stop] 0/478, RunningAvgSamplesPerSec=1.1446397845000715, CurrSamplesPerSec=0.8888069510939437, MemAllocated=2.28GB, MaxMemAllocated=12.6GB
[2022-11-22 06:20:07,742] [INFO] [logging.py:68:log_dist] [Rank 0] step=240, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:20:07,775] [INFO] [timer.py:198:stop] 0/480, RunningAvgSamplesPerSec=1.1440957532093996, CurrSamplesPerSec=0.916099733620826, MemAllocated=2.28GB, MaxMemAllocated=12.6GB
[2022-11-22 06:20:11,712] [INFO] [timer.py:198:stop] 0/482, RunningAvgSamplesPerSec=1.143513752264184, CurrSamplesPerSec=0.9034427743117321, MemAllocated=2.28GB, MaxMemAllocated=12.6GB
[2022-11-22 06:20:15,606] [INFO] [logging.py:68:log_dist] [Rank 0] step=242, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:20:15,641] [INFO] [timer.py:198:stop] 0/484, RunningAvgSamplesPerSec=1.1429495442397348, CurrSamplesPerSec=0.9098394696588685, MemAllocated=2.28GB, MaxMemAllocated=12.6GB
[2022-11-22 06:20:19,557] [INFO] [timer.py:198:stop] 0/486, RunningAvgSamplesPerSec=1.142401532900556, CurrSamplesPerSec=0.9153001717100001, MemAllocated=2.28GB, MaxMemAllocated=12.6GB
[2022-11-22 06:20:23,430] [INFO] [logging.py:68:log_dist] [Rank 0] step=244, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:20:23,457] [INFO] [timer.py:198:stop] 0/488, RunningAvgSamplesPerSec=1.1418864184729685, CurrSamplesPerSec=0.9214801580858857, MemAllocated=2.28GB, MaxMemAllocated=12.64GB
[2022-11-22 06:20:27,474] [INFO] [timer.py:198:stop] 0/490, RunningAvgSamplesPerSec=1.141217436576265, CurrSamplesPerSec=0.8787766823430545, MemAllocated=2.28GB, MaxMemAllocated=12.64GB
[2022-11-22 06:20:31,427] [INFO] [logging.py:68:log_dist] [Rank 0] step=246, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:20:31,462] [INFO] [timer.py:198:stop] 0/492, RunningAvgSamplesPerSec=1.140596483885473, CurrSamplesPerSec=0.890121565791589, MemAllocated=2.28GB, MaxMemAllocated=12.64GB
[2022-11-22 06:20:35,402] [INFO] [timer.py:198:stop] 0/494, RunningAvgSamplesPerSec=1.1400380605657612, CurrSamplesPerSec=0.9030857283609945, MemAllocated=2.28GB, MaxMemAllocated=12.64GB
[2022-11-22 06:20:39,338] [INFO] [logging.py:68:log_dist] [Rank 0] step=248, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:20:39,369] [INFO] [timer.py:198:stop] 0/496, RunningAvgSamplesPerSec=1.1394542688206297, CurrSamplesPerSec=0.8934797534140532, MemAllocated=2.28GB, MaxMemAllocated=12.64GB
[2022-11-22 06:20:43,343] [INFO] [timer.py:198:stop] 0/498, RunningAvgSamplesPerSec=1.1388653889598481, CurrSamplesPerSec=0.8994530868101248, MemAllocated=2.28GB, MaxMemAllocated=12.64GB
[2022-11-22 06:20:47,200] [INFO] [logging.py:68:log_dist] [Rank 0] step=250, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:20:47,233] [INFO] [timer.py:198:stop] 0/500, RunningAvgSamplesPerSec=1.138392354508191, CurrSamplesPerSec=0.938859158389662, MemAllocated=2.28GB, MaxMemAllocated=12.7GB
[2022-11-22 06:20:51,219] [INFO] [timer.py:198:stop] 0/502, RunningAvgSamplesPerSec=1.1377993846695758, CurrSamplesPerSec=0.8976323826196382, MemAllocated=2.28GB, MaxMemAllocated=12.7GB
[2022-11-22 06:20:55,024] [INFO] [logging.py:68:log_dist] [Rank 0] step=252, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:20:55,055] [INFO] [timer.py:198:stop] 0/504, RunningAvgSamplesPerSec=1.1374021502058154, CurrSamplesPerSec=0.955979361094688, MemAllocated=2.28GB, MaxMemAllocated=12.7GB
[2022-11-22 06:20:59,061] [INFO] [timer.py:198:stop] 0/506, RunningAvgSamplesPerSec=1.1367918163426352, CurrSamplesPerSec=0.8872146177157403, MemAllocated=2.28GB, MaxMemAllocated=12.7GB
[2022-11-22 06:21:02,977] [INFO] [logging.py:68:log_dist] [Rank 0] step=254, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:21:03,009] [INFO] [timer.py:198:stop] 0/508, RunningAvgSamplesPerSec=1.1362638726294585, CurrSamplesPerSec=0.9122858532098378, MemAllocated=2.28GB, MaxMemAllocated=12.7GB
[2022-11-22 06:21:07,010] [INFO] [timer.py:198:stop] 0/510, RunningAvgSamplesPerSec=1.135670298673442, CurrSamplesPerSec=0.8838724462621217, MemAllocated=2.28GB, MaxMemAllocated=12.7GB
[2022-11-22 06:21:10,981] [INFO] [logging.py:68:log_dist] [Rank 0] step=256, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:21:11,012] [INFO] [timer.py:198:stop] 0/512, RunningAvgSamplesPerSec=1.1350804954048368, CurrSamplesPerSec=0.8877385293668506, MemAllocated=2.28GB, MaxMemAllocated=12.74GB
[2022-11-22 06:21:15,021] [INFO] [timer.py:198:stop] 0/514, RunningAvgSamplesPerSec=1.1344877223417071, CurrSamplesPerSec=0.8919716461192051, MemAllocated=2.28GB, MaxMemAllocated=12.74GB
[2022-11-22 06:21:18,997] [INFO] [logging.py:68:log_dist] [Rank 0] step=258, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:21:19,033] [INFO] [timer.py:198:stop] 0/516, RunningAvgSamplesPerSec=1.1338975152233808, CurrSamplesPerSec=0.8882949467644073, MemAllocated=2.28GB, MaxMemAllocated=12.74GB
[2022-11-22 06:21:23,021] [INFO] [timer.py:198:stop] 0/518, RunningAvgSamplesPerSec=1.1333436874632044, CurrSamplesPerSec=0.8943249556681305, MemAllocated=2.28GB, MaxMemAllocated=12.74GB
[2022-11-22 06:21:26,985] [INFO] [logging.py:68:log_dist] [Rank 0] step=260, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:21:27,019] [INFO] [timer.py:198:stop] 0/520, RunningAvgSamplesPerSec=1.132779508512621, CurrSamplesPerSec=0.8895228630465244, MemAllocated=2.28GB, MaxMemAllocated=12.74GB
[2022-11-22 06:21:31,037] [INFO] [timer.py:198:stop] 0/522, RunningAvgSamplesPerSec=1.1321953800780418, CurrSamplesPerSec=0.8792963874627796, MemAllocated=2.28GB, MaxMemAllocated=12.74GB
[2022-11-22 06:21:34,852] [INFO] [logging.py:68:log_dist] [Rank 0] step=262, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:21:34,887] [INFO] [timer.py:198:stop] 0/524, RunningAvgSamplesPerSec=1.1318240323499755, CurrSamplesPerSec=0.953383624424991, MemAllocated=2.28GB, MaxMemAllocated=12.8GB
[2022-11-22 06:21:38,898] [INFO] [timer.py:198:stop] 0/526, RunningAvgSamplesPerSec=1.1312598373750975, CurrSamplesPerSec=0.8917181039883953, MemAllocated=2.28GB, MaxMemAllocated=12.8GB
[2022-11-22 06:21:42,758] [INFO] [logging.py:68:log_dist] [Rank 0] step=264, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:21:42,794] [INFO] [timer.py:198:stop] 0/528, RunningAvgSamplesPerSec=1.1308401606751775, CurrSamplesPerSec=0.9407039494703204, MemAllocated=2.28GB, MaxMemAllocated=12.8GB
[2022-11-22 06:21:46,823] [INFO] [timer.py:198:stop] 0/530, RunningAvgSamplesPerSec=1.1302631114382446, CurrSamplesPerSec=0.8828800516302154, MemAllocated=2.28GB, MaxMemAllocated=12.8GB
[2022-11-22 06:21:50,824] [INFO] [logging.py:68:log_dist] [Rank 0] step=266, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:21:50,858] [INFO] [timer.py:198:stop] 0/532, RunningAvgSamplesPerSec=1.1296823445636666, CurrSamplesPerSec=0.8756461702233822, MemAllocated=2.28GB, MaxMemAllocated=12.8GB
[2022-11-22 06:21:54,894] [INFO] [timer.py:198:stop] 0/534, RunningAvgSamplesPerSec=1.1291064459041804, CurrSamplesPerSec=0.8749364418513473, MemAllocated=2.28GB, MaxMemAllocated=12.8GB
[2022-11-22 06:21:58,766] [INFO] [logging.py:68:log_dist] [Rank 0] step=268, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:21:58,801] [INFO] [timer.py:198:stop] 0/536, RunningAvgSamplesPerSec=1.1286890462287742, CurrSamplesPerSec=0.9306829062095394, MemAllocated=2.28GB, MaxMemAllocated=12.87GB
[2022-11-22 06:22:02,821] [INFO] [timer.py:198:stop] 0/538, RunningAvgSamplesPerSec=1.128139632446063, CurrSamplesPerSec=0.8817601971097853, MemAllocated=2.28GB, MaxMemAllocated=12.87GB
[2022-11-22 06:22:06,820] [INFO] [logging.py:68:log_dist] [Rank 0] step=270, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:22:06,854] [INFO] [timer.py:198:stop] 0/540, RunningAvgSamplesPerSec=1.127580671750491, CurrSamplesPerSec=0.8787677526923668, MemAllocated=2.28GB, MaxMemAllocated=12.87GB
[2022-11-22 06:22:10,770] [INFO] [timer.py:198:stop] 0/542, RunningAvgSamplesPerSec=1.1271612923625678, CurrSamplesPerSec=0.9235796533017891, MemAllocated=2.28GB, MaxMemAllocated=12.87GB
[2022-11-22 06:22:14,645] [INFO] [logging.py:68:log_dist] [Rank 0] step=272, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:22:14,680] [INFO] [timer.py:198:stop] 0/544, RunningAvgSamplesPerSec=1.1267528062655565, CurrSamplesPerSec=0.9308442193969969, MemAllocated=2.28GB, MaxMemAllocated=12.87GB
[2022-11-22 06:22:18,653] [INFO] [timer.py:198:stop] 0/546, RunningAvgSamplesPerSec=1.1262764599939799, CurrSamplesPerSec=0.9088456405927697, MemAllocated=2.28GB, MaxMemAllocated=12.87GB
[2022-11-22 06:22:22,661] [INFO] [logging.py:68:log_dist] [Rank 0] step=274, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:22:22,696] [INFO] [timer.py:198:stop] 0/548, RunningAvgSamplesPerSec=1.1257214610674497, CurrSamplesPerSec=0.8862507548644117, MemAllocated=2.28GB, MaxMemAllocated=12.91GB
[2022-11-22 06:22:26,763] [INFO] [timer.py:198:stop] 0/550, RunningAvgSamplesPerSec=1.1251442907888485, CurrSamplesPerSec=0.8742940128958401, MemAllocated=2.28GB, MaxMemAllocated=12.91GB
[2022-11-22 06:22:30,796] [INFO] [logging.py:68:log_dist] [Rank 0] step=276, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:22:30,828] [INFO] [timer.py:198:stop] 0/552, RunningAvgSamplesPerSec=1.1245741964102902, CurrSamplesPerSec=0.8739339544260015, MemAllocated=2.28GB, MaxMemAllocated=12.91GB
[2022-11-22 06:22:34,893] [INFO] [timer.py:198:stop] 0/554, RunningAvgSamplesPerSec=1.1240085295646032, CurrSamplesPerSec=0.87455078005881, MemAllocated=2.28GB, MaxMemAllocated=12.91GB
[2022-11-22 06:22:38,895] [INFO] [logging.py:68:log_dist] [Rank 0] step=278, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:22:38,929] [INFO] [timer.py:198:stop] 0/556, RunningAvgSamplesPerSec=1.12347557209454, CurrSamplesPerSec=0.880642255355776, MemAllocated=2.28GB, MaxMemAllocated=12.91GB
[2022-11-22 06:22:43,018] [INFO] [timer.py:198:stop] 0/558, RunningAvgSamplesPerSec=1.122892327363135, CurrSamplesPerSec=0.8662480104743562, MemAllocated=2.28GB, MaxMemAllocated=12.91GB
[2022-11-22 06:22:46,937] [INFO] [logging.py:68:log_dist] [Rank 0] step=280, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:22:46,968] [INFO] [timer.py:198:stop] 0/560, RunningAvgSamplesPerSec=1.1224722389268065, CurrSamplesPerSec=0.927442810456613, MemAllocated=2.28GB, MaxMemAllocated=12.95GB
[2022-11-22 06:22:51,042] [INFO] [timer.py:198:stop] 0/562, RunningAvgSamplesPerSec=1.121913252270087, CurrSamplesPerSec=0.8785221203858807, MemAllocated=2.28GB, MaxMemAllocated=12.95GB
[2022-11-22 06:22:55,099] [INFO] [logging.py:68:log_dist] [Rank 0] step=282, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:22:55,133] [INFO] [timer.py:198:stop] 0/564, RunningAvgSamplesPerSec=1.121340245125692, CurrSamplesPerSec=0.8713037968767041, MemAllocated=2.28GB, MaxMemAllocated=12.95GB
[2022-11-22 06:22:59,193] [INFO] [timer.py:198:stop] 0/566, RunningAvgSamplesPerSec=1.120805737265374, CurrSamplesPerSec=0.8808760321952186, MemAllocated=2.28GB, MaxMemAllocated=12.95GB
[2022-11-22 06:23:03,227] [INFO] [logging.py:68:log_dist] [Rank 0] step=284, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:23:03,261] [INFO] [timer.py:198:stop] 0/568, RunningAvgSamplesPerSec=1.1202676962428249, CurrSamplesPerSec=0.8761048951998404, MemAllocated=2.28GB, MaxMemAllocated=12.95GB
[2022-11-22 06:23:07,353] [INFO] [timer.py:198:stop] 0/570, RunningAvgSamplesPerSec=1.1197082682428725, CurrSamplesPerSec=0.8691355732501367, MemAllocated=2.28GB, MaxMemAllocated=12.95GB
[2022-11-22 06:23:11,413] [INFO] [logging.py:68:log_dist] [Rank 0] step=286, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:23:11,448] [INFO] [timer.py:198:stop] 0/572, RunningAvgSamplesPerSec=1.1191504856788594, CurrSamplesPerSec=0.8714805795362144, MemAllocated=2.28GB, MaxMemAllocated=12.99GB
[2022-11-22 06:23:15,585] [INFO] [timer.py:198:stop] 0/574, RunningAvgSamplesPerSec=1.1185492189058586, CurrSamplesPerSec=0.8606882852582929, MemAllocated=2.28GB, MaxMemAllocated=12.99GB
[2022-11-22 06:23:19,645] [INFO] [logging.py:68:log_dist] [Rank 0] step=288, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:23:19,680] [INFO] [timer.py:198:stop] 0/576, RunningAvgSamplesPerSec=1.1179993946115767, CurrSamplesPerSec=0.8708916732054941, MemAllocated=2.28GB, MaxMemAllocated=12.99GB
[2022-11-22 06:23:23,805] [INFO] [timer.py:198:stop] 0/578, RunningAvgSamplesPerSec=1.117421255719225, CurrSamplesPerSec=0.8655690585410605, MemAllocated=2.28GB, MaxMemAllocated=12.99GB
[2022-11-22 06:23:27,871] [INFO] [logging.py:68:log_dist] [Rank 0] step=290, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:23:27,906] [INFO] [timer.py:198:stop] 0/580, RunningAvgSamplesPerSec=1.1168749723734934, CurrSamplesPerSec=0.8685799581314335, MemAllocated=2.28GB, MaxMemAllocated=12.99GB
[2022-11-22 06:23:31,955] [INFO] [timer.py:198:stop] 0/582, RunningAvgSamplesPerSec=1.116386868619905, CurrSamplesPerSec=0.8900575322980568, MemAllocated=2.28GB, MaxMemAllocated=12.99GB
[2022-11-22 06:23:36,080] [INFO] [logging.py:68:log_dist] [Rank 0] step=292, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:23:36,107] [INFO] [timer.py:198:stop] 0/584, RunningAvgSamplesPerSec=1.1157937922205798, CurrSamplesPerSec=0.8553504163973922, MemAllocated=2.28GB, MaxMemAllocated=13.03GB
[2022-11-22 06:23:40,206] [INFO] [timer.py:198:stop] 0/586, RunningAvgSamplesPerSec=1.1152622608950453, CurrSamplesPerSec=0.8714604808122736, MemAllocated=2.28GB, MaxMemAllocated=13.03GB
[2022-11-22 06:23:44,301] [INFO] [logging.py:68:log_dist] [Rank 0] step=294, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:23:44,336] [INFO] [timer.py:198:stop] 0/588, RunningAvgSamplesPerSec=1.1146993447712072, CurrSamplesPerSec=0.8647308668710959, MemAllocated=2.28GB, MaxMemAllocated=13.03GB
[2022-11-22 06:23:48,421] [INFO] [timer.py:198:stop] 0/590, RunningAvgSamplesPerSec=1.114189345234869, CurrSamplesPerSec=0.875984771834933, MemAllocated=2.28GB, MaxMemAllocated=13.03GB
[2022-11-22 06:23:52,476] [INFO] [logging.py:68:log_dist] [Rank 0] step=296, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:23:52,510] [INFO] [timer.py:198:stop] 0/592, RunningAvgSamplesPerSec=1.113674460781183, CurrSamplesPerSec=0.8754933686288418, MemAllocated=2.28GB, MaxMemAllocated=13.03GB
[2022-11-22 06:23:56,611] [INFO] [timer.py:198:stop] 0/594, RunningAvgSamplesPerSec=1.1131557463736357, CurrSamplesPerSec=0.8717810844906442, MemAllocated=2.28GB, MaxMemAllocated=13.03GB
[2022-11-22 06:24:00,708] [INFO] [logging.py:68:log_dist] [Rank 0] step=298, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:24:00,742] [INFO] [timer.py:198:stop] 0/596, RunningAvgSamplesPerSec=1.112609388622239, CurrSamplesPerSec=0.8630712429722357, MemAllocated=2.28GB, MaxMemAllocated=13.08GB
[2022-11-22 06:24:04,896] [INFO] [timer.py:198:stop] 0/598, RunningAvgSamplesPerSec=1.1120447148079817, CurrSamplesPerSec=0.8599926247752396, MemAllocated=2.28GB, MaxMemAllocated=13.08GB
[2022-11-22 06:24:08,980] [INFO] [logging.py:68:log_dist] [Rank 0] step=300, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:24:09,014] [INFO] [timer.py:198:stop] 0/600, RunningAvgSamplesPerSec=1.1115201670357395, CurrSamplesPerSec=0.8680279271985549, MemAllocated=2.28GB, MaxMemAllocated=13.08GB
[2022-11-22 06:24:13,122] [INFO] [timer.py:198:stop] 0/602, RunningAvgSamplesPerSec=1.1110103744140263, CurrSamplesPerSec=0.87207717302803, MemAllocated=2.28GB, MaxMemAllocated=13.08GB
[2022-11-22 06:24:17,242] [INFO] [logging.py:68:log_dist] [Rank 0] step=302, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:24:17,276] [INFO] [timer.py:198:stop] 0/604, RunningAvgSamplesPerSec=1.110458109386929, CurrSamplesPerSec=0.8632026840899958, MemAllocated=2.28GB, MaxMemAllocated=13.08GB
[2022-11-22 06:24:21,404] [INFO] [timer.py:198:stop] 0/606, RunningAvgSamplesPerSec=1.109935648100091, CurrSamplesPerSec=0.8635169728285687, MemAllocated=2.28GB, MaxMemAllocated=13.08GB
[2022-11-22 06:24:25,519] [INFO] [logging.py:68:log_dist] [Rank 0] step=304, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:24:25,553] [INFO] [timer.py:198:stop] 0/608, RunningAvgSamplesPerSec=1.1093957743219645, CurrSamplesPerSec=0.8615362621115229, MemAllocated=2.28GB, MaxMemAllocated=13.08GB
[2022-11-22 06:24:29,635] [INFO] [timer.py:198:stop] 0/610, RunningAvgSamplesPerSec=1.1089295338831096, CurrSamplesPerSec=0.8829702870666438, MemAllocated=2.28GB, MaxMemAllocated=13.13GB
[2022-11-22 06:24:33,754] [INFO] [logging.py:68:log_dist] [Rank 0] step=306, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:24:33,787] [INFO] [timer.py:198:stop] 0/612, RunningAvgSamplesPerSec=1.1083923337969745, CurrSamplesPerSec=0.856859300989137, MemAllocated=2.28GB, MaxMemAllocated=13.13GB
[2022-11-22 06:24:37,890] [INFO] [timer.py:198:stop] 0/614, RunningAvgSamplesPerSec=1.1079101653371337, CurrSamplesPerSec=0.8725018539840635, MemAllocated=2.28GB, MaxMemAllocated=13.13GB
[2022-11-22 06:24:41,984] [INFO] [logging.py:68:log_dist] [Rank 0] step=308, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:24:42,011] [INFO] [timer.py:198:stop] 0/616, RunningAvgSamplesPerSec=1.1074132756249646, CurrSamplesPerSec=0.8661975619565683, MemAllocated=2.28GB, MaxMemAllocated=13.13GB
[2022-11-22 06:24:46,334] [INFO] [timer.py:198:stop] 0/618, RunningAvgSamplesPerSec=1.1067164800423444, CurrSamplesPerSec=0.7991956794733541, MemAllocated=2.28GB, MaxMemAllocated=13.13GB
[2022-11-22 06:24:50,299] [INFO] [logging.py:68:log_dist] [Rank 0] step=310, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:24:50,333] [INFO] [timer.py:198:stop] 0/620, RunningAvgSamplesPerSec=1.1063494173133956, CurrSamplesPerSec=0.9191915207331259, MemAllocated=2.28GB, MaxMemAllocated=13.13GB
[2022-11-22 06:24:54,527] [INFO] [timer.py:198:stop] 0/622, RunningAvgSamplesPerSec=1.1057928541652384, CurrSamplesPerSec=0.8505948408895555, MemAllocated=2.28GB, MaxMemAllocated=13.18GB
[2022-11-22 06:24:58,514] [INFO] [logging.py:68:log_dist] [Rank 0] step=312, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:24:58,541] [INFO] [timer.py:198:stop] 0/624, RunningAvgSamplesPerSec=1.105418081723811, CurrSamplesPerSec=0.916684770279361, MemAllocated=2.28GB, MaxMemAllocated=13.18GB
[2022-11-22 06:25:02,606] [INFO] [timer.py:198:stop] 0/626, RunningAvgSamplesPerSec=1.1049941020016893, CurrSamplesPerSec=0.8997172231127337, MemAllocated=2.28GB, MaxMemAllocated=13.18GB
[2022-11-22 06:25:06,690] [INFO] [logging.py:68:log_dist] [Rank 0] step=314, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:25:06,724] [INFO] [timer.py:198:stop] 0/628, RunningAvgSamplesPerSec=1.1045219934982222, CurrSamplesPerSec=0.8764283765017203, MemAllocated=2.28GB, MaxMemAllocated=13.18GB
[2022-11-22 06:25:10,928] [INFO] [timer.py:198:stop] 0/630, RunningAvgSamplesPerSec=1.1039693409273899, CurrSamplesPerSec=0.8465727390234077, MemAllocated=2.28GB, MaxMemAllocated=13.18GB
[2022-11-22 06:25:15,073] [INFO] [logging.py:68:log_dist] [Rank 0] step=316, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:25:15,105] [INFO] [timer.py:198:stop] 0/632, RunningAvgSamplesPerSec=1.1034480590601863, CurrSamplesPerSec=0.8545445117882025, MemAllocated=2.28GB, MaxMemAllocated=13.18GB
[2022-11-22 06:25:19,202] [INFO] [timer.py:198:stop] 0/634, RunningAvgSamplesPerSec=1.1030066113355086, CurrSamplesPerSec=0.8902892487428813, MemAllocated=2.28GB, MaxMemAllocated=13.23GB
[2022-11-22 06:25:23,238] [INFO] [logging.py:68:log_dist] [Rank 0] step=318, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:25:23,272] [INFO] [timer.py:198:stop] 0/636, RunningAvgSamplesPerSec=1.10259458361986, CurrSamplesPerSec=0.8973054441463032, MemAllocated=2.28GB, MaxMemAllocated=13.23GB
[2022-11-22 06:25:27,427] [INFO] [timer.py:198:stop] 0/638, RunningAvgSamplesPerSec=1.10210664450428, CurrSamplesPerSec=0.8645203697380852, MemAllocated=2.28GB, MaxMemAllocated=13.23GB
[2022-11-22 06:25:31,588] [INFO] [logging.py:68:log_dist] [Rank 0] step=320, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:25:31,622] [INFO] [timer.py:198:stop] 0/640, RunningAvgSamplesPerSec=1.1015818146948197, CurrSamplesPerSec=0.8550993068570772, MemAllocated=2.28GB, MaxMemAllocated=13.23GB
[2022-11-22 06:25:35,746] [INFO] [timer.py:198:stop] 0/642, RunningAvgSamplesPerSec=1.1011289318989812, CurrSamplesPerSec=0.8781826579661558, MemAllocated=2.28GB, MaxMemAllocated=13.23GB
[2022-11-22 06:25:39,905] [INFO] [logging.py:68:log_dist] [Rank 0] step=322, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:25:39,939] [INFO] [timer.py:198:stop] 0/644, RunningAvgSamplesPerSec=1.100613855401166, CurrSamplesPerSec=0.8520282144314668, MemAllocated=2.28GB, MaxMemAllocated=13.23GB
[2022-11-22 06:25:44,133] [INFO] [timer.py:198:stop] 0/646, RunningAvgSamplesPerSec=1.1001002254005983, CurrSamplesPerSec=0.8528715174268328, MemAllocated=2.28GB, MaxMemAllocated=13.29GB
[2022-11-22 06:25:48,285] [INFO] [logging.py:68:log_dist] [Rank 0] step=324, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:25:48,318] [INFO] [timer.py:198:stop] 0/648, RunningAvgSamplesPerSec=1.0995963245465616, CurrSamplesPerSec=0.8546293960608393, MemAllocated=2.28GB, MaxMemAllocated=13.29GB
[2022-11-22 06:25:52,478] [INFO] [timer.py:198:stop] 0/650, RunningAvgSamplesPerSec=1.0991229911769693, CurrSamplesPerSec=0.8676247288222807, MemAllocated=2.28GB, MaxMemAllocated=13.29GB
[2022-11-22 06:25:56,521] [INFO] [logging.py:68:log_dist] [Rank 0] step=326, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:25:56,560] [INFO] [timer.py:198:stop] 0/652, RunningAvgSamplesPerSec=1.0987242449800978, CurrSamplesPerSec=0.8950524620854641, MemAllocated=2.28GB, MaxMemAllocated=13.29GB
[2022-11-22 06:26:00,776] [INFO] [timer.py:198:stop] 0/654, RunningAvgSamplesPerSec=1.0982053014917734, CurrSamplesPerSec=0.8461983551774144, MemAllocated=2.28GB, MaxMemAllocated=13.29GB
[2022-11-22 06:26:04,967] [INFO] [logging.py:68:log_dist] [Rank 0] step=328, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:26:05,005] [INFO] [timer.py:198:stop] 0/656, RunningAvgSamplesPerSec=1.0976755842239407, CurrSamplesPerSec=0.8390992720131061, MemAllocated=2.28GB, MaxMemAllocated=13.29GB
[2022-11-22 06:26:09,216] [INFO] [timer.py:198:stop] 0/658, RunningAvgSamplesPerSec=1.0971651833762852, CurrSamplesPerSec=0.8506283069353124, MemAllocated=2.28GB, MaxMemAllocated=13.32GB
[2022-11-22 06:26:13,402] [INFO] [logging.py:68:log_dist] [Rank 0] step=330, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:26:13,436] [INFO] [timer.py:198:stop] 0/660, RunningAvgSamplesPerSec=1.0966522851518627, CurrSamplesPerSec=0.8463776491778786, MemAllocated=2.28GB, MaxMemAllocated=13.32GB
[2022-11-22 06:26:17,602] [INFO] [timer.py:198:stop] 0/662, RunningAvgSamplesPerSec=1.0961925919399853, CurrSamplesPerSec=0.8624942640782884, MemAllocated=2.28GB, MaxMemAllocated=13.32GB
[2022-11-22 06:26:21,812] [INFO] [logging.py:68:log_dist] [Rank 0] step=332, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:26:21,847] [INFO] [timer.py:198:stop] 0/664, RunningAvgSamplesPerSec=1.0956646029385948, CurrSamplesPerSec=0.8368952677741057, MemAllocated=2.28GB, MaxMemAllocated=13.32GB
[2022-11-22 06:26:26,049] [INFO] [timer.py:198:stop] 0/666, RunningAvgSamplesPerSec=1.095178234529722, CurrSamplesPerSec=0.8470488827297958, MemAllocated=2.28GB, MaxMemAllocated=13.32GB
[2022-11-22 06:26:30,131] [INFO] [logging.py:68:log_dist] [Rank 0] step=334, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:26:30,167] [INFO] [timer.py:198:stop] 0/668, RunningAvgSamplesPerSec=1.0947708443161865, CurrSamplesPerSec=0.8841079414604451, MemAllocated=2.28GB, MaxMemAllocated=13.32GB
[2022-11-22 06:26:34,434] [INFO] [timer.py:198:stop] 0/670, RunningAvgSamplesPerSec=1.094234248825584, CurrSamplesPerSec=0.8308851336025491, MemAllocated=2.28GB, MaxMemAllocated=13.39GB
[2022-11-22 06:26:38,617] [INFO] [logging.py:68:log_dist] [Rank 0] step=336, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:26:38,651] [INFO] [timer.py:198:stop] 0/672, RunningAvgSamplesPerSec=1.0937447461235739, CurrSamplesPerSec=0.8516801188123396, MemAllocated=2.28GB, MaxMemAllocated=13.39GB
[2022-11-22 06:26:42,871] [INFO] [timer.py:198:stop] 0/674, RunningAvgSamplesPerSec=1.0932567752108158, CurrSamplesPerSec=0.8505397311564555, MemAllocated=2.28GB, MaxMemAllocated=13.39GB
[2022-11-22 06:26:47,070] [INFO] [logging.py:68:log_dist] [Rank 0] step=338, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:26:47,104] [INFO] [timer.py:198:stop] 0/676, RunningAvgSamplesPerSec=1.0927603522815104, CurrSamplesPerSec=0.8430254299263793, MemAllocated=2.28GB, MaxMemAllocated=13.39GB
[2022-11-22 06:26:51,334] [INFO] [timer.py:198:stop] 0/678, RunningAvgSamplesPerSec=1.0922670209600096, CurrSamplesPerSec=0.8482919401319996, MemAllocated=2.28GB, MaxMemAllocated=13.39GB
[2022-11-22 06:26:55,554] [INFO] [logging.py:68:log_dist] [Rank 0] step=340, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:26:55,593] [INFO] [timer.py:198:stop] 0/680, RunningAvgSamplesPerSec=1.0917551628593323, CurrSamplesPerSec=0.8371954508092503, MemAllocated=2.28GB, MaxMemAllocated=13.39GB
[2022-11-22 06:26:59,878] [INFO] [timer.py:198:stop] 0/682, RunningAvgSamplesPerSec=1.091224140785202, CurrSamplesPerSec=0.8322218335450775, MemAllocated=2.28GB, MaxMemAllocated=13.42GB
[2022-11-22 06:27:04,079] [INFO] [logging.py:68:log_dist] [Rank 0] step=342, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:27:04,112] [INFO] [timer.py:198:stop] 0/684, RunningAvgSamplesPerSec=1.090739206956397, CurrSamplesPerSec=0.8489640666681982, MemAllocated=2.28GB, MaxMemAllocated=13.42GB
[2022-11-22 06:27:08,380] [INFO] [timer.py:198:stop] 0/686, RunningAvgSamplesPerSec=1.090230204260009, CurrSamplesPerSec=0.8368784859303767, MemAllocated=2.28GB, MaxMemAllocated=13.42GB
[2022-11-22 06:27:12,608] [INFO] [logging.py:68:log_dist] [Rank 0] step=344, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:27:12,637] [INFO] [timer.py:198:stop] 0/688, RunningAvgSamplesPerSec=1.0897329810184488, CurrSamplesPerSec=0.8387143604726615, MemAllocated=2.28GB, MaxMemAllocated=13.42GB
[2022-11-22 06:27:16,889] [INFO] [timer.py:198:stop] 0/690, RunningAvgSamplesPerSec=1.089243519911164, CurrSamplesPerSec=0.8426705133910409, MemAllocated=2.28GB, MaxMemAllocated=13.42GB
[2022-11-22 06:27:21,083] [INFO] [logging.py:68:log_dist] [Rank 0] step=346, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:27:21,117] [INFO] [timer.py:198:stop] 0/692, RunningAvgSamplesPerSec=1.0887781179832894, CurrSamplesPerSec=0.8469275306511934, MemAllocated=2.28GB, MaxMemAllocated=13.42GB
[2022-11-22 06:27:25,380] [INFO] [timer.py:198:stop] 0/694, RunningAvgSamplesPerSec=1.0882855305162578, CurrSamplesPerSec=0.8397991075428576, MemAllocated=2.28GB, MaxMemAllocated=13.49GB
[2022-11-22 06:27:29,590] [INFO] [logging.py:68:log_dist] [Rank 0] step=348, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:27:29,625] [INFO] [timer.py:198:stop] 0/696, RunningAvgSamplesPerSec=1.0878118244530457, CurrSamplesPerSec=0.8457993146779607, MemAllocated=2.28GB, MaxMemAllocated=13.49GB
[2022-11-22 06:27:33,908] [INFO] [timer.py:198:stop] 0/698, RunningAvgSamplesPerSec=1.0873095815039715, CurrSamplesPerSec=0.8348784298894274, MemAllocated=2.28GB, MaxMemAllocated=13.49GB
[2022-11-22 06:27:38,111] [INFO] [logging.py:68:log_dist] [Rank 0] step=350, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:27:38,136] [INFO] [timer.py:198:stop] 0/700, RunningAvgSamplesPerSec=1.0868569026510875, CurrSamplesPerSec=0.8531103881238719, MemAllocated=2.28GB, MaxMemAllocated=13.49GB
[2022-11-22 06:27:42,359] [INFO] [timer.py:198:stop] 0/702, RunningAvgSamplesPerSec=1.0864108652193323, CurrSamplesPerSec=0.8574195606482758, MemAllocated=2.28GB, MaxMemAllocated=13.49GB
[2022-11-22 06:27:46,617] [INFO] [logging.py:68:log_dist] [Rank 0] step=352, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:27:46,651] [INFO] [timer.py:198:stop] 0/704, RunningAvgSamplesPerSec=1.0859108938686997, CurrSamplesPerSec=0.833146249872127, MemAllocated=2.28GB, MaxMemAllocated=13.49GB
[2022-11-22 06:27:50,791] [INFO] [timer.py:198:stop] 0/706, RunningAvgSamplesPerSec=1.0855402610939764, CurrSamplesPerSec=0.890151224543048, MemAllocated=2.28GB, MaxMemAllocated=13.53GB
[2022-11-22 06:27:55,044] [INFO] [logging.py:68:log_dist] [Rank 0] step=354, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:27:55,078] [INFO] [timer.py:198:stop] 0/708, RunningAvgSamplesPerSec=1.085049080906255, CurrSamplesPerSec=0.8350709141631619, MemAllocated=2.28GB, MaxMemAllocated=13.53GB
[2022-11-22 06:27:59,384] [INFO] [timer.py:198:stop] 0/710, RunningAvgSamplesPerSec=1.084546135443692, CurrSamplesPerSec=0.8315231074902629, MemAllocated=2.28GB, MaxMemAllocated=13.53GB
[2022-11-22 06:28:03,612] [INFO] [logging.py:68:log_dist] [Rank 0] step=356, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:28:03,647] [INFO] [timer.py:198:stop] 0/712, RunningAvgSamplesPerSec=1.0840819298083348, CurrSamplesPerSec=0.8430514400984414, MemAllocated=2.28GB, MaxMemAllocated=13.53GB
[2022-11-22 06:28:07,932] [INFO] [timer.py:198:stop] 0/714, RunningAvgSamplesPerSec=1.0836022371508427, CurrSamplesPerSec=0.8354147975017849, MemAllocated=2.28GB, MaxMemAllocated=13.53GB
[2022-11-22 06:28:12,248] [INFO] [logging.py:68:log_dist] [Rank 0] step=358, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:28:12,283] [INFO] [timer.py:198:stop] 0/716, RunningAvgSamplesPerSec=1.083068392049313, CurrSamplesPerSec=0.8156153545866045, MemAllocated=2.28GB, MaxMemAllocated=13.53GB
[2022-11-22 06:28:16,587] [INFO] [timer.py:198:stop] 0/718, RunningAvgSamplesPerSec=1.0825771015521566, CurrSamplesPerSec=0.833239350720365, MemAllocated=2.28GB, MaxMemAllocated=13.6GB
[2022-11-22 06:28:20,847] [INFO] [logging.py:68:log_dist] [Rank 0] step=360, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:28:20,881] [INFO] [timer.py:198:stop] 0/720, RunningAvgSamplesPerSec=1.082099587646473, CurrSamplesPerSec=0.8377218333953157, MemAllocated=2.28GB, MaxMemAllocated=13.6GB
[2022-11-22 06:28:25,174] [INFO] [timer.py:198:stop] 0/722, RunningAvgSamplesPerSec=1.0816269818034137, CurrSamplesPerSec=0.8382216559873097, MemAllocated=2.28GB, MaxMemAllocated=13.6GB
[2022-11-22 06:28:29,404] [INFO] [logging.py:68:log_dist] [Rank 0] step=362, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:28:29,436] [INFO] [timer.py:198:stop] 0/724, RunningAvgSamplesPerSec=1.0811813310299025, CurrSamplesPerSec=0.8522455723880257, MemAllocated=2.28GB, MaxMemAllocated=13.6GB
[2022-11-22 06:28:33,752] [INFO] [timer.py:198:stop] 0/726, RunningAvgSamplesPerSec=1.0806941714415506, CurrSamplesPerSec=0.8309301533375009, MemAllocated=2.28GB, MaxMemAllocated=13.6GB
[2022-11-22 06:28:38,044] [INFO] [logging.py:68:log_dist] [Rank 0] step=364, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:28:38,078] [INFO] [timer.py:198:stop] 0/728, RunningAvgSamplesPerSec=1.0802039937113606, CurrSamplesPerSec=0.8295630572542939, MemAllocated=2.28GB, MaxMemAllocated=13.6GB
[2022-11-22 06:28:42,359] [INFO] [timer.py:198:stop] 0/730, RunningAvgSamplesPerSec=1.0797524767491535, CurrSamplesPerSec=0.8411385189955881, MemAllocated=2.28GB, MaxMemAllocated=13.64GB
[2022-11-22 06:28:46,613] [INFO] [logging.py:68:log_dist] [Rank 0] step=366, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:28:46,646] [INFO] [timer.py:198:stop] 0/732, RunningAvgSamplesPerSec=1.0792984362369813, CurrSamplesPerSec=0.8467332174155998, MemAllocated=2.28GB, MaxMemAllocated=13.64GB
[2022-11-22 06:28:50,956] [INFO] [timer.py:198:stop] 0/734, RunningAvgSamplesPerSec=1.0788290617535075, CurrSamplesPerSec=0.8314776114017967, MemAllocated=2.28GB, MaxMemAllocated=13.64GB
[2022-11-22 06:28:55,240] [INFO] [logging.py:68:log_dist] [Rank 0] step=368, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:28:55,273] [INFO] [timer.py:198:stop] 0/736, RunningAvgSamplesPerSec=1.0783565200672525, CurrSamplesPerSec=0.8335451989120182, MemAllocated=2.28GB, MaxMemAllocated=13.64GB
[2022-11-22 06:28:59,613] [INFO] [timer.py:198:stop] 0/738, RunningAvgSamplesPerSec=1.0778694416089194, CurrSamplesPerSec=0.8240303953625029, MemAllocated=2.28GB, MaxMemAllocated=13.64GB
[2022-11-22 06:29:03,888] [INFO] [logging.py:68:log_dist] [Rank 0] step=370, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:29:03,919] [INFO] [timer.py:198:stop] 0/740, RunningAvgSamplesPerSec=1.077413140260555, CurrSamplesPerSec=0.8327048627610663, MemAllocated=2.28GB, MaxMemAllocated=13.64GB
[2022-11-22 06:29:08,270] [INFO] [timer.py:198:stop] 0/742, RunningAvgSamplesPerSec=1.0769222224678658, CurrSamplesPerSec=0.8193037731439227, MemAllocated=2.28GB, MaxMemAllocated=13.68GB
[2022-11-22 06:29:12,560] [INFO] [logging.py:68:log_dist] [Rank 0] step=372, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:29:12,593] [INFO] [timer.py:198:stop] 0/744, RunningAvgSamplesPerSec=1.0764572313412222, CurrSamplesPerSec=0.831243121783353, MemAllocated=2.28GB, MaxMemAllocated=13.68GB
[2022-11-22 06:29:16,984] [INFO] [timer.py:198:stop] 0/746, RunningAvgSamplesPerSec=1.0759435641983015, CurrSamplesPerSec=0.8106414000930798, MemAllocated=2.28GB, MaxMemAllocated=13.68GB
[2022-11-22 06:29:21,337] [INFO] [logging.py:68:log_dist] [Rank 0] step=374, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:29:21,362] [INFO] [timer.py:198:stop] 0/748, RunningAvgSamplesPerSec=1.075442290422224, CurrSamplesPerSec=0.8128404758241089, MemAllocated=2.28GB, MaxMemAllocated=13.68GB
[2022-11-22 06:29:25,711] [INFO] [timer.py:198:stop] 0/750, RunningAvgSamplesPerSec=1.0749668513490813, CurrSamplesPerSec=0.8263400134817236, MemAllocated=2.28GB, MaxMemAllocated=13.68GB
[2022-11-22 06:29:30,030] [INFO] [logging.py:68:log_dist] [Rank 0] step=376, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:29:30,061] [INFO] [timer.py:198:stop] 0/752, RunningAvgSamplesPerSec=1.074494273577684, CurrSamplesPerSec=0.8219140017716705, MemAllocated=2.28GB, MaxMemAllocated=13.68GB
[2022-11-22 06:29:34,390] [INFO] [timer.py:198:stop] 0/754, RunningAvgSamplesPerSec=1.0740399111173708, CurrSamplesPerSec=0.8329639152583203, MemAllocated=2.28GB, MaxMemAllocated=13.73GB
[2022-11-22 06:29:38,689] [INFO] [logging.py:68:log_dist] [Rank 0] step=378, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:29:38,723] [INFO] [timer.py:198:stop] 0/756, RunningAvgSamplesPerSec=1.0735826402511794, CurrSamplesPerSec=0.8297136221723608, MemAllocated=2.28GB, MaxMemAllocated=13.73GB
[2022-11-22 06:29:43,044] [INFO] [timer.py:198:stop] 0/758, RunningAvgSamplesPerSec=1.0731391214516748, CurrSamplesPerSec=0.8345002026411191, MemAllocated=2.28GB, MaxMemAllocated=13.73GB
[2022-11-22 06:29:47,339] [INFO] [logging.py:68:log_dist] [Rank 0] step=380, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:29:47,373] [INFO] [timer.py:198:stop] 0/760, RunningAvgSamplesPerSec=1.0726935571073328, CurrSamplesPerSec=0.8323251333553537, MemAllocated=2.28GB, MaxMemAllocated=13.73GB
[2022-11-22 06:29:51,651] [INFO] [timer.py:198:stop] 0/762, RunningAvgSamplesPerSec=1.0722887357809525, CurrSamplesPerSec=0.8506082959934771, MemAllocated=2.28GB, MaxMemAllocated=13.73GB
[2022-11-22 06:29:55,966] [INFO] [logging.py:68:log_dist] [Rank 0] step=382, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:29:56,001] [INFO] [timer.py:198:stop] 0/764, RunningAvgSamplesPerSec=1.0718326086455678, CurrSamplesPerSec=0.828600734268, MemAllocated=2.28GB, MaxMemAllocated=13.73GB
[2022-11-22 06:30:00,378] [INFO] [timer.py:198:stop] 0/766, RunningAvgSamplesPerSec=1.0713590668688908, CurrSamplesPerSec=0.8155458924714373, MemAllocated=2.28GB, MaxMemAllocated=13.79GB
[2022-11-22 06:30:04,712] [INFO] [logging.py:68:log_dist] [Rank 0] step=384, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:30:04,746] [INFO] [timer.py:198:stop] 0/768, RunningAvgSamplesPerSec=1.0708937549145838, CurrSamplesPerSec=0.8176660776024665, MemAllocated=2.28GB, MaxMemAllocated=13.79GB
[2022-11-22 06:30:09,135] [INFO] [timer.py:198:stop] 0/770, RunningAvgSamplesPerSec=1.0704163049333992, CurrSamplesPerSec=0.8118006432579608, MemAllocated=2.28GB, MaxMemAllocated=13.79GB
[2022-11-22 06:30:13,445] [INFO] [logging.py:68:log_dist] [Rank 0] step=386, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:30:13,479] [INFO] [timer.py:198:stop] 0/772, RunningAvgSamplesPerSec=1.0699745912042382, CurrSamplesPerSec=0.8262561793582717, MemAllocated=2.28GB, MaxMemAllocated=13.79GB
[2022-11-22 06:30:17,891] [INFO] [timer.py:198:stop] 0/774, RunningAvgSamplesPerSec=1.069486443966955, CurrSamplesPerSec=0.8059340423271091, MemAllocated=2.28GB, MaxMemAllocated=13.79GB
[2022-11-22 06:30:22,226] [INFO] [logging.py:68:log_dist] [Rank 0] step=388, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:30:22,261] [INFO] [timer.py:198:stop] 0/776, RunningAvgSamplesPerSec=1.06903247049384, CurrSamplesPerSec=0.8220529411545655, MemAllocated=2.28GB, MaxMemAllocated=13.79GB
[2022-11-22 06:30:26,573] [INFO] [timer.py:198:stop] 0/778, RunningAvgSamplesPerSec=1.0686215193629514, CurrSamplesPerSec=0.8420771980657319, MemAllocated=2.28GB, MaxMemAllocated=13.83GB
[2022-11-22 06:30:30,902] [INFO] [logging.py:68:log_dist] [Rank 0] step=390, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:30:30,936] [INFO] [timer.py:198:stop] 0/780, RunningAvgSamplesPerSec=1.0681765240056835, CurrSamplesPerSec=0.8219734379153725, MemAllocated=2.28GB, MaxMemAllocated=13.83GB
[2022-11-22 06:30:35,292] [INFO] [timer.py:198:stop] 0/782, RunningAvgSamplesPerSec=1.0677407488264508, CurrSamplesPerSec=0.8224971372055813, MemAllocated=2.28GB, MaxMemAllocated=13.83GB
[2022-11-22 06:30:39,617] [INFO] [logging.py:68:log_dist] [Rank 0] step=392, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:30:39,652] [INFO] [timer.py:198:stop] 0/784, RunningAvgSamplesPerSec=1.0673028183073139, CurrSamplesPerSec=0.8236860322282588, MemAllocated=2.28GB, MaxMemAllocated=13.83GB
[2022-11-22 06:30:44,028] [INFO] [timer.py:198:stop] 0/786, RunningAvgSamplesPerSec=1.0668570099047536, CurrSamplesPerSec=0.8183841732772642, MemAllocated=2.28GB, MaxMemAllocated=13.83GB
[2022-11-22 06:30:48,375] [INFO] [logging.py:68:log_dist] [Rank 0] step=394, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:30:48,408] [INFO] [timer.py:198:stop] 0/788, RunningAvgSamplesPerSec=1.0664104587356056, CurrSamplesPerSec=0.81604984041584, MemAllocated=2.28GB, MaxMemAllocated=13.83GB
[2022-11-22 06:30:52,832] [INFO] [timer.py:198:stop] 0/790, RunningAvgSamplesPerSec=1.0659352540863252, CurrSamplesPerSec=0.812169892310089, MemAllocated=2.28GB, MaxMemAllocated=13.89GB
[2022-11-22 06:30:57,193] [INFO] [logging.py:68:log_dist] [Rank 0] step=396, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:30:57,228] [INFO] [timer.py:198:stop] 0/792, RunningAvgSamplesPerSec=1.0654824329215373, CurrSamplesPerSec=0.8179412172224406, MemAllocated=2.28GB, MaxMemAllocated=13.89GB
[2022-11-22 06:31:01,667] [INFO] [timer.py:198:stop] 0/794, RunningAvgSamplesPerSec=1.0650031998462597, CurrSamplesPerSec=0.8066882960396861, MemAllocated=2.28GB, MaxMemAllocated=13.89GB
[2022-11-22 06:31:06,053] [INFO] [logging.py:68:log_dist] [Rank 0] step=398, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:31:06,088] [INFO] [timer.py:198:stop] 0/796, RunningAvgSamplesPerSec=1.0645385796967297, CurrSamplesPerSec=0.8121816087698412, MemAllocated=2.28GB, MaxMemAllocated=13.89GB
[2022-11-22 06:31:10,500] [INFO] [timer.py:198:stop] 0/798, RunningAvgSamplesPerSec=1.0640830278416973, CurrSamplesPerSec=0.8174023534180689, MemAllocated=2.28GB, MaxMemAllocated=13.89GB
[2022-11-22 06:31:14,767] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:31:14,798] [INFO] [timer.py:198:stop] 0/800, RunningAvgSamplesPerSec=1.0637115553872782, CurrSamplesPerSec=0.8579509814941277, MemAllocated=2.28GB, MaxMemAllocated=13.89GB
Epoch: [0][ 800/1563]	Time  1.973 ( 1.887)	Loss 1.3169e+00 (2.5473e+00)	Acc@1  46.88 ( 16.41)	Acc@5  96.88 ( 61.66)
[2022-11-22 06:31:19,226] [INFO] [timer.py:198:stop] 0/802, RunningAvgSamplesPerSec=1.063249572088513, CurrSamplesPerSec=0.8169705639220471, MemAllocated=2.28GB, MaxMemAllocated=13.94GB
[2022-11-22 06:31:23,468] [INFO] [logging.py:68:log_dist] [Rank 0] step=402, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:31:23,503] [INFO] [timer.py:198:stop] 0/804, RunningAvgSamplesPerSec=1.0628963280100798, CurrSamplesPerSec=0.8635382180098904, MemAllocated=2.28GB, MaxMemAllocated=13.94GB
[2022-11-22 06:31:27,936] [INFO] [timer.py:198:stop] 0/806, RunningAvgSamplesPerSec=1.0624335355018764, CurrSamplesPerSec=0.8083508111590195, MemAllocated=2.28GB, MaxMemAllocated=13.94GB
[2022-11-22 06:31:32,267] [INFO] [logging.py:68:log_dist] [Rank 0] step=404, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:31:32,300] [INFO] [timer.py:198:stop] 0/808, RunningAvgSamplesPerSec=1.0620230651093567, CurrSamplesPerSec=0.8346982433303359, MemAllocated=2.28GB, MaxMemAllocated=13.94GB
[2022-11-22 06:31:36,739] [INFO] [timer.py:198:stop] 0/810, RunningAvgSamplesPerSec=1.061563484462848, CurrSamplesPerSec=0.8093000631050076, MemAllocated=2.28GB, MaxMemAllocated=13.94GB
[2022-11-22 06:31:41,133] [INFO] [logging.py:68:log_dist] [Rank 0] step=406, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:31:41,168] [INFO] [timer.py:198:stop] 0/812, RunningAvgSamplesPerSec=1.0611137461787552, CurrSamplesPerSec=0.8105329960028972, MemAllocated=2.28GB, MaxMemAllocated=13.94GB
[2022-11-22 06:31:45,597] [INFO] [timer.py:198:stop] 0/814, RunningAvgSamplesPerSec=1.0606666729681782, CurrSamplesPerSec=0.8135610841845703, MemAllocated=2.28GB, MaxMemAllocated=13.94GB
[2022-11-22 06:31:50,003] [INFO] [logging.py:68:log_dist] [Rank 0] step=408, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:31:50,042] [INFO] [timer.py:198:stop] 0/816, RunningAvgSamplesPerSec=1.0602116519305778, CurrSamplesPerSec=0.8100030638453025, MemAllocated=2.28GB, MaxMemAllocated=14.0GB
[2022-11-22 06:31:54,439] [INFO] [timer.py:198:stop] 0/818, RunningAvgSamplesPerSec=1.0597929041063372, CurrSamplesPerSec=0.8241536139287192, MemAllocated=2.28GB, MaxMemAllocated=14.0GB
[2022-11-22 06:31:58,858] [INFO] [logging.py:68:log_dist] [Rank 0] step=410, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:31:58,893] [INFO] [timer.py:198:stop] 0/820, RunningAvgSamplesPerSec=1.0593356227086617, CurrSamplesPerSec=0.8077618865900927, MemAllocated=2.28GB, MaxMemAllocated=14.0GB
[2022-11-22 06:32:03,368] [INFO] [timer.py:198:stop] 0/822, RunningAvgSamplesPerSec=1.0588671496815136, CurrSamplesPerSec=0.8007403543219711, MemAllocated=2.28GB, MaxMemAllocated=14.0GB
[2022-11-22 06:32:07,744] [INFO] [logging.py:68:log_dist] [Rank 0] step=412, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:32:07,782] [INFO] [timer.py:198:stop] 0/824, RunningAvgSamplesPerSec=1.0584435487424708, CurrSamplesPerSec=0.8203434337724839, MemAllocated=2.28GB, MaxMemAllocated=14.0GB
[2022-11-22 06:32:12,207] [INFO] [timer.py:198:stop] 0/826, RunningAvgSamplesPerSec=1.0580152028466054, CurrSamplesPerSec=0.8170790256269346, MemAllocated=2.28GB, MaxMemAllocated=14.0GB
[2022-11-22 06:32:16,631] [INFO] [logging.py:68:log_dist] [Rank 0] step=414, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:32:16,665] [INFO] [timer.py:198:stop] 0/828, RunningAvgSamplesPerSec=1.057566265030388, CurrSamplesPerSec=0.8073621315895267, MemAllocated=2.28GB, MaxMemAllocated=14.04GB
[2022-11-22 06:32:21,131] [INFO] [timer.py:198:stop] 0/830, RunningAvgSamplesPerSec=1.0571140930101444, CurrSamplesPerSec=0.8090387420262946, MemAllocated=2.28GB, MaxMemAllocated=14.04GB
[2022-11-22 06:32:25,563] [INFO] [logging.py:68:log_dist] [Rank 0] step=416, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:32:25,598] [INFO] [timer.py:198:stop] 0/832, RunningAvgSamplesPerSec=1.056663875900066, CurrSamplesPerSec=0.8101621819790997, MemAllocated=2.28GB, MaxMemAllocated=14.04GB
[2022-11-22 06:32:30,063] [INFO] [timer.py:198:stop] 0/834, RunningAvgSamplesPerSec=1.0562171144850674, CurrSamplesPerSec=0.8082943411934292, MemAllocated=2.28GB, MaxMemAllocated=14.04GB
[2022-11-22 06:32:34,538] [INFO] [logging.py:68:log_dist] [Rank 0] step=418, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:32:34,572] [INFO] [timer.py:198:stop] 0/836, RunningAvgSamplesPerSec=1.0557436391445605, CurrSamplesPerSec=0.7988408695383048, MemAllocated=2.28GB, MaxMemAllocated=14.04GB
[2022-11-22 06:32:39,045] [INFO] [timer.py:198:stop] 0/838, RunningAvgSamplesPerSec=1.0552965976846371, CurrSamplesPerSec=0.8060978400007918, MemAllocated=2.28GB, MaxMemAllocated=14.04GB
[2022-11-22 06:32:43,512] [INFO] [logging.py:68:log_dist] [Rank 0] step=420, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:32:43,547] [INFO] [timer.py:198:stop] 0/840, RunningAvgSamplesPerSec=1.054834447955558, CurrSamplesPerSec=0.7993148572981457, MemAllocated=2.28GB, MaxMemAllocated=14.09GB
[2022-11-22 06:32:47,993] [INFO] [timer.py:198:stop] 0/842, RunningAvgSamplesPerSec=1.0544109174932716, CurrSamplesPerSec=0.8172384680597683, MemAllocated=2.28GB, MaxMemAllocated=14.09GB
[2022-11-22 06:32:52,455] [INFO] [logging.py:68:log_dist] [Rank 0] step=422, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:32:52,489] [INFO] [timer.py:198:stop] 0/844, RunningAvgSamplesPerSec=1.0539558251946919, CurrSamplesPerSec=0.8007092463951605, MemAllocated=2.28GB, MaxMemAllocated=14.09GB
[2022-11-22 06:32:56,976] [INFO] [timer.py:198:stop] 0/846, RunningAvgSamplesPerSec=1.0535104615396678, CurrSamplesPerSec=0.8027041168425891, MemAllocated=2.28GB, MaxMemAllocated=14.09GB
[2022-11-22 06:33:01,470] [INFO] [logging.py:68:log_dist] [Rank 0] step=424, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:33:01,503] [INFO] [timer.py:198:stop] 0/848, RunningAvgSamplesPerSec=1.0530399602419098, CurrSamplesPerSec=0.791592515293529, MemAllocated=2.28GB, MaxMemAllocated=14.09GB
[2022-11-22 06:33:06,008] [INFO] [timer.py:198:stop] 0/850, RunningAvgSamplesPerSec=1.0525852970862877, CurrSamplesPerSec=0.795292075632976, MemAllocated=2.28GB, MaxMemAllocated=14.09GB
[2022-11-22 06:33:10,406] [INFO] [logging.py:68:log_dist] [Rank 0] step=426, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:33:10,438] [INFO] [timer.py:198:stop] 0/852, RunningAvgSamplesPerSec=1.0521863588522655, CurrSamplesPerSec=0.8250248040265531, MemAllocated=2.28GB, MaxMemAllocated=14.14GB
[2022-11-22 06:33:14,920] [INFO] [timer.py:198:stop] 0/854, RunningAvgSamplesPerSec=1.0517528707759252, CurrSamplesPerSec=0.8088872406322016, MemAllocated=2.28GB, MaxMemAllocated=14.14GB
[2022-11-22 06:33:19,261] [INFO] [logging.py:68:log_dist] [Rank 0] step=428, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:33:19,296] [INFO] [timer.py:198:stop] 0/856, RunningAvgSamplesPerSec=1.0513902653413114, CurrSamplesPerSec=0.8449483997355749, MemAllocated=2.28GB, MaxMemAllocated=14.14GB
[2022-11-22 06:33:23,796] [INFO] [timer.py:198:stop] 0/858, RunningAvgSamplesPerSec=1.0509511923589299, CurrSamplesPerSec=0.8002145961231516, MemAllocated=2.28GB, MaxMemAllocated=14.14GB
[2022-11-22 06:33:28,267] [INFO] [logging.py:68:log_dist] [Rank 0] step=430, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:33:28,303] [INFO] [timer.py:198:stop] 0/860, RunningAvgSamplesPerSec=1.0505099338445794, CurrSamplesPerSec=0.7996051449355625, MemAllocated=2.28GB, MaxMemAllocated=14.14GB
[2022-11-22 06:33:32,845] [INFO] [timer.py:198:stop] 0/862, RunningAvgSamplesPerSec=1.0500496324809196, CurrSamplesPerSec=0.7910144704231724, MemAllocated=2.28GB, MaxMemAllocated=14.14GB
[2022-11-22 06:33:37,411] [INFO] [logging.py:68:log_dist] [Rank 0] step=432, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:33:37,446] [INFO] [timer.py:198:stop] 0/864, RunningAvgSamplesPerSec=1.0495517265076686, CurrSamplesPerSec=0.7762676963343905, MemAllocated=2.28GB, MaxMemAllocated=14.2GB
[2022-11-22 06:33:41,946] [INFO] [timer.py:198:stop] 0/866, RunningAvgSamplesPerSec=1.0491219795010198, CurrSamplesPerSec=0.8020381843087458, MemAllocated=2.28GB, MaxMemAllocated=14.2GB
[2022-11-22 06:33:46,437] [INFO] [logging.py:68:log_dist] [Rank 0] step=434, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:33:46,472] [INFO] [timer.py:198:stop] 0/868, RunningAvgSamplesPerSec=1.048677507986658, CurrSamplesPerSec=0.7939189534506471, MemAllocated=2.28GB, MaxMemAllocated=14.2GB
[2022-11-22 06:33:51,010] [INFO] [timer.py:198:stop] 0/870, RunningAvgSamplesPerSec=1.0482292694877284, CurrSamplesPerSec=0.7924622913348054, MemAllocated=2.28GB, MaxMemAllocated=14.2GB
[2022-11-22 06:33:55,513] [INFO] [logging.py:68:log_dist] [Rank 0] step=436, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:33:55,548] [INFO] [timer.py:198:stop] 0/872, RunningAvgSamplesPerSec=1.047783494953037, CurrSamplesPerSec=0.794469273229794, MemAllocated=2.28GB, MaxMemAllocated=14.2GB
[2022-11-22 06:34:00,099] [INFO] [timer.py:198:stop] 0/874, RunningAvgSamplesPerSec=1.047331827440294, CurrSamplesPerSec=0.7926406551718794, MemAllocated=2.28GB, MaxMemAllocated=14.2GB
[2022-11-22 06:34:04,614] [INFO] [logging.py:68:log_dist] [Rank 0] step=438, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:34:04,648] [INFO] [timer.py:198:stop] 0/876, RunningAvgSamplesPerSec=1.0468828066047642, CurrSamplesPerSec=0.7932730629459296, MemAllocated=2.28GB, MaxMemAllocated=14.24GB
[2022-11-22 06:34:09,168] [INFO] [timer.py:198:stop] 0/878, RunningAvgSamplesPerSec=1.046453846400949, CurrSamplesPerSec=0.797883953584173, MemAllocated=2.28GB, MaxMemAllocated=14.24GB
[2022-11-22 06:34:13,664] [INFO] [logging.py:68:log_dist] [Rank 0] step=440, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:34:13,700] [INFO] [timer.py:198:stop] 0/880, RunningAvgSamplesPerSec=1.0460181714971808, CurrSamplesPerSec=0.7960198098534947, MemAllocated=2.28GB, MaxMemAllocated=14.24GB
[2022-11-22 06:34:18,245] [INFO] [timer.py:198:stop] 0/882, RunningAvgSamplesPerSec=1.0455807007577815, CurrSamplesPerSec=0.7962641704436165, MemAllocated=2.28GB, MaxMemAllocated=14.24GB
[2022-11-22 06:34:22,700] [INFO] [logging.py:68:log_dist] [Rank 0] step=442, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:34:22,734] [INFO] [timer.py:198:stop] 0/884, RunningAvgSamplesPerSec=1.045178727718728, CurrSamplesPerSec=0.8116144955762573, MemAllocated=2.28GB, MaxMemAllocated=14.24GB
[2022-11-22 06:34:27,236] [INFO] [timer.py:198:stop] 0/886, RunningAvgSamplesPerSec=1.0447704098950203, CurrSamplesPerSec=0.8076528515213592, MemAllocated=2.28GB, MaxMemAllocated=14.24GB
[2022-11-22 06:34:31,769] [INFO] [logging.py:68:log_dist] [Rank 0] step=444, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:34:31,801] [INFO] [timer.py:198:stop] 0/888, RunningAvgSamplesPerSec=1.0443254508772226, CurrSamplesPerSec=0.788704479428368, MemAllocated=2.28GB, MaxMemAllocated=14.3GB
[2022-11-22 06:34:36,350] [INFO] [timer.py:198:stop] 0/890, RunningAvgSamplesPerSec=1.043893499621319, CurrSamplesPerSec=0.7925526612977667, MemAllocated=2.28GB, MaxMemAllocated=14.3GB
[2022-11-22 06:34:40,891] [INFO] [logging.py:68:log_dist] [Rank 0] step=446, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:34:40,926] [INFO] [timer.py:198:stop] 0/892, RunningAvgSamplesPerSec=1.0434463097861228, CurrSamplesPerSec=0.7821528418024986, MemAllocated=2.28GB, MaxMemAllocated=14.3GB
[2022-11-22 06:34:45,476] [INFO] [timer.py:198:stop] 0/894, RunningAvgSamplesPerSec=1.0430175363581953, CurrSamplesPerSec=0.7948380582721504, MemAllocated=2.28GB, MaxMemAllocated=14.3GB
[2022-11-22 06:34:49,987] [INFO] [logging.py:68:log_dist] [Rank 0] step=448, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:34:50,022] [INFO] [timer.py:198:stop] 0/896, RunningAvgSamplesPerSec=1.042592790737991, CurrSamplesPerSec=0.7926861949927182, MemAllocated=2.28GB, MaxMemAllocated=14.3GB
[2022-11-22 06:34:54,572] [INFO] [timer.py:198:stop] 0/898, RunningAvgSamplesPerSec=1.0421685021909772, CurrSamplesPerSec=0.7901748855822469, MemAllocated=2.28GB, MaxMemAllocated=14.3GB
[2022-11-22 06:34:59,126] [INFO] [logging.py:68:log_dist] [Rank 0] step=450, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:34:59,160] [INFO] [timer.py:198:stop] 0/900, RunningAvgSamplesPerSec=1.0417241638616326, CurrSamplesPerSec=0.7874437914491568, MemAllocated=2.28GB, MaxMemAllocated=14.36GB
[2022-11-22 06:35:03,764] [INFO] [timer.py:198:stop] 0/902, RunningAvgSamplesPerSec=1.041270339985965, CurrSamplesPerSec=0.779704176320089, MemAllocated=2.28GB, MaxMemAllocated=14.36GB
[2022-11-22 06:35:08,298] [INFO] [logging.py:68:log_dist] [Rank 0] step=452, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:35:08,337] [INFO] [timer.py:198:stop] 0/904, RunningAvgSamplesPerSec=1.0408364328871837, CurrSamplesPerSec=0.7857981310263693, MemAllocated=2.28GB, MaxMemAllocated=14.36GB
[2022-11-22 06:35:12,893] [INFO] [timer.py:198:stop] 0/906, RunningAvgSamplesPerSec=1.040418878617311, CurrSamplesPerSec=0.796038014607966, MemAllocated=2.28GB, MaxMemAllocated=14.36GB
[2022-11-22 06:35:17,457] [INFO] [logging.py:68:log_dist] [Rank 0] step=454, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:35:17,490] [INFO] [timer.py:198:stop] 0/908, RunningAvgSamplesPerSec=1.0399777543403281, CurrSamplesPerSec=0.7837416598011713, MemAllocated=2.28GB, MaxMemAllocated=14.36GB
[2022-11-22 06:35:22,069] [INFO] [timer.py:198:stop] 0/910, RunningAvgSamplesPerSec=1.0395497214298577, CurrSamplesPerSec=0.7850876355600579, MemAllocated=2.28GB, MaxMemAllocated=14.36GB
[2022-11-22 06:35:26,685] [INFO] [logging.py:68:log_dist] [Rank 0] step=456, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:35:26,720] [INFO] [timer.py:198:stop] 0/912, RunningAvgSamplesPerSec=1.0390800563231204, CurrSamplesPerSec=0.7706183810213059, MemAllocated=2.28GB, MaxMemAllocated=14.41GB
[2022-11-22 06:35:31,316] [INFO] [timer.py:198:stop] 0/914, RunningAvgSamplesPerSec=1.0386469712830655, CurrSamplesPerSec=0.7877296615346187, MemAllocated=2.28GB, MaxMemAllocated=14.41GB
[2022-11-22 06:35:35,847] [INFO] [logging.py:68:log_dist] [Rank 0] step=458, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:35:35,880] [INFO] [timer.py:198:stop] 0/916, RunningAvgSamplesPerSec=1.0382344094459213, CurrSamplesPerSec=0.7954858973171176, MemAllocated=2.28GB, MaxMemAllocated=14.41GB
[2022-11-22 06:35:40,494] [INFO] [timer.py:198:stop] 0/918, RunningAvgSamplesPerSec=1.0377931553478947, CurrSamplesPerSec=0.7788993375285741, MemAllocated=2.28GB, MaxMemAllocated=14.41GB
[2022-11-22 06:35:45,053] [INFO] [logging.py:68:log_dist] [Rank 0] step=460, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:35:45,086] [INFO] [timer.py:198:stop] 0/920, RunningAvgSamplesPerSec=1.0373686880768656, CurrSamplesPerSec=0.7873190379148107, MemAllocated=2.28GB, MaxMemAllocated=14.41GB
[2022-11-22 06:35:49,725] [INFO] [timer.py:198:stop] 0/922, RunningAvgSamplesPerSec=1.0369194545946228, CurrSamplesPerSec=0.7743801761227191, MemAllocated=2.28GB, MaxMemAllocated=14.41GB
[2022-11-22 06:35:54,300] [INFO] [logging.py:68:log_dist] [Rank 0] step=462, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:35:54,331] [INFO] [timer.py:198:stop] 0/924, RunningAvgSamplesPerSec=1.0364923133473956, CurrSamplesPerSec=0.7831788220193607, MemAllocated=2.28GB, MaxMemAllocated=14.46GB
[2022-11-22 06:35:58,976] [INFO] [timer.py:198:stop] 0/926, RunningAvgSamplesPerSec=1.036042309412566, CurrSamplesPerSec=0.7760659656366837, MemAllocated=2.28GB, MaxMemAllocated=14.46GB
[2022-11-22 06:36:03,559] [INFO] [logging.py:68:log_dist] [Rank 0] step=464, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:36:03,595] [INFO] [timer.py:198:stop] 0/928, RunningAvgSamplesPerSec=1.0356110794894522, CurrSamplesPerSec=0.7796910591216359, MemAllocated=2.28GB, MaxMemAllocated=14.46GB
[2022-11-22 06:36:08,227] [INFO] [timer.py:198:stop] 0/930, RunningAvgSamplesPerSec=1.0351755268933338, CurrSamplesPerSec=0.7775988416582197, MemAllocated=2.28GB, MaxMemAllocated=14.46GB
[2022-11-22 06:36:12,817] [INFO] [logging.py:68:log_dist] [Rank 0] step=466, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:36:12,850] [INFO] [timer.py:198:stop] 0/932, RunningAvgSamplesPerSec=1.034746391122075, CurrSamplesPerSec=0.7790707069656392, MemAllocated=2.28GB, MaxMemAllocated=14.46GB
[2022-11-22 06:36:17,306] [INFO] [timer.py:198:stop] 0/934, RunningAvgSamplesPerSec=1.0344153542213352, CurrSamplesPerSec=0.8321888094392021, MemAllocated=2.28GB, MaxMemAllocated=14.46GB
[2022-11-22 06:36:21,935] [INFO] [logging.py:68:log_dist] [Rank 0] step=468, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:36:21,964] [INFO] [timer.py:198:stop] 0/936, RunningAvgSamplesPerSec=1.0339712529181464, CurrSamplesPerSec=0.7744789818241443, MemAllocated=2.28GB, MaxMemAllocated=14.51GB
[2022-11-22 06:36:26,559] [INFO] [timer.py:198:stop] 0/938, RunningAvgSamplesPerSec=1.0335638030896084, CurrSamplesPerSec=0.7904401739143873, MemAllocated=2.28GB, MaxMemAllocated=14.51GB
[2022-11-22 06:36:31,145] [INFO] [logging.py:68:log_dist] [Rank 0] step=470, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:36:31,179] [INFO] [timer.py:198:stop] 0/940, RunningAvgSamplesPerSec=1.0331447536292473, CurrSamplesPerSec=0.7834610178875432, MemAllocated=2.28GB, MaxMemAllocated=14.51GB
[2022-11-22 06:36:35,770] [INFO] [timer.py:198:stop] 0/942, RunningAvgSamplesPerSec=1.0327443480319543, CurrSamplesPerSec=0.792833411290895, MemAllocated=2.28GB, MaxMemAllocated=14.51GB
[2022-11-22 06:36:40,368] [INFO] [logging.py:68:log_dist] [Rank 0] step=472, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:36:40,404] [INFO] [timer.py:198:stop] 0/944, RunningAvgSamplesPerSec=1.0323212247878797, CurrSamplesPerSec=0.7747534392892882, MemAllocated=2.28GB, MaxMemAllocated=14.51GB
[2022-11-22 06:36:44,915] [INFO] [timer.py:198:stop] 0/946, RunningAvgSamplesPerSec=1.031970446169514, CurrSamplesPerSec=0.8172085330338548, MemAllocated=2.28GB, MaxMemAllocated=14.51GB
[2022-11-22 06:36:49,563] [INFO] [logging.py:68:log_dist] [Rank 0] step=474, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:36:49,597] [INFO] [timer.py:198:stop] 0/948, RunningAvgSamplesPerSec=1.0315267641257204, CurrSamplesPerSec=0.7701293012868434, MemAllocated=2.28GB, MaxMemAllocated=14.57GB
[2022-11-22 06:36:54,244] [INFO] [timer.py:198:stop] 0/950, RunningAvgSamplesPerSec=1.031102932426258, CurrSamplesPerSec=0.7771682515871131, MemAllocated=2.28GB, MaxMemAllocated=14.57GB
[2022-11-22 06:36:58,816] [INFO] [logging.py:68:log_dist] [Rank 0] step=476, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:36:58,851] [INFO] [timer.py:198:stop] 0/952, RunningAvgSamplesPerSec=1.0307044116922144, CurrSamplesPerSec=0.7923833935732805, MemAllocated=2.28GB, MaxMemAllocated=14.57GB
[2022-11-22 06:37:03,512] [INFO] [timer.py:198:stop] 0/954, RunningAvgSamplesPerSec=1.0302768268816729, CurrSamplesPerSec=0.7750464227289081, MemAllocated=2.28GB, MaxMemAllocated=14.57GB
[2022-11-22 06:37:08,160] [INFO] [logging.py:68:log_dist] [Rank 0] step=478, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:37:08,195] [INFO] [timer.py:198:stop] 0/956, RunningAvgSamplesPerSec=1.0298397390330583, CurrSamplesPerSec=0.771832404159128, MemAllocated=2.28GB, MaxMemAllocated=14.57GB
[2022-11-22 06:37:12,846] [INFO] [timer.py:198:stop] 0/958, RunningAvgSamplesPerSec=1.0294223499732695, CurrSamplesPerSec=0.7773016208362522, MemAllocated=2.28GB, MaxMemAllocated=14.57GB
[2022-11-22 06:37:17,490] [INFO] [logging.py:68:log_dist] [Rank 0] step=480, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:37:17,525] [INFO] [timer.py:198:stop] 0/960, RunningAvgSamplesPerSec=1.0289913998903013, CurrSamplesPerSec=0.7702333900621569, MemAllocated=2.28GB, MaxMemAllocated=14.63GB
[2022-11-22 06:37:22,203] [INFO] [timer.py:198:stop] 0/962, RunningAvgSamplesPerSec=1.0285644971769676, CurrSamplesPerSec=0.7750019563038856, MemAllocated=2.28GB, MaxMemAllocated=14.63GB
[2022-11-22 06:37:26,853] [INFO] [logging.py:68:log_dist] [Rank 0] step=482, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:37:26,888] [INFO] [timer.py:198:stop] 0/964, RunningAvgSamplesPerSec=1.0281331097023203, CurrSamplesPerSec=0.7703157193164889, MemAllocated=2.28GB, MaxMemAllocated=14.63GB
[2022-11-22 06:37:31,625] [INFO] [timer.py:198:stop] 0/966, RunningAvgSamplesPerSec=1.0276778155579829, CurrSamplesPerSec=0.7576672116633998, MemAllocated=2.28GB, MaxMemAllocated=14.63GB
[2022-11-22 06:37:36,267] [INFO] [logging.py:68:log_dist] [Rank 0] step=484, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:37:36,306] [INFO] [timer.py:198:stop] 0/968, RunningAvgSamplesPerSec=1.0272523990475093, CurrSamplesPerSec=0.7692985904826467, MemAllocated=2.28GB, MaxMemAllocated=14.63GB
[2022-11-22 06:37:40,982] [INFO] [timer.py:198:stop] 0/970, RunningAvgSamplesPerSec=1.026835319388039, CurrSamplesPerSec=0.7761404264539966, MemAllocated=2.28GB, MaxMemAllocated=14.63GB
[2022-11-22 06:37:45,575] [INFO] [logging.py:68:log_dist] [Rank 0] step=486, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:37:45,607] [INFO] [timer.py:198:stop] 0/972, RunningAvgSamplesPerSec=1.02644502166371, CurrSamplesPerSec=0.787123783415149, MemAllocated=2.28GB, MaxMemAllocated=14.67GB
[2022-11-22 06:37:50,331] [INFO] [timer.py:198:stop] 0/974, RunningAvgSamplesPerSec=1.0260048601031448, CurrSamplesPerSec=0.7609425642486327, MemAllocated=2.28GB, MaxMemAllocated=14.67GB
[2022-11-22 06:37:55,004] [INFO] [logging.py:68:log_dist] [Rank 0] step=488, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:37:55,038] [INFO] [timer.py:198:stop] 0/976, RunningAvgSamplesPerSec=1.025575301878522, CurrSamplesPerSec=0.7672518779067689, MemAllocated=2.28GB, MaxMemAllocated=14.67GB
[2022-11-22 06:37:59,623] [INFO] [timer.py:198:stop] 0/978, RunningAvgSamplesPerSec=1.025213574734845, CurrSamplesPerSec=0.8031916222883116, MemAllocated=2.28GB, MaxMemAllocated=14.67GB
[2022-11-22 06:38:04,300] [INFO] [logging.py:68:log_dist] [Rank 0] step=490, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:38:04,334] [INFO] [timer.py:198:stop] 0/980, RunningAvgSamplesPerSec=1.024786553600604, CurrSamplesPerSec=0.7679342400061812, MemAllocated=2.28GB, MaxMemAllocated=14.67GB
[2022-11-22 06:38:09,021] [INFO] [timer.py:198:stop] 0/982, RunningAvgSamplesPerSec=1.0243749147674641, CurrSamplesPerSec=0.7690455386261064, MemAllocated=2.28GB, MaxMemAllocated=14.67GB
[2022-11-22 06:38:13,696] [INFO] [logging.py:68:log_dist] [Rank 0] step=492, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:38:13,731] [INFO] [timer.py:198:stop] 0/984, RunningAvgSamplesPerSec=1.0239524108166416, CurrSamplesPerSec=0.7685447924328195, MemAllocated=2.28GB, MaxMemAllocated=14.73GB
[2022-11-22 06:38:17,932] [INFO] [timer.py:198:stop] 0/986, RunningAvgSamplesPerSec=1.0238032385263411, CurrSamplesPerSec=0.9525163890663404, MemAllocated=2.28GB, MaxMemAllocated=14.73GB
[2022-11-22 06:38:22,562] [INFO] [logging.py:68:log_dist] [Rank 0] step=494, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:38:22,597] [INFO] [timer.py:198:stop] 0/988, RunningAvgSamplesPerSec=1.0234062222973683, CurrSamplesPerSec=0.7679884454863396, MemAllocated=2.28GB, MaxMemAllocated=14.73GB
[2022-11-22 06:38:27,313] [INFO] [timer.py:198:stop] 0/990, RunningAvgSamplesPerSec=1.022985448999858, CurrSamplesPerSec=0.7672034598112111, MemAllocated=2.28GB, MaxMemAllocated=14.73GB
[2022-11-22 06:38:32,074] [INFO] [logging.py:68:log_dist] [Rank 0] step=496, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:38:32,108] [INFO] [timer.py:198:stop] 0/992, RunningAvgSamplesPerSec=1.0225255419171388, CurrSamplesPerSec=0.7502943314398749, MemAllocated=2.28GB, MaxMemAllocated=14.73GB
[2022-11-22 06:38:36,774] [INFO] [timer.py:198:stop] 0/994, RunningAvgSamplesPerSec=1.0221353195773382, CurrSamplesPerSec=0.781494638979465, MemAllocated=2.28GB, MaxMemAllocated=14.73GB
[2022-11-22 06:38:41,473] [INFO] [logging.py:68:log_dist] [Rank 0] step=498, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:38:41,506] [INFO] [timer.py:198:stop] 0/996, RunningAvgSamplesPerSec=1.0217129760882364, CurrSamplesPerSec=0.7658107273652142, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:38:46,241] [INFO] [timer.py:198:stop] 0/998, RunningAvgSamplesPerSec=1.0212907640023918, CurrSamplesPerSec=0.7606076586225331, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:38:50,943] [INFO] [logging.py:68:log_dist] [Rank 0] step=500, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:38:50,976] [INFO] [timer.py:198:stop] 0/1000, RunningAvgSamplesPerSec=1.020870540070592, CurrSamplesPerSec=0.7639928611735785, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:38:55,706] [INFO] [timer.py:198:stop] 0/1002, RunningAvgSamplesPerSec=1.0204547902044458, CurrSamplesPerSec=0.7636770259029613, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:00,331] [INFO] [logging.py:68:log_dist] [Rank 0] step=502, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:39:00,365] [INFO] [timer.py:198:stop] 0/1004, RunningAvgSamplesPerSec=1.02007830699618, CurrSamplesPerSec=0.7861934639893164, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:05,068] [INFO] [timer.py:198:stop] 0/1006, RunningAvgSamplesPerSec=1.0196801531283746, CurrSamplesPerSec=0.7708614892262271, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:09,781] [INFO] [logging.py:68:log_dist] [Rank 0] step=504, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:39:09,815] [INFO] [timer.py:198:stop] 0/1008, RunningAvgSamplesPerSec=1.0192627368531124, CurrSamplesPerSec=0.7631610262225248, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:14,445] [INFO] [timer.py:198:stop] 0/1010, RunningAvgSamplesPerSec=1.018904543215046, CurrSamplesPerSec=0.7894700534622971, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:19,135] [INFO] [logging.py:68:log_dist] [Rank 0] step=506, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:39:19,170] [INFO] [timer.py:198:stop] 0/1012, RunningAvgSamplesPerSec=1.0185008421632016, CurrSamplesPerSec=0.7647376824439055, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:23,858] [INFO] [timer.py:198:stop] 0/1014, RunningAvgSamplesPerSec=1.0181181167505562, CurrSamplesPerSec=0.7771837321701005, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:28,539] [INFO] [logging.py:68:log_dist] [Rank 0] step=508, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:39:28,573] [INFO] [timer.py:198:stop] 0/1016, RunningAvgSamplesPerSec=1.0177213020474378, CurrSamplesPerSec=0.7626759548555471, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:33,230] [INFO] [timer.py:198:stop] 0/1018, RunningAvgSamplesPerSec=1.0173576704359126, CurrSamplesPerSec=0.7826902514168205, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:37,941] [INFO] [logging.py:68:log_dist] [Rank 0] step=510, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:39:37,976] [INFO] [timer.py:198:stop] 0/1020, RunningAvgSamplesPerSec=1.0169507059863157, CurrSamplesPerSec=0.7595456963826587, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:42,643] [INFO] [timer.py:198:stop] 0/1022, RunningAvgSamplesPerSec=1.0165853303844639, CurrSamplesPerSec=0.7799957674256166, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:47,349] [INFO] [logging.py:68:log_dist] [Rank 0] step=512, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:39:47,383] [INFO] [timer.py:198:stop] 0/1024, RunningAvgSamplesPerSec=1.016186011381295, CurrSamplesPerSec=0.7630439864612261, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:52,090] [INFO] [timer.py:198:stop] 0/1026, RunningAvgSamplesPerSec=1.0158040453221462, CurrSamplesPerSec=0.7664926984709451, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:39:56,702] [INFO] [logging.py:68:log_dist] [Rank 0] step=514, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:39:56,734] [INFO] [timer.py:198:stop] 0/1028, RunningAvgSamplesPerSec=1.0154559788484123, CurrSamplesPerSec=0.7885988231288258, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:01,405] [INFO] [timer.py:198:stop] 0/1030, RunningAvgSamplesPerSec=1.0150960645690994, CurrSamplesPerSec=0.7812574390098979, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:06,012] [INFO] [logging.py:68:log_dist] [Rank 0] step=516, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:40:06,046] [INFO] [timer.py:198:stop] 0/1032, RunningAvgSamplesPerSec=1.0147517829915476, CurrSamplesPerSec=0.7870590893294233, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:10,760] [INFO] [timer.py:198:stop] 0/1034, RunningAvgSamplesPerSec=1.0143741505503514, CurrSamplesPerSec=0.7689155510881593, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:15,451] [INFO] [logging.py:68:log_dist] [Rank 0] step=518, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:40:15,487] [INFO] [timer.py:198:stop] 0/1036, RunningAvgSamplesPerSec=1.0139912483858187, CurrSamplesPerSec=0.763472265567157, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:20,165] [INFO] [timer.py:198:stop] 0/1038, RunningAvgSamplesPerSec=1.0136348129883572, CurrSamplesPerSec=0.7754811161200651, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:24,861] [INFO] [logging.py:68:log_dist] [Rank 0] step=520, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:40:24,895] [INFO] [timer.py:198:stop] 0/1040, RunningAvgSamplesPerSec=1.0132545240793853, CurrSamplesPerSec=0.7636049371837546, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:29,612] [INFO] [timer.py:198:stop] 0/1042, RunningAvgSamplesPerSec=1.0128803966642614, CurrSamplesPerSec=0.7681067257666753, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:34,124] [INFO] [logging.py:68:log_dist] [Rank 0] step=522, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:40:34,160] [INFO] [timer.py:198:stop] 0/1044, RunningAvgSamplesPerSec=1.012593036472642, CurrSamplesPerSec=0.8194705693354417, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:38,857] [INFO] [timer.py:198:stop] 0/1046, RunningAvgSamplesPerSec=1.012233356873671, CurrSamplesPerSec=0.7731682503423611, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:43,522] [INFO] [logging.py:68:log_dist] [Rank 0] step=524, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:40:43,557] [INFO] [timer.py:198:stop] 0/1048, RunningAvgSamplesPerSec=1.0118733005650131, CurrSamplesPerSec=0.7693642785880015, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:48,262] [INFO] [timer.py:198:stop] 0/1050, RunningAvgSamplesPerSec=1.0115126367957334, CurrSamplesPerSec=0.769497947236888, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:52,934] [INFO] [logging.py:68:log_dist] [Rank 0] step=526, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:40:52,970] [INFO] [timer.py:198:stop] 0/1052, RunningAvgSamplesPerSec=1.0111524257183158, CurrSamplesPerSec=0.7672457025053037, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:40:57,715] [INFO] [timer.py:198:stop] 0/1054, RunningAvgSamplesPerSec=1.0107760470802944, CurrSamplesPerSec=0.7635414102902048, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:02,357] [INFO] [logging.py:68:log_dist] [Rank 0] step=528, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:41:02,392] [INFO] [timer.py:198:stop] 0/1056, RunningAvgSamplesPerSec=1.0104336074251532, CurrSamplesPerSec=0.7771501796867407, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:07,129] [INFO] [timer.py:198:stop] 0/1058, RunningAvgSamplesPerSec=1.0100652217683617, CurrSamplesPerSec=0.7620971888755684, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:11,788] [INFO] [logging.py:68:log_dist] [Rank 0] step=530, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:41:11,823] [INFO] [timer.py:198:stop] 0/1060, RunningAvgSamplesPerSec=1.009718233848443, CurrSamplesPerSec=0.7713777437420217, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:16,550] [INFO] [timer.py:198:stop] 0/1062, RunningAvgSamplesPerSec=1.0093572218454163, CurrSamplesPerSec=0.7655896589001333, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:21,227] [INFO] [logging.py:68:log_dist] [Rank 0] step=532, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:41:21,260] [INFO] [timer.py:198:stop] 0/1064, RunningAvgSamplesPerSec=1.0090057334362827, CurrSamplesPerSec=0.7673229021693047, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:26,032] [INFO] [timer.py:198:stop] 0/1066, RunningAvgSamplesPerSec=1.0086267450967696, CurrSamplesPerSec=0.7546722775380539, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:30,725] [INFO] [logging.py:68:log_dist] [Rank 0] step=534, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:41:30,759] [INFO] [timer.py:198:stop] 0/1068, RunningAvgSamplesPerSec=1.008269799152603, CurrSamplesPerSec=0.762982704159255, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:35,490] [INFO] [timer.py:198:stop] 0/1070, RunningAvgSamplesPerSec=1.0079131536441863, CurrSamplesPerSec=0.7625777806140561, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:40,190] [INFO] [logging.py:68:log_dist] [Rank 0] step=536, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:41:40,225] [INFO] [timer.py:198:stop] 0/1072, RunningAvgSamplesPerSec=1.0075557490857758, CurrSamplesPerSec=0.762220448561663, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:44,915] [INFO] [timer.py:198:stop] 0/1074, RunningAvgSamplesPerSec=1.0072219694268785, CurrSamplesPerSec=0.7757596562268835, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:49,636] [INFO] [logging.py:68:log_dist] [Rank 0] step=538, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:41:49,675] [INFO] [timer.py:198:stop] 0/1076, RunningAvgSamplesPerSec=1.0068560287844304, CurrSamplesPerSec=0.7521176431876466, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:54,430] [INFO] [timer.py:198:stop] 0/1078, RunningAvgSamplesPerSec=1.006494037968211, CurrSamplesPerSec=0.7550172652228954, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:41:59,100] [INFO] [logging.py:68:log_dist] [Rank 0] step=540, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:41:59,134] [INFO] [timer.py:198:stop] 0/1080, RunningAvgSamplesPerSec=1.0061577516565583, CurrSamplesPerSec=0.7716702377285912, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:03,831] [INFO] [timer.py:198:stop] 0/1082, RunningAvgSamplesPerSec=1.005826065766487, CurrSamplesPerSec=0.7728393023502635, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:08,530] [INFO] [logging.py:68:log_dist] [Rank 0] step=542, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:42:08,565] [INFO] [timer.py:198:stop] 0/1084, RunningAvgSamplesPerSec=1.005478744223472, CurrSamplesPerSec=0.764904689734999, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:13,285] [INFO] [timer.py:198:stop] 0/1086, RunningAvgSamplesPerSec=1.005140021557347, CurrSamplesPerSec=0.7642129386777232, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:17,965] [INFO] [logging.py:68:log_dist] [Rank 0] step=544, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:42:17,998] [INFO] [timer.py:198:stop] 0/1088, RunningAvgSamplesPerSec=1.004806335885393, CurrSamplesPerSec=0.7698533759542512, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:22,732] [INFO] [timer.py:198:stop] 0/1090, RunningAvgSamplesPerSec=1.0044634833568447, CurrSamplesPerSec=0.7608226156542509, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:27,409] [INFO] [logging.py:68:log_dist] [Rank 0] step=546, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:42:27,446] [INFO] [timer.py:198:stop] 0/1092, RunningAvgSamplesPerSec=1.004130791758319, CurrSamplesPerSec=0.764904689734999, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:32,077] [INFO] [timer.py:198:stop] 0/1094, RunningAvgSamplesPerSec=1.0038387449588686, CurrSamplesPerSec=0.7936662680331219, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:36,732] [INFO] [logging.py:68:log_dist] [Rank 0] step=548, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:42:36,767] [INFO] [timer.py:198:stop] 0/1096, RunningAvgSamplesPerSec=1.003520640279019, CurrSamplesPerSec=0.7769786464916325, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:41,464] [INFO] [timer.py:198:stop] 0/1098, RunningAvgSamplesPerSec=1.00320069558381, CurrSamplesPerSec=0.7724909286320029, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:46,111] [INFO] [logging.py:68:log_dist] [Rank 0] step=550, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:42:46,146] [INFO] [timer.py:198:stop] 0/1100, RunningAvgSamplesPerSec=1.0028888664456819, CurrSamplesPerSec=0.7792300635414758, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:50,851] [INFO] [timer.py:198:stop] 0/1102, RunningAvgSamplesPerSec=1.0025674813810939, CurrSamplesPerSec=0.7685479609989263, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:42:55,544] [INFO] [logging.py:68:log_dist] [Rank 0] step=552, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:42:55,579] [INFO] [timer.py:198:stop] 0/1104, RunningAvgSamplesPerSec=1.0022372241849546, CurrSamplesPerSec=0.7619787448045818, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:00,264] [INFO] [timer.py:198:stop] 0/1106, RunningAvgSamplesPerSec=1.0019284925409224, CurrSamplesPerSec=0.7756355649917093, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:04,932] [INFO] [logging.py:68:log_dist] [Rank 0] step=554, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:43:04,966] [INFO] [timer.py:198:stop] 0/1108, RunningAvgSamplesPerSec=1.001612860585005, CurrSamplesPerSec=0.7712192425296769, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:09,693] [INFO] [timer.py:198:stop] 0/1110, RunningAvgSamplesPerSec=1.0012870398037426, CurrSamplesPerSec=0.7613655155463237, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:14,282] [INFO] [logging.py:68:log_dist] [Rank 0] step=556, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:43:14,316] [INFO] [timer.py:198:stop] 0/1112, RunningAvgSamplesPerSec=1.0010098052747198, CurrSamplesPerSec=0.7947865478198864, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:19,032] [INFO] [timer.py:198:stop] 0/1114, RunningAvgSamplesPerSec=1.0006919973599437, CurrSamplesPerSec=0.7689135071665648, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:23,718] [INFO] [logging.py:68:log_dist] [Rank 0] step=558, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:43:23,751] [INFO] [timer.py:198:stop] 0/1116, RunningAvgSamplesPerSec=1.000373971359496, CurrSamplesPerSec=0.7657349500354907, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:28,426] [INFO] [timer.py:198:stop] 0/1118, RunningAvgSamplesPerSec=1.000075795186674, CurrSamplesPerSec=0.7776676130940908, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:33,110] [INFO] [logging.py:68:log_dist] [Rank 0] step=560, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:43:33,144] [INFO] [timer.py:198:stop] 0/1120, RunningAvgSamplesPerSec=0.9997614144402818, CurrSamplesPerSec=0.7661274207342088, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:37,853] [INFO] [timer.py:198:stop] 0/1122, RunningAvgSamplesPerSec=0.9994515968360889, CurrSamplesPerSec=0.7653047577011649, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:42,510] [INFO] [logging.py:68:log_dist] [Rank 0] step=562, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:43:42,545] [INFO] [timer.py:198:stop] 0/1124, RunningAvgSamplesPerSec=0.9991500477742853, CurrSamplesPerSec=0.773100486101927, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:47,254] [INFO] [timer.py:198:stop] 0/1126, RunningAvgSamplesPerSec=0.9988430761573434, CurrSamplesPerSec=0.7670563484034167, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:51,927] [INFO] [logging.py:68:log_dist] [Rank 0] step=564, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:43:51,959] [INFO] [timer.py:198:stop] 0/1128, RunningAvgSamplesPerSec=0.9985395901740228, CurrSamplesPerSec=0.7709543682869198, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:43:56,675] [INFO] [timer.py:198:stop] 0/1130, RunningAvgSamplesPerSec=0.9982311491611927, CurrSamplesPerSec=0.7647294559947782, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:01,340] [INFO] [logging.py:68:log_dist] [Rank 0] step=566, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:44:01,375] [INFO] [timer.py:198:stop] 0/1132, RunningAvgSamplesPerSec=0.9979319819706662, CurrSamplesPerSec=0.768280344484833, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:06,081] [INFO] [timer.py:198:stop] 0/1134, RunningAvgSamplesPerSec=0.9976316466034441, CurrSamplesPerSec=0.7696929580767953, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:10,769] [INFO] [logging.py:68:log_dist] [Rank 0] step=568, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:44:10,803] [INFO] [timer.py:198:stop] 0/1136, RunningAvgSamplesPerSec=0.9973254208267456, CurrSamplesPerSec=0.7652549793844048, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:15,524] [INFO] [timer.py:198:stop] 0/1138, RunningAvgSamplesPerSec=0.9970202910583409, CurrSamplesPerSec=0.7635577427817939, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:20,142] [INFO] [logging.py:68:log_dist] [Rank 0] step=570, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:44:20,176] [INFO] [timer.py:198:stop] 0/1140, RunningAvgSamplesPerSec=0.9967460937791804, CurrSamplesPerSec=0.785029152903761, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:24,813] [INFO] [timer.py:198:stop] 0/1142, RunningAvgSamplesPerSec=0.9964803763278264, CurrSamplesPerSec=0.7924771144889611, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:29,520] [INFO] [logging.py:68:log_dist] [Rank 0] step=572, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:44:29,556] [INFO] [timer.py:198:stop] 0/1144, RunningAvgSamplesPerSec=0.9961697519322048, CurrSamplesPerSec=0.7619720310769041, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:34,315] [INFO] [timer.py:198:stop] 0/1146, RunningAvgSamplesPerSec=0.995853222175627, CurrSamplesPerSec=0.7498035573043745, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:38,990] [INFO] [logging.py:68:log_dist] [Rank 0] step=574, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:44:39,025] [INFO] [timer.py:198:stop] 0/1148, RunningAvgSamplesPerSec=0.9955592249532808, CurrSamplesPerSec=0.7662628366897835, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:43,741] [INFO] [timer.py:198:stop] 0/1150, RunningAvgSamplesPerSec=0.9952642424680989, CurrSamplesPerSec=0.7697495311227243, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:48,414] [INFO] [logging.py:68:log_dist] [Rank 0] step=576, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:44:48,449] [INFO] [timer.py:198:stop] 0/1152, RunningAvgSamplesPerSec=0.9949731165923407, CurrSamplesPerSec=0.7683814706348965, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:53,145] [INFO] [timer.py:198:stop] 0/1154, RunningAvgSamplesPerSec=0.994689553639454, CurrSamplesPerSec=0.7730389314110375, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:44:57,834] [INFO] [logging.py:68:log_dist] [Rank 0] step=578, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:44:57,867] [INFO] [timer.py:198:stop] 0/1156, RunningAvgSamplesPerSec=0.9943942286119196, CurrSamplesPerSec=0.7652371780521655, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:02,557] [INFO] [timer.py:198:stop] 0/1158, RunningAvgSamplesPerSec=0.9941145488431758, CurrSamplesPerSec=0.7710603811968292, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:07,291] [INFO] [logging.py:68:log_dist] [Rank 0] step=580, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:45:07,326] [INFO] [timer.py:198:stop] 0/1160, RunningAvgSamplesPerSec=0.9938026638053139, CurrSamplesPerSec=0.7537745074649987, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:12,034] [INFO] [timer.py:198:stop] 0/1162, RunningAvgSamplesPerSec=0.9935175580805707, CurrSamplesPerSec=0.7644403878132903, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:16,692] [INFO] [logging.py:68:log_dist] [Rank 0] step=582, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:45:16,725] [INFO] [timer.py:198:stop] 0/1164, RunningAvgSamplesPerSec=0.9932409936913984, CurrSamplesPerSec=0.7774431776845123, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:21,441] [INFO] [timer.py:198:stop] 0/1166, RunningAvgSamplesPerSec=0.9929549234224669, CurrSamplesPerSec=0.7652166551910732, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:26,138] [INFO] [logging.py:68:log_dist] [Rank 0] step=584, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:45:26,172] [INFO] [timer.py:198:stop] 0/1168, RunningAvgSamplesPerSec=0.9926640010342882, CurrSamplesPerSec=0.7641372683854015, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:30,880] [INFO] [timer.py:198:stop] 0/1170, RunningAvgSamplesPerSec=0.992383505873354, CurrSamplesPerSec=0.7723213747281581, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:35,586] [INFO] [logging.py:68:log_dist] [Rank 0] step=586, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:45:35,618] [INFO] [timer.py:198:stop] 0/1172, RunningAvgSamplesPerSec=0.9920917827242625, CurrSamplesPerSec=0.7594109939858973, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:40,328] [INFO] [timer.py:198:stop] 0/1174, RunningAvgSamplesPerSec=0.9918128519404688, CurrSamplesPerSec=0.767241562234988, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:45,010] [INFO] [logging.py:68:log_dist] [Rank 0] step=588, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:45:45,045] [INFO] [timer.py:198:stop] 0/1176, RunningAvgSamplesPerSec=0.9915321193983616, CurrSamplesPerSec=0.763048775640169, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:49,763] [INFO] [timer.py:198:stop] 0/1178, RunningAvgSamplesPerSec=0.991250817409642, CurrSamplesPerSec=0.7640948800791366, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:54,435] [INFO] [logging.py:68:log_dist] [Rank 0] step=590, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:45:54,462] [INFO] [timer.py:198:stop] 0/1180, RunningAvgSamplesPerSec=0.9909801189735858, CurrSamplesPerSec=0.771657105514989, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:45:59,159] [INFO] [timer.py:198:stop] 0/1182, RunningAvgSamplesPerSec=0.990711493839168, CurrSamplesPerSec=0.7693772623123999, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:03,963] [INFO] [logging.py:68:log_dist] [Rank 0] step=592, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:46:03,996] [INFO] [timer.py:198:stop] 0/1184, RunningAvgSamplesPerSec=0.990385362062299, CurrSamplesPerSec=0.7331485504060778, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:08,691] [INFO] [timer.py:198:stop] 0/1186, RunningAvgSamplesPerSec=0.9901200293001409, CurrSamplesPerSec=0.7762857990527927, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:13,353] [INFO] [logging.py:68:log_dist] [Rank 0] step=594, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:46:13,388] [INFO] [timer.py:198:stop] 0/1188, RunningAvgSamplesPerSec=0.9898541184742528, CurrSamplesPerSec=0.7727491718973302, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:18,092] [INFO] [timer.py:198:stop] 0/1190, RunningAvgSamplesPerSec=0.9895868389035457, CurrSamplesPerSec=0.773110104907898, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:22,741] [INFO] [logging.py:68:log_dist] [Rank 0] step=596, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:46:22,775] [INFO] [timer.py:198:stop] 0/1192, RunningAvgSamplesPerSec=0.9893287584697074, CurrSamplesPerSec=0.7798437822471037, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:27,461] [INFO] [timer.py:198:stop] 0/1194, RunningAvgSamplesPerSec=0.98907025713901, CurrSamplesPerSec=0.7727957295536276, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:32,016] [INFO] [logging.py:68:log_dist] [Rank 0] step=598, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:46:32,049] [INFO] [timer.py:198:stop] 0/1196, RunningAvgSamplesPerSec=0.9888530872210133, CurrSamplesPerSec=0.8067775171211402, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:36,733] [INFO] [timer.py:198:stop] 0/1198, RunningAvgSamplesPerSec=0.988597889417151, CurrSamplesPerSec=0.775501978181759, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:41,435] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:46:41,469] [INFO] [timer.py:198:stop] 0/1200, RunningAvgSamplesPerSec=0.9883224033947213, CurrSamplesPerSec=0.7561448996008262, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
Epoch: [0][1200/1563]	Time  2.083 ( 2.030)	Loss 1.2152e+00 (2.1480e+00)	Acc@1  56.25 ( 28.98)	Acc@5  96.88 ( 72.19)
[2022-11-22 06:46:46,173] [INFO] [timer.py:198:stop] 0/1202, RunningAvgSamplesPerSec=0.9880610419546835, CurrSamplesPerSec=0.7654217936689934, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:50,884] [INFO] [logging.py:68:log_dist] [Rank 0] step=602, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:46:50,917] [INFO] [timer.py:198:stop] 0/1204, RunningAvgSamplesPerSec=0.9877824476922903, CurrSamplesPerSec=0.7549303602920292, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:46:55,573] [INFO] [timer.py:198:stop] 0/1206, RunningAvgSamplesPerSec=0.9875420404199198, CurrSamplesPerSec=0.7841404231265773, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:00,253] [INFO] [logging.py:68:log_dist] [Rank 0] step=604, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:47:00,287] [INFO] [timer.py:198:stop] 0/1208, RunningAvgSamplesPerSec=0.9872798134493046, CurrSamplesPerSec=0.7646736881254456, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:04,994] [INFO] [timer.py:198:stop] 0/1210, RunningAvgSamplesPerSec=0.9870192661815824, CurrSamplesPerSec=0.7644334216541694, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:09,623] [INFO] [logging.py:68:log_dist] [Rank 0] step=606, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:47:09,658] [INFO] [timer.py:198:stop] 0/1212, RunningAvgSamplesPerSec=0.9867786809186685, CurrSamplesPerSec=0.779541945433231, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:14,330] [INFO] [timer.py:198:stop] 0/1214, RunningAvgSamplesPerSec=0.9865367054461421, CurrSamplesPerSec=0.7801179931291726, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:19,020] [INFO] [logging.py:68:log_dist] [Rank 0] step=608, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:47:19,055] [INFO] [timer.py:198:stop] 0/1216, RunningAvgSamplesPerSec=0.9862738361022951, CurrSamplesPerSec=0.7632699068164853, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:23,757] [INFO] [timer.py:198:stop] 0/1218, RunningAvgSamplesPerSec=0.9860209518221197, CurrSamplesPerSec=0.7714200217357678, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:28,452] [INFO] [logging.py:68:log_dist] [Rank 0] step=610, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:47:28,479] [INFO] [timer.py:198:stop] 0/1220, RunningAvgSamplesPerSec=0.9857606327666211, CurrSamplesPerSec=0.7632306006720819, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:33,210] [INFO] [timer.py:198:stop] 0/1222, RunningAvgSamplesPerSec=0.9854986077714853, CurrSamplesPerSec=0.7618415867606833, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:37,907] [INFO] [logging.py:68:log_dist] [Rank 0] step=612, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:47:37,942] [INFO] [timer.py:198:stop] 0/1224, RunningAvgSamplesPerSec=0.9852362153651472, CurrSamplesPerSec=0.7635761611105386, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:42,651] [INFO] [timer.py:198:stop] 0/1226, RunningAvgSamplesPerSec=0.9849843652478859, CurrSamplesPerSec=0.7712771038786598, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:47,337] [INFO] [logging.py:68:log_dist] [Rank 0] step=614, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:47:47,369] [INFO] [timer.py:198:stop] 0/1228, RunningAvgSamplesPerSec=0.9847296470232412, CurrSamplesPerSec=0.7676411989562008, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:52,114] [INFO] [timer.py:198:stop] 0/1230, RunningAvgSamplesPerSec=0.9844651230270796, CurrSamplesPerSec=0.7571947012849624, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:47:56,837] [INFO] [logging.py:68:log_dist] [Rank 0] step=616, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:47:56,871] [INFO] [timer.py:198:stop] 0/1232, RunningAvgSamplesPerSec=0.9841970165177684, CurrSamplesPerSec=0.755049341526423, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:01,558] [INFO] [timer.py:198:stop] 0/1234, RunningAvgSamplesPerSec=0.9839568556915457, CurrSamplesPerSec=0.7718184852770745, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:06,247] [INFO] [logging.py:68:log_dist] [Rank 0] step=618, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:48:06,280] [INFO] [timer.py:198:stop] 0/1236, RunningAvgSamplesPerSec=0.9837047116229821, CurrSamplesPerSec=0.7675248878532344, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:11,049] [INFO] [timer.py:198:stop] 0/1238, RunningAvgSamplesPerSec=0.9834352858419674, CurrSamplesPerSec=0.7519559027935271, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:15,766] [INFO] [logging.py:68:log_dist] [Rank 0] step=620, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:48:15,798] [INFO] [timer.py:198:stop] 0/1240, RunningAvgSamplesPerSec=0.9831744100314503, CurrSamplesPerSec=0.7578742787819346, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:20,526] [INFO] [timer.py:198:stop] 0/1242, RunningAvgSamplesPerSec=0.9829226551548564, CurrSamplesPerSec=0.7653851986253262, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:25,234] [INFO] [logging.py:68:log_dist] [Rank 0] step=622, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:48:25,269] [INFO] [timer.py:198:stop] 0/1244, RunningAvgSamplesPerSec=0.9826669488103361, CurrSamplesPerSec=0.7613860396718, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:30,019] [INFO] [timer.py:198:stop] 0/1246, RunningAvgSamplesPerSec=0.9824083113385855, CurrSamplesPerSec=0.7557198295231166, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:34,695] [INFO] [logging.py:68:log_dist] [Rank 0] step=624, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:48:34,729] [INFO] [timer.py:198:stop] 0/1248, RunningAvgSamplesPerSec=0.9821666699574365, CurrSamplesPerSec=0.7685984503436911, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:39,472] [INFO] [timer.py:198:stop] 0/1250, RunningAvgSamplesPerSec=0.9819128102684977, CurrSamplesPerSec=0.7561455130280071, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:44,159] [INFO] [logging.py:68:log_dist] [Rank 0] step=626, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:48:44,192] [INFO] [timer.py:198:stop] 0/1252, RunningAvgSamplesPerSec=0.9816691192911584, CurrSamplesPerSec=0.7658531664245019, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:48,903] [INFO] [timer.py:198:stop] 0/1254, RunningAvgSamplesPerSec=0.9814295275844441, CurrSamplesPerSec=0.7660850911998016, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:53,572] [INFO] [logging.py:68:log_dist] [Rank 0] step=628, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:48:53,607] [INFO] [timer.py:198:stop] 0/1256, RunningAvgSamplesPerSec=0.9811941099668386, CurrSamplesPerSec=0.7702885572047935, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:48:58,309] [INFO] [timer.py:198:stop] 0/1258, RunningAvgSamplesPerSec=0.9809594053162831, CurrSamplesPerSec=0.7663191866277677, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:02,944] [INFO] [logging.py:68:log_dist] [Rank 0] step=630, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:49:02,980] [INFO] [timer.py:198:stop] 0/1260, RunningAvgSamplesPerSec=0.9807382601883136, CurrSamplesPerSec=0.7824152512534013, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:07,707] [INFO] [timer.py:198:stop] 0/1262, RunningAvgSamplesPerSec=0.980496290048587, CurrSamplesPerSec=0.764712515644339, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:12,387] [INFO] [logging.py:68:log_dist] [Rank 0] step=632, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:49:12,422] [INFO] [timer.py:198:stop] 0/1264, RunningAvgSamplesPerSec=0.9802594829866983, CurrSamplesPerSec=0.7656078958863332, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:17,130] [INFO] [timer.py:198:stop] 0/1266, RunningAvgSamplesPerSec=0.980026825593327, CurrSamplesPerSec=0.7706054261645308, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:21,779] [INFO] [logging.py:68:log_dist] [Rank 0] step=634, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:49:21,814] [INFO] [timer.py:198:stop] 0/1268, RunningAvgSamplesPerSec=0.9798021323344562, CurrSamplesPerSec=0.7764046370617677, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:26,558] [INFO] [timer.py:198:stop] 0/1270, RunningAvgSamplesPerSec=0.9795571780078673, CurrSamplesPerSec=0.760089185307421, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:31,240] [INFO] [logging.py:68:log_dist] [Rank 0] step=636, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:49:31,275] [INFO] [timer.py:198:stop] 0/1272, RunningAvgSamplesPerSec=0.9793222673615012, CurrSamplesPerSec=0.7644810727184974, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:36,006] [INFO] [timer.py:198:stop] 0/1274, RunningAvgSamplesPerSec=0.9790841374742127, CurrSamplesPerSec=0.7632137266613684, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:40,677] [INFO] [logging.py:68:log_dist] [Rank 0] step=638, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:49:40,712] [INFO] [timer.py:198:stop] 0/1276, RunningAvgSamplesPerSec=0.978854907679012, CurrSamplesPerSec=0.76828407378656, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:45,411] [INFO] [timer.py:198:stop] 0/1278, RunningAvgSamplesPerSec=0.9786303263998787, CurrSamplesPerSec=0.7729159226461957, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:50,113] [INFO] [logging.py:68:log_dist] [Rank 0] step=640, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:49:50,147] [INFO] [timer.py:198:stop] 0/1280, RunningAvgSamplesPerSec=0.9783925229241743, CurrSamplesPerSec=0.7592622511544014, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:54,836] [INFO] [timer.py:198:stop] 0/1282, RunningAvgSamplesPerSec=0.978173176615371, CurrSamplesPerSec=0.7753884333149575, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:49:59,541] [INFO] [logging.py:68:log_dist] [Rank 0] step=642, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:49:59,573] [INFO] [timer.py:198:stop] 0/1284, RunningAvgSamplesPerSec=0.9779366487488034, CurrSamplesPerSec=0.7616049634014872, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:04,256] [INFO] [timer.py:198:stop] 0/1286, RunningAvgSamplesPerSec=0.9777201087767441, CurrSamplesPerSec=0.7761807863100072, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:08,907] [INFO] [logging.py:68:log_dist] [Rank 0] step=644, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:50:08,945] [INFO] [timer.py:198:stop] 0/1288, RunningAvgSamplesPerSec=0.9775028052559331, CurrSamplesPerSec=0.7751294260512392, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:13,619] [INFO] [timer.py:198:stop] 0/1290, RunningAvgSamplesPerSec=0.9772919392634727, CurrSamplesPerSec=0.7774271824190375, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:18,284] [INFO] [logging.py:68:log_dist] [Rank 0] step=646, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:50:18,318] [INFO] [timer.py:198:stop] 0/1292, RunningAvgSamplesPerSec=0.97707346723219, CurrSamplesPerSec=0.7700851851875652, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:23,013] [INFO] [timer.py:198:stop] 0/1294, RunningAvgSamplesPerSec=0.9768567592160632, CurrSamplesPerSec=0.7703768410722523, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:27,576] [INFO] [logging.py:68:log_dist] [Rank 0] step=648, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:50:27,609] [INFO] [timer.py:198:stop] 0/1296, RunningAvgSamplesPerSec=0.9766775760641122, CurrSamplesPerSec=0.8025850780894654, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:32,313] [INFO] [timer.py:198:stop] 0/1298, RunningAvgSamplesPerSec=0.9764588064424334, CurrSamplesPerSec=0.7687219906000582, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:36,960] [INFO] [logging.py:68:log_dist] [Rank 0] step=650, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:50:36,996] [INFO] [timer.py:198:stop] 0/1300, RunningAvgSamplesPerSec=0.9762484938494372, CurrSamplesPerSec=0.7743402177355551, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:41,740] [INFO] [timer.py:198:stop] 0/1302, RunningAvgSamplesPerSec=0.9760166888697458, CurrSamplesPerSec=0.7610164984728609, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:46,279] [INFO] [logging.py:68:log_dist] [Rank 0] step=652, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:50:46,312] [INFO] [timer.py:198:stop] 0/1304, RunningAvgSamplesPerSec=0.9758483401024711, CurrSamplesPerSec=0.7555050240865068, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:51,021] [INFO] [timer.py:198:stop] 0/1306, RunningAvgSamplesPerSec=0.975629587558091, CurrSamplesPerSec=0.7672996704545912, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:50:55,708] [INFO] [logging.py:68:log_dist] [Rank 0] step=654, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:50:55,742] [INFO] [timer.py:198:stop] 0/1308, RunningAvgSamplesPerSec=0.9754082069098702, CurrSamplesPerSec=0.7668937987581755, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:00,468] [INFO] [timer.py:198:stop] 0/1310, RunningAvgSamplesPerSec=0.9751852326047606, CurrSamplesPerSec=0.7668688403768684, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:05,119] [INFO] [logging.py:68:log_dist] [Rank 0] step=656, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:51:05,158] [INFO] [timer.py:198:stop] 0/1312, RunningAvgSamplesPerSec=0.9749766570595546, CurrSamplesPerSec=0.774560147189002, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:09,879] [INFO] [timer.py:198:stop] 0/1314, RunningAvgSamplesPerSec=0.9747577466650431, CurrSamplesPerSec=0.7663261871987856, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:14,536] [INFO] [logging.py:68:log_dist] [Rank 0] step=658, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:51:14,572] [INFO] [timer.py:198:stop] 0/1316, RunningAvgSamplesPerSec=0.9745496221415515, CurrSamplesPerSec=0.773610898232905, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:19,251] [INFO] [timer.py:198:stop] 0/1318, RunningAvgSamplesPerSec=0.9743478726656379, CurrSamplesPerSec=0.7812614408832942, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:23,830] [INFO] [logging.py:68:log_dist] [Rank 0] step=660, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:51:23,864] [INFO] [timer.py:198:stop] 0/1320, RunningAvgSamplesPerSec=0.9741692589257016, CurrSamplesPerSec=0.800633206480154, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:28,589] [INFO] [timer.py:198:stop] 0/1322, RunningAvgSamplesPerSec=0.9739521504500409, CurrSamplesPerSec=0.7664530597059109, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:33,291] [INFO] [logging.py:68:log_dist] [Rank 0] step=662, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:51:33,321] [INFO] [timer.py:198:stop] 0/1324, RunningAvgSamplesPerSec=0.9737328326647238, CurrSamplesPerSec=0.7634926254761244, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:38,037] [INFO] [timer.py:198:stop] 0/1326, RunningAvgSamplesPerSec=0.9735202175785651, CurrSamplesPerSec=0.765971279437262, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:42,726] [INFO] [logging.py:68:log_dist] [Rank 0] step=664, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:51:42,761] [INFO] [timer.py:198:stop] 0/1328, RunningAvgSamplesPerSec=0.9733053008742168, CurrSamplesPerSec=0.7636100809615619, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:47,435] [INFO] [timer.py:198:stop] 0/1330, RunningAvgSamplesPerSec=0.9731097227820026, CurrSamplesPerSec=0.7773500253167185, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:52,168] [INFO] [logging.py:68:log_dist] [Rank 0] step=666, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:51:52,201] [INFO] [timer.py:198:stop] 0/1332, RunningAvgSamplesPerSec=0.9728813163636318, CurrSamplesPerSec=0.751387161884609, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:51:56,906] [INFO] [timer.py:198:stop] 0/1334, RunningAvgSamplesPerSec=0.9726756904808476, CurrSamplesPerSec=0.7677349196508505, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:01,549] [INFO] [logging.py:68:log_dist] [Rank 0] step=668, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:52:01,583] [INFO] [timer.py:198:stop] 0/1336, RunningAvgSamplesPerSec=0.9724798380386581, CurrSamplesPerSec=0.7759610123577727, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:06,287] [INFO] [timer.py:198:stop] 0/1338, RunningAvgSamplesPerSec=0.9722743480389628, CurrSamplesPerSec=0.7671855677136692, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:10,897] [INFO] [logging.py:68:log_dist] [Rank 0] step=670, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:52:10,931] [INFO] [timer.py:198:stop] 0/1340, RunningAvgSamplesPerSec=0.9720910465812932, CurrSamplesPerSec=0.7868185000000469, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:15,694] [INFO] [timer.py:198:stop] 0/1342, RunningAvgSamplesPerSec=0.9718673826234702, CurrSamplesPerSec=0.7494226076229731, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:20,389] [INFO] [logging.py:68:log_dist] [Rank 0] step=672, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:52:20,427] [INFO] [timer.py:198:stop] 0/1344, RunningAvgSamplesPerSec=0.971655056342859, CurrSamplesPerSec=0.7616110483341011, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:25,162] [INFO] [timer.py:198:stop] 0/1346, RunningAvgSamplesPerSec=0.9714434983549977, CurrSamplesPerSec=0.7617048930725746, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:29,845] [INFO] [logging.py:68:log_dist] [Rank 0] step=674, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:52:29,880] [INFO] [timer.py:198:stop] 0/1348, RunningAvgSamplesPerSec=0.9712382515961018, CurrSamplesPerSec=0.7651959938307124, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:34,605] [INFO] [timer.py:198:stop] 0/1350, RunningAvgSamplesPerSec=0.971031082249637, CurrSamplesPerSec=0.7654399528140654, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:39,288] [INFO] [logging.py:68:log_dist] [Rank 0] step=676, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:52:39,325] [INFO] [timer.py:198:stop] 0/1352, RunningAvgSamplesPerSec=0.9708261907566078, CurrSamplesPerSec=0.7647508590744176, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:44,062] [INFO] [timer.py:198:stop] 0/1354, RunningAvgSamplesPerSec=0.970616099705757, CurrSamplesPerSec=0.7631937288000049, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:48,752] [INFO] [logging.py:68:log_dist] [Rank 0] step=678, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:52:48,787] [INFO] [timer.py:198:stop] 0/1356, RunningAvgSamplesPerSec=0.9704110450047083, CurrSamplesPerSec=0.764762223411442, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:53,525] [INFO] [timer.py:198:stop] 0/1358, RunningAvgSamplesPerSec=0.9702025978744989, CurrSamplesPerSec=0.7625910908943969, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:52:58,217] [INFO] [logging.py:68:log_dist] [Rank 0] step=680, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:52:58,244] [INFO] [timer.py:198:stop] 0/1360, RunningAvgSamplesPerSec=0.9700006522532149, CurrSamplesPerSec=0.7640926529090164, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:02,977] [INFO] [timer.py:198:stop] 0/1362, RunningAvgSamplesPerSec=0.9697951157406466, CurrSamplesPerSec=0.7655510217193388, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:07,655] [INFO] [logging.py:68:log_dist] [Rank 0] step=682, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:53:07,690] [INFO] [timer.py:198:stop] 0/1364, RunningAvgSamplesPerSec=0.9695951981665023, CurrSamplesPerSec=0.7678101094626744, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:12,399] [INFO] [timer.py:198:stop] 0/1366, RunningAvgSamplesPerSec=0.9693992052611201, CurrSamplesPerSec=0.7678663357672358, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:17,056] [INFO] [logging.py:68:log_dist] [Rank 0] step=684, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:53:17,091] [INFO] [timer.py:198:stop] 0/1368, RunningAvgSamplesPerSec=0.9692083833864502, CurrSamplesPerSec=0.7756669068335111, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:21,800] [INFO] [timer.py:198:stop] 0/1370, RunningAvgSamplesPerSec=0.9690136873322339, CurrSamplesPerSec=0.7655211906149232, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:26,485] [INFO] [logging.py:68:log_dist] [Rank 0] step=686, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:53:26,519] [INFO] [timer.py:198:stop] 0/1372, RunningAvgSamplesPerSec=0.9688158793742083, CurrSamplesPerSec=0.76689737438966, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:31,214] [INFO] [timer.py:198:stop] 0/1374, RunningAvgSamplesPerSec=0.9686251728303916, CurrSamplesPerSec=0.7715784635571954, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:35,860] [INFO] [logging.py:68:log_dist] [Rank 0] step=688, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:53:35,893] [INFO] [timer.py:198:stop] 0/1376, RunningAvgSamplesPerSec=0.9684426679934591, CurrSamplesPerSec=0.7791843920280389, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:40,607] [INFO] [timer.py:198:stop] 0/1378, RunningAvgSamplesPerSec=0.9682474223562232, CurrSamplesPerSec=0.7655893794128515, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:45,312] [INFO] [logging.py:68:log_dist] [Rank 0] step=690, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:53:45,345] [INFO] [timer.py:198:stop] 0/1380, RunningAvgSamplesPerSec=0.9680457213120057, CurrSamplesPerSec=0.7641951161741998, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:50,083] [INFO] [timer.py:198:stop] 0/1382, RunningAvgSamplesPerSec=0.9678447680220262, CurrSamplesPerSec=0.7592048728948932, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:54,754] [INFO] [logging.py:68:log_dist] [Rank 0] step=692, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:53:54,788] [INFO] [timer.py:198:stop] 0/1384, RunningAvgSamplesPerSec=0.9676559423186947, CurrSamplesPerSec=0.7726140867880777, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:53:59,510] [INFO] [timer.py:198:stop] 0/1386, RunningAvgSamplesPerSec=0.9674603302548838, CurrSamplesPerSec=0.7625488739492987, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:04,100] [INFO] [logging.py:68:log_dist] [Rank 0] step=694, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:54:04,135] [INFO] [timer.py:198:stop] 0/1388, RunningAvgSamplesPerSec=0.9672996427351198, CurrSamplesPerSec=0.7933862786657171, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:08,847] [INFO] [timer.py:198:stop] 0/1390, RunningAvgSamplesPerSec=0.9671100147701394, CurrSamplesPerSec=0.7679574398586797, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:13,534] [INFO] [logging.py:68:log_dist] [Rank 0] step=696, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:54:13,567] [INFO] [timer.py:198:stop] 0/1392, RunningAvgSamplesPerSec=0.9669167118175964, CurrSamplesPerSec=0.760647453761237, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:18,281] [INFO] [timer.py:198:stop] 0/1394, RunningAvgSamplesPerSec=0.9667265677067165, CurrSamplesPerSec=0.7640606387732487, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:22,893] [INFO] [logging.py:68:log_dist] [Rank 0] step=698, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:54:22,926] [INFO] [timer.py:198:stop] 0/1396, RunningAvgSamplesPerSec=0.9665611816885062, CurrSamplesPerSec=0.7838600815854355, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:27,645] [INFO] [timer.py:198:stop] 0/1398, RunningAvgSamplesPerSec=0.966371595073268, CurrSamplesPerSec=0.7628365824742722, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:32,277] [INFO] [logging.py:68:log_dist] [Rank 0] step=700, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:54:32,309] [INFO] [timer.py:198:stop] 0/1400, RunningAvgSamplesPerSec=0.966200668722039, CurrSamplesPerSec=0.7781681942259059, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:36,985] [INFO] [timer.py:198:stop] 0/1402, RunningAvgSamplesPerSec=0.9660269385647133, CurrSamplesPerSec=0.7800842593605186, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:41,625] [INFO] [logging.py:68:log_dist] [Rank 0] step=702, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:54:41,658] [INFO] [timer.py:198:stop] 0/1404, RunningAvgSamplesPerSec=0.9658543526848863, CurrSamplesPerSec=0.7744257151263424, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:46,383] [INFO] [timer.py:198:stop] 0/1406, RunningAvgSamplesPerSec=0.9656652182652982, CurrSamplesPerSec=0.7631417948052442, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:51,063] [INFO] [logging.py:68:log_dist] [Rank 0] step=704, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:54:51,099] [INFO] [timer.py:198:stop] 0/1408, RunningAvgSamplesPerSec=0.9654782924514562, CurrSamplesPerSec=0.7649660719094414, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:54:55,764] [INFO] [timer.py:198:stop] 0/1410, RunningAvgSamplesPerSec=0.9653098560338436, CurrSamplesPerSec=0.7795675182183285, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:00,419] [INFO] [logging.py:68:log_dist] [Rank 0] step=706, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:55:00,454] [INFO] [timer.py:198:stop] 0/1412, RunningAvgSamplesPerSec=0.9651342085057139, CurrSamplesPerSec=0.7750812977143319, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:05,143] [INFO] [timer.py:198:stop] 0/1414, RunningAvgSamplesPerSec=0.9649593660582447, CurrSamplesPerSec=0.7724163840218633, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:09,883] [INFO] [logging.py:68:log_dist] [Rank 0] step=708, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:55:09,917] [INFO] [timer.py:198:stop] 0/1416, RunningAvgSamplesPerSec=0.9647573190959697, CurrSamplesPerSec=0.7492408100503173, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:14,564] [INFO] [timer.py:198:stop] 0/1418, RunningAvgSamplesPerSec=0.964597310858271, CurrSamplesPerSec=0.7840662516002886, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:19,171] [INFO] [logging.py:68:log_dist] [Rank 0] step=710, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:55:19,205] [INFO] [timer.py:198:stop] 0/1420, RunningAvgSamplesPerSec=0.9644401806943237, CurrSamplesPerSec=0.7861474146359018, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:23,916] [INFO] [timer.py:198:stop] 0/1422, RunningAvgSamplesPerSec=0.9642598465510805, CurrSamplesPerSec=0.7692810238142532, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:28,575] [INFO] [logging.py:68:log_dist] [Rank 0] step=712, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:55:28,609] [INFO] [timer.py:198:stop] 0/1424, RunningAvgSamplesPerSec=0.9640865456252351, CurrSamplesPerSec=0.7776232058280063, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:33,298] [INFO] [timer.py:198:stop] 0/1426, RunningAvgSamplesPerSec=0.963914964521587, CurrSamplesPerSec=0.7778716921869157, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:37,945] [INFO] [logging.py:68:log_dist] [Rank 0] step=714, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:55:37,980] [INFO] [timer.py:198:stop] 0/1428, RunningAvgSamplesPerSec=0.9637458600481293, CurrSamplesPerSec=0.7726825486801701, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:42,686] [INFO] [timer.py:198:stop] 0/1430, RunningAvgSamplesPerSec=0.9635699041338637, CurrSamplesPerSec=0.7695738357989012, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:47,349] [INFO] [logging.py:68:log_dist] [Rank 0] step=716, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:55:47,383] [INFO] [timer.py:198:stop] 0/1432, RunningAvgSamplesPerSec=0.9633970719615024, CurrSamplesPerSec=0.7725226571342979, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:52,066] [INFO] [timer.py:198:stop] 0/1434, RunningAvgSamplesPerSec=0.9632303089692742, CurrSamplesPerSec=0.777315017901598, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:55:56,757] [INFO] [logging.py:68:log_dist] [Rank 0] step=718, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:55:56,792] [INFO] [timer.py:198:stop] 0/1436, RunningAvgSamplesPerSec=0.9630491377077479, CurrSamplesPerSec=0.7634421098816451, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:01,486] [INFO] [timer.py:198:stop] 0/1438, RunningAvgSamplesPerSec=0.9628793274791557, CurrSamplesPerSec=0.7699857304118097, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:06,191] [INFO] [logging.py:68:log_dist] [Rank 0] step=720, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:56:06,225] [INFO] [timer.py:198:stop] 0/1440, RunningAvgSamplesPerSec=0.9626949769407578, CurrSamplesPerSec=0.7598826959495608, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:10,907] [INFO] [timer.py:198:stop] 0/1442, RunningAvgSamplesPerSec=0.9625297177495186, CurrSamplesPerSec=0.7734776512694792, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:15,559] [INFO] [logging.py:68:log_dist] [Rank 0] step=722, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:56:15,585] [INFO] [timer.py:198:stop] 0/1444, RunningAvgSamplesPerSec=0.9623666358270019, CurrSamplesPerSec=0.7793625484534565, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:20,321] [INFO] [timer.py:198:stop] 0/1446, RunningAvgSamplesPerSec=0.9621856494684334, CurrSamplesPerSec=0.7635513487018611, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:24,996] [INFO] [logging.py:68:log_dist] [Rank 0] step=724, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:56:25,030] [INFO] [timer.py:198:stop] 0/1448, RunningAvgSamplesPerSec=0.9620138107749219, CurrSamplesPerSec=0.7663525104904483, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:29,727] [INFO] [timer.py:198:stop] 0/1450, RunningAvgSamplesPerSec=0.9618451749275023, CurrSamplesPerSec=0.7683911835242784, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:34,404] [INFO] [logging.py:68:log_dist] [Rank 0] step=726, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:56:34,435] [INFO] [timer.py:198:stop] 0/1452, RunningAvgSamplesPerSec=0.961674167831793, CurrSamplesPerSec=0.7687871575293661, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:39,172] [INFO] [timer.py:198:stop] 0/1454, RunningAvgSamplesPerSec=0.9614951366283833, CurrSamplesPerSec=0.7620103078314866, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:43,845] [INFO] [logging.py:68:log_dist] [Rank 0] step=728, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:56:43,878] [INFO] [timer.py:198:stop] 0/1456, RunningAvgSamplesPerSec=0.9613257583829116, CurrSamplesPerSec=0.7686499323631587, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:48,589] [INFO] [timer.py:198:stop] 0/1458, RunningAvgSamplesPerSec=0.9611560774837823, CurrSamplesPerSec=0.7720921970312317, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:53,272] [INFO] [logging.py:68:log_dist] [Rank 0] step=730, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:56:53,307] [INFO] [timer.py:198:stop] 0/1460, RunningAvgSamplesPerSec=0.9609826711692041, CurrSamplesPerSec=0.7649715828365512, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:56:58,001] [INFO] [timer.py:198:stop] 0/1462, RunningAvgSamplesPerSec=0.9608192620017835, CurrSamplesPerSec=0.7724722911305926, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:02,668] [INFO] [logging.py:68:log_dist] [Rank 0] step=732, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:57:02,703] [INFO] [timer.py:198:stop] 0/1464, RunningAvgSamplesPerSec=0.9606529878881325, CurrSamplesPerSec=0.7669001788298416, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:07,391] [INFO] [timer.py:198:stop] 0/1466, RunningAvgSamplesPerSec=0.9604915995272368, CurrSamplesPerSec=0.7711308363791468, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:12,056] [INFO] [logging.py:68:log_dist] [Rank 0] step=734, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:57:12,091] [INFO] [timer.py:198:stop] 0/1468, RunningAvgSamplesPerSec=0.9603276444032424, CurrSamplesPerSec=0.7681188934029339, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:16,799] [INFO] [timer.py:198:stop] 0/1470, RunningAvgSamplesPerSec=0.9601615617820152, CurrSamplesPerSec=0.7665719182510488, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:21,496] [INFO] [logging.py:68:log_dist] [Rank 0] step=736, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:57:21,530] [INFO] [timer.py:198:stop] 0/1472, RunningAvgSamplesPerSec=0.9599891869591276, CurrSamplesPerSec=0.7655121788649997, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:26,305] [INFO] [timer.py:198:stop] 0/1474, RunningAvgSamplesPerSec=0.959802978307466, CurrSamplesPerSec=0.7503018475961895, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:30,980] [INFO] [logging.py:68:log_dist] [Rank 0] step=738, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:57:31,007] [INFO] [timer.py:198:stop] 0/1476, RunningAvgSamplesPerSec=0.9596407046735344, CurrSamplesPerSec=0.7662710961623361, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:35,742] [INFO] [timer.py:198:stop] 0/1478, RunningAvgSamplesPerSec=0.959468578313239, CurrSamplesPerSec=0.7629287172639947, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:40,411] [INFO] [logging.py:68:log_dist] [Rank 0] step=740, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:57:40,444] [INFO] [timer.py:198:stop] 0/1480, RunningAvgSamplesPerSec=0.959306937656846, CurrSamplesPerSec=0.766996453675693, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:45,182] [INFO] [timer.py:198:stop] 0/1482, RunningAvgSamplesPerSec=0.959133755538644, CurrSamplesPerSec=0.7570998462714948, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:49,862] [INFO] [logging.py:68:log_dist] [Rank 0] step=742, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:57:49,897] [INFO] [timer.py:198:stop] 0/1484, RunningAvgSamplesPerSec=0.9589687211188728, CurrSamplesPerSec=0.7640675981397742, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:54,587] [INFO] [timer.py:198:stop] 0/1486, RunningAvgSamplesPerSec=0.9588123195859941, CurrSamplesPerSec=0.771429244061492, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:57:59,290] [INFO] [logging.py:68:log_dist] [Rank 0] step=744, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:57:59,323] [INFO] [timer.py:198:stop] 0/1488, RunningAvgSamplesPerSec=0.9586420663267996, CurrSamplesPerSec=0.7576413447827511, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:04,038] [INFO] [timer.py:198:stop] 0/1490, RunningAvgSamplesPerSec=0.9584788593586883, CurrSamplesPerSec=0.7626744986969649, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:08,687] [INFO] [logging.py:68:log_dist] [Rank 0] step=746, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:58:08,721] [INFO] [timer.py:198:stop] 0/1492, RunningAvgSamplesPerSec=0.9583266987294734, CurrSamplesPerSec=0.7736753269043987, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:13,420] [INFO] [timer.py:198:stop] 0/1494, RunningAvgSamplesPerSec=0.958169443024479, CurrSamplesPerSec=0.7692173954506858, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:18,047] [INFO] [logging.py:68:log_dist] [Rank 0] step=748, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:58:18,079] [INFO] [timer.py:198:stop] 0/1496, RunningAvgSamplesPerSec=0.9580252742294983, CurrSamplesPerSec=0.7799726322716972, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:22,815] [INFO] [timer.py:198:stop] 0/1498, RunningAvgSamplesPerSec=0.9578574270494536, CurrSamplesPerSec=0.7581777251996558, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:27,473] [INFO] [logging.py:68:log_dist] [Rank 0] step=750, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:58:27,508] [INFO] [timer.py:198:stop] 0/1500, RunningAvgSamplesPerSec=0.9577038323352364, CurrSamplesPerSec=0.7731883467540794, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:32,207] [INFO] [timer.py:198:stop] 0/1502, RunningAvgSamplesPerSec=0.9575471446422911, CurrSamplesPerSec=0.7693196856546217, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:36,899] [INFO] [logging.py:68:log_dist] [Rank 0] step=752, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:58:36,933] [INFO] [timer.py:198:stop] 0/1504, RunningAvgSamplesPerSec=0.9573843578200338, CurrSamplesPerSec=0.7646759883892167, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:41,622] [INFO] [timer.py:198:stop] 0/1506, RunningAvgSamplesPerSec=0.9572317853509357, CurrSamplesPerSec=0.7727866881019282, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:46,288] [INFO] [logging.py:68:log_dist] [Rank 0] step=754, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:58:46,322] [INFO] [timer.py:198:stop] 0/1508, RunningAvgSamplesPerSec=0.9570779266683079, CurrSamplesPerSec=0.7718222490068846, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:51,009] [INFO] [timer.py:198:stop] 0/1510, RunningAvgSamplesPerSec=0.9569278515761084, CurrSamplesPerSec=0.7726279632182799, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:58:55,687] [INFO] [logging.py:68:log_dist] [Rank 0] step=756, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:58:55,722] [INFO] [timer.py:198:stop] 0/1512, RunningAvgSamplesPerSec=0.9567710711088956, CurrSamplesPerSec=0.766684367005715, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:00,324] [INFO] [timer.py:198:stop] 0/1514, RunningAvgSamplesPerSec=0.9566475466861117, CurrSamplesPerSec=0.8031981591741408, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:05,015] [INFO] [logging.py:68:log_dist] [Rank 0] step=758, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:59:05,049] [INFO] [timer.py:198:stop] 0/1516, RunningAvgSamplesPerSec=0.9564874341430675, CurrSamplesPerSec=0.7667091732278859, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:09,754] [INFO] [timer.py:198:stop] 0/1518, RunningAvgSamplesPerSec=0.9563326120081378, CurrSamplesPerSec=0.7656131365603152, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:14,419] [INFO] [logging.py:68:log_dist] [Rank 0] step=760, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:59:14,453] [INFO] [timer.py:198:stop] 0/1520, RunningAvgSamplesPerSec=0.9561816736343863, CurrSamplesPerSec=0.7738181356614826, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:19,160] [INFO] [timer.py:198:stop] 0/1522, RunningAvgSamplesPerSec=0.9560282074850875, CurrSamplesPerSec=0.7696528463989591, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:23,740] [INFO] [logging.py:68:log_dist] [Rank 0] step=762, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:59:23,773] [INFO] [timer.py:198:stop] 0/1524, RunningAvgSamplesPerSec=0.9559038228268543, CurrSamplesPerSec=0.8021230815893584, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:28,487] [INFO] [timer.py:198:stop] 0/1526, RunningAvgSamplesPerSec=0.9557494423216745, CurrSamplesPerSec=0.7688012491289979, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:33,181] [INFO] [logging.py:68:log_dist] [Rank 0] step=764, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:59:33,206] [INFO] [timer.py:198:stop] 0/1528, RunningAvgSamplesPerSec=0.9555938236497548, CurrSamplesPerSec=0.7631006969748271, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:37,854] [INFO] [timer.py:198:stop] 0/1530, RunningAvgSamplesPerSec=0.955460144424507, CurrSamplesPerSec=0.7880031551659078, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:42,517] [INFO] [logging.py:68:log_dist] [Rank 0] step=766, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:59:42,552] [INFO] [timer.py:198:stop] 0/1532, RunningAvgSamplesPerSec=0.9553118965925954, CurrSamplesPerSec=0.7702134469631063, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:47,254] [INFO] [timer.py:198:stop] 0/1534, RunningAvgSamplesPerSec=0.9551625921738922, CurrSamplesPerSec=0.7673952734146084, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:51,944] [INFO] [logging.py:68:log_dist] [Rank 0] step=768, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 06:59:51,978] [INFO] [timer.py:198:stop] 0/1536, RunningAvgSamplesPerSec=0.9550066172897698, CurrSamplesPerSec=0.7619595037158275, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 06:59:56,680] [INFO] [timer.py:198:stop] 0/1538, RunningAvgSamplesPerSec=0.954858461078489, CurrSamplesPerSec=0.7705781020479008, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:01,371] [INFO] [logging.py:68:log_dist] [Rank 0] step=770, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:00:01,406] [INFO] [timer.py:198:stop] 0/1540, RunningAvgSamplesPerSec=0.9547023777278212, CurrSamplesPerSec=0.7620492114752223, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:06,124] [INFO] [timer.py:198:stop] 0/1542, RunningAvgSamplesPerSec=0.9545499701761921, CurrSamplesPerSec=0.7624553062515894, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:10,760] [INFO] [logging.py:68:log_dist] [Rank 0] step=772, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:00:10,794] [INFO] [timer.py:198:stop] 0/1544, RunningAvgSamplesPerSec=0.9544129745493497, CurrSamplesPerSec=0.778903170634099, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:15,496] [INFO] [timer.py:198:stop] 0/1546, RunningAvgSamplesPerSec=0.9542664217013748, CurrSamplesPerSec=0.7692502664395152, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:20,121] [INFO] [logging.py:68:log_dist] [Rank 0] step=774, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:00:20,157] [INFO] [timer.py:198:stop] 0/1548, RunningAvgSamplesPerSec=0.9541317578939897, CurrSamplesPerSec=0.7830047636804717, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:24,864] [INFO] [timer.py:198:stop] 0/1550, RunningAvgSamplesPerSec=0.9539849806588389, CurrSamplesPerSec=0.7713602947802518, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:29,534] [INFO] [logging.py:68:log_dist] [Rank 0] step=776, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:00:29,568] [INFO] [timer.py:198:stop] 0/1552, RunningAvgSamplesPerSec=0.9538389865601206, CurrSamplesPerSec=0.767809266130789, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:34,312] [INFO] [timer.py:198:stop] 0/1554, RunningAvgSamplesPerSec=0.9536822892336934, CurrSamplesPerSec=0.7641517469139407, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:38,966] [INFO] [logging.py:68:log_dist] [Rank 0] step=778, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:00:39,001] [INFO] [timer.py:198:stop] 0/1556, RunningAvgSamplesPerSec=0.9535417497140156, CurrSamplesPerSec=0.7763358014234752, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:43,659] [INFO] [timer.py:198:stop] 0/1558, RunningAvgSamplesPerSec=0.9534108045385302, CurrSamplesPerSec=0.7789995169215814, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:48,343] [INFO] [logging.py:68:log_dist] [Rank 0] step=780, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:00:48,377] [INFO] [timer.py:198:stop] 0/1560, RunningAvgSamplesPerSec=0.9532625143583938, CurrSamplesPerSec=0.7691620289991945, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:00:53,077] [INFO] [timer.py:198:stop] 0/1562, RunningAvgSamplesPerSec=0.9531199951990975, CurrSamplesPerSec=0.7690066223465671, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
val[  0/157]	Time  2.097 ( 2.097)	Loss 6.1675e-01 (6.1675e-01)	Acc@1  85.94 ( 85.94)	Acc@5  96.88 ( 96.88)
0 epoch at time 3511.7020456790924s | researved_length 197
iter 1563 | LR [0.0001]| val_acc 87.68999481201172 | layer_token 5721312
[2022-11-22 07:04:39,670] [INFO] [logging.py:68:log_dist] [Rank 0] step=782, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:04:39,708] [INFO] [timer.py:198:stop] 0/1564, RunningAvgSamplesPerSec=0.9531358695383548, CurrSamplesPerSec=0.7594519016065028, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
Epoch: [1][   0/1563]	Time  3.083 ( 3.083)	Loss 4.4420e-01 (4.4420e-01)	Acc@1  87.50 ( 87.50)	Acc@5 100.00 (100.00)
[2022-11-22 07:04:44,314] [INFO] [timer.py:198:stop] 0/1566, RunningAvgSamplesPerSec=0.953021449677739, CurrSamplesPerSec=0.8019444117282657, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:04:48,986] [INFO] [logging.py:68:log_dist] [Rank 0] step=784, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:04:49,020] [INFO] [timer.py:198:stop] 0/1568, RunningAvgSamplesPerSec=0.9528781591939866, CurrSamplesPerSec=0.7711726619432547, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:04:53,756] [INFO] [timer.py:198:stop] 0/1570, RunningAvgSamplesPerSec=0.9527268185449818, CurrSamplesPerSec=0.7621676774559909, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:04:58,480] [INFO] [logging.py:68:log_dist] [Rank 0] step=786, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:04:58,514] [INFO] [timer.py:198:stop] 0/1572, RunningAvgSamplesPerSec=0.9525679998816009, CurrSamplesPerSec=0.7535371820470652, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:03,195] [INFO] [timer.py:198:stop] 0/1574, RunningAvgSamplesPerSec=0.9524328365087453, CurrSamplesPerSec=0.7745566427822334, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:07,857] [INFO] [logging.py:68:log_dist] [Rank 0] step=788, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:05:07,895] [INFO] [timer.py:198:stop] 0/1576, RunningAvgSamplesPerSec=0.9522925536748941, CurrSamplesPerSec=0.7696181051555354, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:12,561] [INFO] [timer.py:198:stop] 0/1578, RunningAvgSamplesPerSec=0.9521626311015746, CurrSamplesPerSec=0.7795602736329597, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:17,263] [INFO] [logging.py:68:log_dist] [Rank 0] step=790, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:05:17,295] [INFO] [timer.py:198:stop] 0/1580, RunningAvgSamplesPerSec=0.9520137164517292, CurrSamplesPerSec=0.7590163759395857, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:21,967] [INFO] [timer.py:198:stop] 0/1582, RunningAvgSamplesPerSec=0.9518830262769399, CurrSamplesPerSec=0.7781860247437428, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:26,660] [INFO] [logging.py:68:log_dist] [Rank 0] step=792, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:05:26,694] [INFO] [timer.py:198:stop] 0/1584, RunningAvgSamplesPerSec=0.9517368144717119, CurrSamplesPerSec=0.7644771712384945, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:31,390] [INFO] [timer.py:198:stop] 0/1586, RunningAvgSamplesPerSec=0.9515996770725736, CurrSamplesPerSec=0.7718208997410336, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:36,084] [INFO] [logging.py:68:log_dist] [Rank 0] step=794, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:05:36,117] [INFO] [timer.py:198:stop] 0/1588, RunningAvgSamplesPerSec=0.9514541360702912, CurrSamplesPerSec=0.76558868069554, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:40,796] [INFO] [timer.py:198:stop] 0/1590, RunningAvgSamplesPerSec=0.9513220995855879, CurrSamplesPerSec=0.775169036145135, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:45,497] [INFO] [logging.py:68:log_dist] [Rank 0] step=796, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:05:45,530] [INFO] [timer.py:198:stop] 0/1592, RunningAvgSamplesPerSec=0.9511752913783413, CurrSamplesPerSec=0.7625113748034434, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:50,171] [INFO] [timer.py:198:stop] 0/1594, RunningAvgSamplesPerSec=0.9510547306773434, CurrSamplesPerSec=0.7916917276947727, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:54,843] [INFO] [logging.py:68:log_dist] [Rank 0] step=798, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:05:54,878] [INFO] [timer.py:198:stop] 0/1596, RunningAvgSamplesPerSec=0.9509155751539788, CurrSamplesPerSec=0.7687536215999345, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:05:59,641] [INFO] [timer.py:198:stop] 0/1598, RunningAvgSamplesPerSec=0.9507623490262483, CurrSamplesPerSec=0.7564986714436498, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:04,305] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:06:04,339] [INFO] [timer.py:198:stop] 0/1600, RunningAvgSamplesPerSec=0.9506271590685011, CurrSamplesPerSec=0.7716399278346352, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:09,069] [INFO] [timer.py:198:stop] 0/1602, RunningAvgSamplesPerSec=0.9504840282128479, CurrSamplesPerSec=0.7658580608524529, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:13,775] [INFO] [logging.py:68:log_dist] [Rank 0] step=802, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:06:13,810] [INFO] [timer.py:198:stop] 0/1604, RunningAvgSamplesPerSec=0.9503375383272741, CurrSamplesPerSec=0.7557749118033701, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:18,537] [INFO] [timer.py:198:stop] 0/1606, RunningAvgSamplesPerSec=0.9501956989202229, CurrSamplesPerSec=0.7656372445847504, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:23,136] [INFO] [logging.py:68:log_dist] [Rank 0] step=804, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:06:23,171] [INFO] [timer.py:198:stop] 0/1608, RunningAvgSamplesPerSec=0.9500800579050124, CurrSamplesPerSec=0.7926154906735534, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:27,911] [INFO] [timer.py:198:stop] 0/1610, RunningAvgSamplesPerSec=0.9499356679140167, CurrSamplesPerSec=0.7628102226984338, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:32,590] [INFO] [logging.py:68:log_dist] [Rank 0] step=806, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:06:32,624] [INFO] [timer.py:198:stop] 0/1612, RunningAvgSamplesPerSec=0.9497987992552407, CurrSamplesPerSec=0.7674630241468928, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:37,367] [INFO] [timer.py:198:stop] 0/1614, RunningAvgSamplesPerSec=0.9496542154557808, CurrSamplesPerSec=0.7629983881599383, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:42,080] [INFO] [logging.py:68:log_dist] [Rank 0] step=808, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:06:42,115] [INFO] [timer.py:198:stop] 0/1616, RunningAvgSamplesPerSec=0.9495078381789014, CurrSamplesPerSec=0.757756459116546, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:46,799] [INFO] [timer.py:198:stop] 0/1618, RunningAvgSamplesPerSec=0.9493800847767216, CurrSamplesPerSec=0.7738241317848379, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:51,348] [INFO] [logging.py:68:log_dist] [Rank 0] step=810, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:06:51,382] [INFO] [timer.py:198:stop] 0/1620, RunningAvgSamplesPerSec=0.9492811083544297, CurrSamplesPerSec=0.8084648656014941, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:06:56,011] [INFO] [timer.py:198:stop] 0/1622, RunningAvgSamplesPerSec=0.9491693332163035, CurrSamplesPerSec=0.7937855299260437, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:00,696] [INFO] [logging.py:68:log_dist] [Rank 0] step=812, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:07:00,731] [INFO] [timer.py:198:stop] 0/1624, RunningAvgSamplesPerSec=0.9490330866686416, CurrSamplesPerSec=0.7682113237570907, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:05,392] [INFO] [timer.py:198:stop] 0/1626, RunningAvgSamplesPerSec=0.9489130919823209, CurrSamplesPerSec=0.7839475477294411, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:10,067] [INFO] [logging.py:68:log_dist] [Rank 0] step=814, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:07:10,101] [INFO] [timer.py:198:stop] 0/1628, RunningAvgSamplesPerSec=0.9487807101558646, CurrSamplesPerSec=0.7678028709242832, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:14,810] [INFO] [timer.py:198:stop] 0/1630, RunningAvgSamplesPerSec=0.948648542448587, CurrSamplesPerSec=0.7669585158362071, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:19,490] [INFO] [logging.py:68:log_dist] [Rank 0] step=816, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:07:19,525] [INFO] [timer.py:198:stop] 0/1632, RunningAvgSamplesPerSec=0.9485149758663225, CurrSamplesPerSec=0.7670921915254162, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:24,244] [INFO] [timer.py:198:stop] 0/1634, RunningAvgSamplesPerSec=0.9483803666614128, CurrSamplesPerSec=0.7635791498288034, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:28,939] [INFO] [logging.py:68:log_dist] [Rank 0] step=818, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:07:28,972] [INFO] [timer.py:198:stop] 0/1636, RunningAvgSamplesPerSec=0.9482440682372576, CurrSamplesPerSec=0.7639339308791898, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:33,679] [INFO] [timer.py:198:stop] 0/1638, RunningAvgSamplesPerSec=0.9481135337019517, CurrSamplesPerSec=0.7679890782803198, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:38,386] [INFO] [logging.py:68:log_dist] [Rank 0] step=820, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:07:38,419] [INFO] [timer.py:198:stop] 0/1640, RunningAvgSamplesPerSec=0.9479744700636822, CurrSamplesPerSec=0.7608827922701072, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:43,104] [INFO] [timer.py:198:stop] 0/1642, RunningAvgSamplesPerSec=0.9478505711813481, CurrSamplesPerSec=0.7758408032348404, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:47,773] [INFO] [logging.py:68:log_dist] [Rank 0] step=822, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:07:47,800] [INFO] [timer.py:198:stop] 0/1644, RunningAvgSamplesPerSec=0.947724395646672, CurrSamplesPerSec=0.7703819349897304, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:07:52,543] [INFO] [timer.py:198:stop] 0/1646, RunningAvgSamplesPerSec=0.9475854968015103, CurrSamplesPerSec=0.757874141840664, MemAllocated=2.28GB, MaxMemAllocated=14.8GB
[2022-11-22 07:08:20,901] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 07:08:20,901] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 32 --data_outdir check/cifar/
[2022-11-22 07:08:22,477] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 07:08:22,478] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 07:08:22,478] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 07:08:22,478] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 07:08:22,478] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 07:08:22,478] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.15886354446411133 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 07:08:42,764] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 07:08:42,767] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 07:08:43,729] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 07:08:43,729] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 07:08:43,729] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 07:08:43,743] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 07:08:43,743] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 07:08:43,743] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 07:08:43,743] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7fbf75601310>
[2022-11-22 07:08:43,743] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:08:43,744] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 07:08:43,744] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 07:08:43,744] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 07:08:43,744] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 07:08:43,744] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 07:08:43,850] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 07:08:43,850] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 07:08:43,850] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 07:08:43,850] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 07:08:43,850] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 07:08:43,850] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbf75601af0>
[2022-11-22 07:08:43,850] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 500, 'seq_per_step': 2}}, 'global_batch_size': 32, 'micro_batch_size': 32}}}
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 1
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fbf75601bb0>
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 07:08:43,851] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   steps_per_print .............. 200
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   train_batch_size ............. 32
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  32
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 07:08:43,852] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 07:08:43,852] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": 200, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 500, 
                        "seq_per_step": 2
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.7517476081848145 seconds
Epoch: [0][   0/1563]	Time  2.553 ( 2.553)	Loss 3.3179e+00 (3.3179e+00)	Acc@1   0.00 (  0.00)	Acc@5  37.50 ( 37.50)
[2022-11-22 07:15:28,801] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:15:28,835] [INFO] [timer.py:198:stop] 0/200, RunningAvgSamplesPerSec=15.90364000818335, CurrSamplesPerSec=14.83680979533434, MemAllocated=2.28GB, MaxMemAllocated=11.13GB
[2022-11-22 07:23:06,981] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:23:07,015] [INFO] [timer.py:198:stop] 0/400, RunningAvgSamplesPerSec=14.892032107390225, CurrSamplesPerSec=12.86756793576346, MemAllocated=2.28GB, MaxMemAllocated=12.75GB
Epoch: [0][ 400/1563]	Time  2.377 ( 2.157)	Loss 2.0940e+00 (2.7090e+00)	Acc@1  31.25 ( 13.66)	Acc@5  75.00 ( 57.10)
[2022-11-22 07:31:37,271] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:31:37,304] [INFO] [timer.py:198:stop] 0/600, RunningAvgSamplesPerSec=14.027924491246822, CurrSamplesPerSec=12.366139753196345, MemAllocated=2.28GB, MaxMemAllocated=13.67GB
[2022-11-22 07:40:15,550] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:40:15,585] [INFO] [timer.py:198:stop] 0/800, RunningAvgSamplesPerSec=13.575458937493446, CurrSamplesPerSec=12.710789694142274, MemAllocated=2.28GB, MaxMemAllocated=13.67GB
Epoch: [0][ 800/1563]	Time  2.624 ( 2.364)	Loss 6.0360e-01 (2.0113e+00)	Acc@1  81.25 ( 34.86)	Acc@5 100.00 ( 74.86)
[2022-11-22 07:48:54,748] [INFO] [logging.py:68:log_dist] [Rank 0] step=1000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:48:54,782] [INFO] [timer.py:198:stop] 0/1000, RunningAvgSamplesPerSec=13.312939531336976, CurrSamplesPerSec=12.240582312104747, MemAllocated=2.28GB, MaxMemAllocated=13.67GB
[2022-11-22 07:57:32,364] [INFO] [logging.py:68:log_dist] [Rank 0] step=1200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 07:57:32,397] [INFO] [timer.py:198:stop] 0/1200, RunningAvgSamplesPerSec=13.150815129604728, CurrSamplesPerSec=12.325658180809684, MemAllocated=2.28GB, MaxMemAllocated=13.67GB
Epoch: [0][1200/1563]	Time  2.544 ( 2.440)	Loss 3.5864e-01 (1.4786e+00)	Acc@1  87.50 ( 53.15)	Acc@5 100.00 ( 83.02)
[2022-11-22 08:06:11,407] [INFO] [logging.py:68:log_dist] [Rank 0] step=1400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 08:06:11,442] [INFO] [timer.py:198:stop] 0/1400, RunningAvgSamplesPerSec=13.031970244598167, CurrSamplesPerSec=12.278318758491116, MemAllocated=2.28GB, MaxMemAllocated=13.67GB
[2022-11-22 08:08:42,663] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 08:08:42,664] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 32 --data_outdir check/cifar/
[2022-11-22 08:08:44,270] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 08:08:44,270] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 08:08:44,270] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 08:08:44,270] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 08:08:44,270] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 08:08:44,270] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.16616177558898926 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 08:09:04,371] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 08:09:04,376] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 08:09:05,119] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 08:09:05,120] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 08:09:05,120] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 08:09:05,134] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 08:09:05,134] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 08:09:05,134] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 08:09:05,134] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7f5a80f6c310>
[2022-11-22 08:09:05,134] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 08:09:05,135] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 08:09:05,136] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 08:09:05,136] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 08:09:05,136] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 08:09:05,136] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5a80f6caf0>
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 1563, 'seq_per_step': 8}}, 'global_batch_size': 32, 'micro_batch_size': 32}}}
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 1
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 08:09:05,243] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f5a80f6cbb0>
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   steps_per_print .............. 200
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   train_batch_size ............. 32
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  32
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 08:09:05,244] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 08:09:05,244] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": 200, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 1.563000e+03, 
                        "seq_per_step": 8
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.7642371654510498 seconds
Epoch: [0][   0/1563]	Time  2.770 ( 2.770)	Loss 3.3179e+00 (3.3179e+00)	Acc@1   0.00 (  0.00)	Acc@5  37.50 ( 37.50)
[2022-11-22 08:11:19,859] [INFO] [runner.py:417:main] Using IP address of 10.228.58.174 for node worker-0
[2022-11-22 08:11:19,860] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJ3b3JrZXItMCI6IFswXX0= --master_addr=10.228.58.174 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 32 --data_outdir check/cifar/
[2022-11-22 08:11:21,574] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 08:11:21,575] [INFO] [launch.py:142:main] WORLD INFO DICT: {'worker-0': [0]}
[2022-11-22 08:11:21,575] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 08:11:21,575] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'worker-0': [0]})
[2022-11-22 08:11:21,575] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 08:11:21,575] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.1492905616760254 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 08:11:40,745] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 08:11:40,748] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 08:11:41,529] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 08:11:41,530] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 08:11:41,530] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 08:11:41,545] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 08:11:41,545] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 08:11:41,545] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 08:11:41,545] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7f6985b4f310>
[2022-11-22 08:11:41,545] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 08:11:41,546] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 08:11:41,547] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 08:11:41,547] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 08:11:41,547] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 08:11:41,547] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6985b4faf0>
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 3000, 'seq_per_step': 8}}, 'global_batch_size': 32, 'micro_batch_size': 32}}}
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 1
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 08:11:41,648] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f6985b4fbb0>
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   steps_per_print .............. 200
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   train_batch_size ............. 32
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  32
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 08:11:41,649] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 08:11:41,649] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": 200, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 3.000000e+03, 
                        "seq_per_step": 8
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.8250551223754883 seconds
Epoch: [0][   0/1563]	Time  2.798 ( 2.798)	Loss 3.3179e+00 (3.3179e+00)	Acc@1   0.00 (  0.00)	Acc@5  37.50 ( 37.50)
[2022-11-22 08:18:00,993] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 08:18:01,027] [INFO] [timer.py:198:stop] 0/200, RunningAvgSamplesPerSec=17.009493726848227, CurrSamplesPerSec=16.63292331116027, MemAllocated=2.28GB, MaxMemAllocated=9.92GB
[2022-11-22 08:24:26,709] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 08:24:26,743] [INFO] [timer.py:198:stop] 0/400, RunningAvgSamplesPerSec=16.82743063322366, CurrSamplesPerSec=16.422843874868096, MemAllocated=2.28GB, MaxMemAllocated=10.07GB
Epoch: [0][ 400/1563]	Time  1.953 ( 1.911)	Loss 2.1183e+00 (2.4171e+00)	Acc@1  21.88 ( 14.20)	Acc@5  71.88 ( 58.38)
[2022-11-22 08:31:02,837] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 08:31:02,871] [INFO] [timer.py:198:stop] 0/600, RunningAvgSamplesPerSec=16.616829878679354, CurrSamplesPerSec=15.948113451918392, MemAllocated=2.28GB, MaxMemAllocated=10.42GB
[2022-11-22 09:26:50,232] [INFO] [runner.py:417:main] Using IP address of 192.168.200.181 for node master
[2022-11-22 09:26:50,232] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJtYXN0ZXIiOiBbMF19 --master_addr=192.168.200.181 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch lvits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 32 --data_outdir check/cifar/
[2022-11-22 09:26:52,015] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 09:26:52,016] [INFO] [launch.py:142:main] WORLD INFO DICT: {'master': [0]}
[2022-11-22 09:26:52,016] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 09:26:52,016] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'master': [0]})
[2022-11-22 09:26:52,016] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 09:26:52,016] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Creating extension directory /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/5] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=random_ltd -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeed-internal/deepspeed/ops/csrc/includes -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeed-internal/deepspeed/ops/csrc/random_ltd/gather_scatter.cu -o gather_scatter.cuda.o 
[2/5] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=random_ltd -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeed-internal/deepspeed/ops/csrc/includes -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeed-internal/deepspeed/ops/csrc/random_ltd/slice_attn_masks.cu -o slice_attn_masks.cuda.o 
[3/5] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=random_ltd -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeed-internal/deepspeed/ops/csrc/includes -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeed-internal/deepspeed/ops/csrc/random_ltd/token_sort.cu -o token_sort.cuda.o 
[4/5] c++ -MMD -MF pt_binding.o.d -DTORCH_EXTENSION_NAME=random_ltd -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeed-internal/deepspeed/ops/csrc/includes -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeed-internal/deepspeed/ops/csrc/random_ltd/pt_binding.cpp -o pt_binding.o 
[5/5] c++ pt_binding.o gather_scatter.cuda.o slice_attn_masks.cuda.o token_sort.cuda.o -shared -lcurand -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o random_ltd.so
Loading extension module random_ltd...
Time to load random_ltd op: 25.392021894454956 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'lvits16r224'
[2022-11-22 09:28:23,314] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 09:28:23,317] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 09:28:23,398] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 09:28:23,398] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 09:28:23,398] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 09:28:23,412] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 09:28:23,412] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 09:28:23,412] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 09:28:23,413] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7f2109766130>
[2022-11-22 09:28:23,413] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:28:23,413] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2107062670>
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 09:28:23,414] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 3000, 'seq_per_step': 8}}, 'global_batch_size': 32, 'micro_batch_size': 32}}}
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 1
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f2107062c70>
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   steps_per_print .............. 200
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   train_batch_size ............. 32
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  32
[2022-11-22 09:28:23,415] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 09:28:23,416] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 09:28:23,416] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 09:28:23,416] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 09:28:23,416] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 09:28:23,416] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 09:28:23,416] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 09:28:23,416] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": 200, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 3.000000e+03, 
                        "seq_per_step": 8
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Creating extension directory /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -c /vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeed-internal/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o 
[2/2] c++ flatten_unflatten.o -shared -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so
Loading extension module utils...
Time to load utils op: 14.049904108047485 seconds
[2022-11-22 09:28:47,232] [INFO] [runner.py:417:main] Using IP address of 192.168.200.181 for node master
[2022-11-22 09:28:47,232] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJtYXN0ZXIiOiBbMF19 --master_addr=192.168.200.181 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch vits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 32 --data_outdir check/cifar/
[2022-11-22 09:28:48,806] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 09:28:48,806] [INFO] [launch.py:142:main] WORLD INFO DICT: {'master': [0]}
[2022-11-22 09:28:48,806] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 09:28:48,806] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'master': [0]})
[2022-11-22 09:28:48,806] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 09:28:48,806] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.13967323303222656 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'vits16r224'
[2022-11-22 09:29:10,311] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 09:29:10,313] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 09:29:10,461] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 09:29:10,462] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 09:29:10,462] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 09:29:10,466] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 09:29:10,466] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 09:29:10,466] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 09:29:10,466] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7f0631787f10>
[2022-11-22 09:29:10,466] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:29:10,467] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 09:29:10,467] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 09:29:10,467] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 09:29:10,467] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 09:29:10,467] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f062c578790>
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 3000, 'seq_per_step': 8}}, 'global_batch_size': 32, 'micro_batch_size': 32}}}
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 1
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 09:29:10,468] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f062c5784c0>
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   steps_per_print .............. 200
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   train_batch_size ............. 32
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  32
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 09:29:10,469] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 09:29:10,469] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": 200, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 3.000000e+03, 
                        "seq_per_step": 8
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.9087157249450684 seconds
Epoch: [0][   0/1563]	Time  2.801 ( 2.801)	Loss 3.6376e+00 (3.6376e+00)	Acc@1   6.25 (  6.25)	Acc@5  46.88 ( 46.88)
[2022-11-22 09:29:36,307] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:29:36,308] [INFO] [timer.py:198:stop] 0/200, RunningAvgSamplesPerSec=294.1603978550765, CurrSamplesPerSec=282.39123061709694, MemAllocated=0.66GB, MaxMemAllocated=2.25GB
[2022-11-22 09:30:00,732] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:30:00,733] [INFO] [timer.py:198:stop] 0/400, RunningAvgSamplesPerSec=279.9789882798486, CurrSamplesPerSec=261.7830257496499, MemAllocated=0.66GB, MaxMemAllocated=2.37GB
Epoch: [0][ 400/1563]	Time  0.125 ( 0.123)	Loss 2.1958e+00 (2.5279e+00)	Acc@1  12.50 ( 11.85)	Acc@5  65.62 ( 52.60)
[2022-11-22 09:30:28,032] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:30:28,033] [INFO] [timer.py:198:stop] 0/600, RunningAvgSamplesPerSec=264.6140965716386, CurrSamplesPerSec=224.47626836590484, MemAllocated=0.66GB, MaxMemAllocated=2.63GB
[2022-11-22 09:30:57,892] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:30:57,893] [INFO] [timer.py:198:stop] 0/800, RunningAvgSamplesPerSec=251.06493921597414, CurrSamplesPerSec=207.0922472558501, MemAllocated=0.66GB, MaxMemAllocated=2.76GB
Epoch: [0][ 800/1563]	Time  0.155 ( 0.133)	Loss 2.2105e+00 (2.4254e+00)	Acc@1  18.75 ( 13.64)	Acc@5  62.50 ( 56.56)
[2022-11-22 09:31:29,867] [INFO] [logging.py:68:log_dist] [Rank 0] step=1000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:31:29,868] [INFO] [timer.py:198:stop] 0/1000, RunningAvgSamplesPerSec=239.72056724546135, CurrSamplesPerSec=200.87542579366743, MemAllocated=0.66GB, MaxMemAllocated=2.89GB
[2022-11-22 09:32:05,154] [INFO] [logging.py:68:log_dist] [Rank 0] step=1200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:32:05,155] [INFO] [timer.py:198:stop] 0/1200, RunningAvgSamplesPerSec=228.13231668959043, CurrSamplesPerSec=177.47188592524424, MemAllocated=0.66GB, MaxMemAllocated=3.17GB
Epoch: [0][1200/1563]	Time  0.183 ( 0.145)	Loss 2.4650e+00 (2.3587e+00)	Acc@1  12.50 ( 15.17)	Acc@5  46.88 ( 59.93)
[2022-11-22 09:32:42,313] [INFO] [logging.py:68:log_dist] [Rank 0] step=1400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:32:42,313] [INFO] [timer.py:198:stop] 0/1400, RunningAvgSamplesPerSec=218.50482014340432, CurrSamplesPerSec=172.10379745212313, MemAllocated=0.66GB, MaxMemAllocated=3.31GB
val[  0/157]	Time  1.284 ( 1.284)	Loss 3.0552e+00 (3.0552e+00)	Acc@1  15.62 ( 15.62)	Acc@5  60.94 ( 60.94)
0 epoch at time 276.16288328170776s | researved_length 112
iter 1563 | LR [0.0001]| val_acc 12.569999694824219 | layer_token 55231424
Epoch: [1][   0/1563]	Time  0.911 ( 0.911)	Loss 2.2750e+00 (2.2750e+00)	Acc@1  12.50 ( 12.50)	Acc@5  62.50 ( 62.50)
[2022-11-22 09:33:55,821] [INFO] [logging.py:68:log_dist] [Rank 0] step=1600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:33:55,821] [INFO] [timer.py:198:stop] 0/1600, RunningAvgSamplesPerSec=209.12303534362204, CurrSamplesPerSec=156.23407804386315, MemAllocated=0.66GB, MaxMemAllocated=3.45GB
[2022-11-22 09:34:38,999] [INFO] [logging.py:68:log_dist] [Rank 0] step=1800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:34:39,000] [INFO] [timer.py:198:stop] 0/1800, RunningAvgSamplesPerSec=200.31054705289336, CurrSamplesPerSec=147.20956055743596, MemAllocated=0.66GB, MaxMemAllocated=3.74GB
Epoch: [1][ 400/1563]	Time  0.231 ( 0.220)	Loss 1.8840e+00 (2.1339e+00)	Acc@1  40.62 ( 22.50)	Acc@5  81.25 ( 73.85)
[2022-11-22 09:35:24,310] [INFO] [logging.py:68:log_dist] [Rank 0] step=2000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:35:24,311] [INFO] [timer.py:198:stop] 0/2000, RunningAvgSamplesPerSec=192.53243151328428, CurrSamplesPerSec=140.20182217403203, MemAllocated=0.66GB, MaxMemAllocated=3.89GB
[2022-11-22 09:36:12,638] [INFO] [logging.py:68:log_dist] [Rank 0] step=2200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:36:12,639] [INFO] [timer.py:198:stop] 0/2200, RunningAvgSamplesPerSec=185.12537802165997, CurrSamplesPerSec=129.343047235778, MemAllocated=0.66GB, MaxMemAllocated=4.19GB
Epoch: [1][ 800/1563]	Time  0.258 ( 0.233)	Loss 2.2277e+00 (2.1022e+00)	Acc@1  12.50 ( 24.07)	Acc@5  78.12 ( 75.87)
[2022-11-22 09:37:03,211] [INFO] [logging.py:68:log_dist] [Rank 0] step=2400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:37:03,212] [INFO] [timer.py:198:stop] 0/2400, RunningAvgSamplesPerSec=178.43786698264026, CurrSamplesPerSec=125.12186863752638, MemAllocated=0.66GB, MaxMemAllocated=4.34GB
[2022-11-22 09:37:56,525] [INFO] [logging.py:68:log_dist] [Rank 0] step=2600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:37:56,526] [INFO] [timer.py:198:stop] 0/2600, RunningAvgSamplesPerSec=172.16323304228024, CurrSamplesPerSec=119.95753599367937, MemAllocated=0.66GB, MaxMemAllocated=4.5GB
Epoch: [1][1200/1563]	Time  0.285 ( 0.246)	Loss 1.9334e+00 (2.0262e+00)	Acc@1  34.38 ( 27.12)	Acc@5  81.25 ( 78.51)
[2022-11-22 09:38:53,525] [INFO] [logging.py:68:log_dist] [Rank 0] step=2800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:38:53,526] [INFO] [timer.py:198:stop] 0/2800, RunningAvgSamplesPerSec=165.98489619984517, CurrSamplesPerSec=110.44399533925362, MemAllocated=0.66GB, MaxMemAllocated=4.81GB
[2022-11-22 09:39:53,066] [INFO] [logging.py:68:log_dist] [Rank 0] step=3000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:39:53,066] [INFO] [timer.py:198:stop] 0/3000, RunningAvgSamplesPerSec=160.2955720432776, CurrSamplesPerSec=106.24677660409859, MemAllocated=0.66GB, MaxMemAllocated=4.97GB
val[  0/157]	Time  0.856 ( 0.856)	Loss 9.1048e-01 (9.1048e-01)	Acc@1  68.75 ( 68.75)	Acc@5  95.31 ( 95.31)
1 epoch at time 435.9314651489258s | researved_length 197
iter 3126 | LR [0.0001]| val_acc 69.68999481201172 | layer_token 153366848
Epoch: [2][   0/1563]	Time  0.935 ( 0.935)	Loss 9.2667e-01 (9.2667e-01)	Acc@1  65.62 ( 65.62)	Acc@5 100.00 (100.00)
[2022-11-22 09:41:26,929] [INFO] [logging.py:68:log_dist] [Rank 0] step=3200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:41:26,929] [INFO] [timer.py:198:stop] 0/3200, RunningAvgSamplesPerSec=155.23013461571858, CurrSamplesPerSec=104.764703173358, MemAllocated=0.66GB, MaxMemAllocated=4.97GB
[2022-11-22 09:42:28,513] [INFO] [logging.py:68:log_dist] [Rank 0] step=3400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:42:28,514] [INFO] [timer.py:198:stop] 0/3400, RunningAvgSamplesPerSec=150.94536096985996, CurrSamplesPerSec=104.67221569298749, MemAllocated=0.66GB, MaxMemAllocated=4.97GB
Epoch: [2][ 400/1563]	Time  0.318 ( 0.310)	Loss 3.5666e-01 (5.9610e-01)	Acc@1  93.75 ( 81.73)	Acc@5 100.00 ( 98.70)
[2022-11-22 09:43:30,123] [INFO] [logging.py:68:log_dist] [Rank 0] step=3600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:43:30,124] [INFO] [timer.py:198:stop] 0/3600, RunningAvgSamplesPerSec=147.32572768538319, CurrSamplesPerSec=104.70651177558632, MemAllocated=0.66GB, MaxMemAllocated=4.97GB
[2022-11-22 09:44:31,800] [INFO] [logging.py:68:log_dist] [Rank 0] step=3800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:44:31,801] [INFO] [timer.py:198:stop] 0/3800, RunningAvgSamplesPerSec=144.21996222179365, CurrSamplesPerSec=104.88718146289696, MemAllocated=0.66GB, MaxMemAllocated=4.97GB
[2022-11-22 09:45:00,580] [INFO] [runner.py:417:main] Using IP address of 192.168.200.181 for node master
[2022-11-22 09:45:00,581] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJtYXN0ZXIiOiBbMF19 --master_addr=192.168.200.181 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch vits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 128 --data_outdir check/cifar/
[2022-11-22 09:45:02,293] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 09:45:02,293] [INFO] [launch.py:142:main] WORLD INFO DICT: {'master': [0]}
[2022-11-22 09:45:02,293] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 09:45:02,293] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'master': [0]})
[2022-11-22 09:45:02,293] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 09:45:02,293] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.1501922607421875 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'vits16r224'
[2022-11-22 09:45:20,017] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 09:45:20,019] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 09:45:20,097] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 09:45:20,097] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 09:45:20,097] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 09:45:20,101] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 09:45:20,101] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 09:45:20,101] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 09:45:20,101] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7fedd482a310>
[2022-11-22 09:45:20,102] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:45:20,102] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fedcf4bd6d0>
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 3000, 'seq_per_step': 8}}, 'global_batch_size': 32, 'micro_batch_size': 32}}}
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 09:45:20,103] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 1
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fedcf4bd910>
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   steps_per_print .............. 200
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   train_batch_size ............. 32
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  32
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 09:45:20,104] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 09:45:20,105] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": 200, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 3.000000e+03, 
                        "seq_per_step": 8
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.8390111923217773 seconds
Epoch: [0][  0/391]	Time  4.898 ( 4.898)	Loss 3.4360e+00 (3.4360e+00)	Acc@1   7.81 (  7.81)	Acc@5  53.12 ( 53.12)
[2022-11-22 09:46:39,636] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:46:39,637] [INFO] [timer.py:198:stop] 0/200, RunningAvgSamplesPerSec=88.09629364002956, CurrSamplesPerSec=82.5640743618277, MemAllocated=0.72GB, MaxMemAllocated=7.01GB
val[ 0/40]	Time  3.316 ( 3.316)	Loss 3.6165e+00 (3.6165e+00)	Acc@1   8.59 (  8.59)	Acc@5  49.61 ( 49.61)
0 epoch at time 192.01936864852905s | researved_length 48
iter 391 | LR [0.0001]| val_acc 11.059999465942383 | layer_token 9816768
Epoch: [1][  0/391]	Time  1.438 ( 1.438)	Loss 2.2461e+00 (2.2461e+00)	Acc@1  15.62 ( 15.62)	Acc@5  60.94 ( 60.94)
[2022-11-22 09:48:37,907] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:48:37,908] [INFO] [timer.py:198:stop] 0/400, RunningAvgSamplesPerSec=82.40518455500397, CurrSamplesPerSec=74.34460097953523, MemAllocated=0.72GB, MaxMemAllocated=7.52GB
[2022-11-22 09:50:12,848] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:50:12,849] [INFO] [timer.py:198:stop] 0/600, RunningAvgSamplesPerSec=77.15445626264405, CurrSamplesPerSec=63.79011925560775, MemAllocated=0.72GB, MaxMemAllocated=8.56GB
val[ 0/40]	Time  2.045 ( 2.045)	Loss 3.5687e+00 (3.5687e+00)	Acc@1   9.38 (  9.38)	Acc@5  50.78 ( 50.78)
1 epoch at time 225.86219453811646s | researved_length 72
iter 782 | LR [0.0001]| val_acc 11.9399995803833 | layer_token 22285696
Epoch: [2][  0/391]	Time  1.569 ( 1.569)	Loss 2.0437e+00 (2.0437e+00)	Acc@1  25.78 ( 25.78)	Acc@5  72.66 ( 72.66)
[2022-11-22 09:52:29,734] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:52:29,734] [INFO] [timer.py:198:stop] 0/800, RunningAvgSamplesPerSec=72.7451063426944, CurrSamplesPerSec=59.246995112989225, MemAllocated=0.72GB, MaxMemAllocated=9.09GB
[2022-11-22 09:54:23,054] [INFO] [logging.py:68:log_dist] [Rank 0] step=1000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:54:23,055] [INFO] [timer.py:198:stop] 0/1000, RunningAvgSamplesPerSec=68.99457125337322, CurrSamplesPerSec=56.10487466898525, MemAllocated=0.72GB, MaxMemAllocated=9.62GB
val[ 0/40]	Time  2.070 ( 2.070)	Loss 3.5138e+00 (3.5138e+00)	Acc@1   9.77 (  9.77)	Acc@5  53.12 ( 53.12)
2 epoch at time 262.8514528274536s | researved_length 96
iter 1173 | LR [0.0001]| val_acc 12.679999351501465 | layer_token 37409344
Epoch: [3][  0/391]	Time  1.771 ( 1.771)	Loss 2.0590e+00 (2.0590e+00)	Acc@1  26.56 ( 26.56)	Acc@5  76.56 ( 76.56)
[2022-11-22 09:57:00,698] [INFO] [logging.py:68:log_dist] [Rank 0] step=1200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:57:00,699] [INFO] [timer.py:198:stop] 0/1200, RunningAvgSamplesPerSec=65.36205861867087, CurrSamplesPerSec=48.86376818769946, MemAllocated=0.72GB, MaxMemAllocated=10.72GB
[2022-11-22 09:59:15,246] [INFO] [logging.py:68:log_dist] [Rank 0] step=1400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 09:59:15,247] [INFO] [timer.py:198:stop] 0/1400, RunningAvgSamplesPerSec=62.169158130994376, CurrSamplesPerSec=47.363078264030165, MemAllocated=0.72GB, MaxMemAllocated=11.28GB
[2022-11-22 10:02:00,070] [INFO] [runner.py:417:main] Using IP address of 192.168.200.181 for node master
[2022-11-22 10:02:00,070] [INFO] [runner.py:508:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJtYXN0ZXIiOiBbMF19 --master_addr=192.168.200.181 --master_port=60000 main_cifar.py --deepspeed_config config/ds_config.json --deepspeed --random_ltd --dataset cifar10vit224 --seed 1234 --printfreq 400 --arch vits16r224 --optimizer sgd --lr 0.0001 --seq_len 197 --scheduler constant --epochs 14 --batchsize 128 --data_outdir check/cifar/
[2022-11-22 10:02:01,786] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.9.8
[2022-11-22 10:02:01,787] [INFO] [launch.py:142:main] WORLD INFO DICT: {'master': [0]}
[2022-11-22 10:02:01,787] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0
[2022-11-22 10:02:01,787] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'master': [0]})
[2022-11-22 10:02:01,787] [INFO] [launch.py:162:main] dist_world_size=1
[2022-11-22 10:02:01,787] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/random_ltd/build.ninja...
Building extension module random_ltd...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module random_ltd...
Time to load random_ltd op: 0.15318989753723145 seconds
Files already downloaded and verified
cifar10
Files already downloaded and verified
cifar10
=> creating model 'vits16r224'
[2022-11-22 10:02:19,811] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.6+7fe3dbf3, git-hash=7fe3dbf3, git-branch=staging_data_efficiency_v1
[2022-11-22 10:02:19,812] [INFO] [comm.py:633:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2022-11-22 10:02:19,886] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2022-11-22 10:02:19,887] [INFO] [logging.py:68:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2022-11-22 10:02:19,887] [INFO] [logging.py:68:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2022-11-22 10:02:19,891] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = SGD
[2022-11-22 10:02:19,891] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = SGD
[2022-11-22 10:02:19,891] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2022-11-22 10:02:19,891] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.StepLR object at 0x7f8a6fc1e310>
[2022-11-22 10:02:19,891] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:02:19,892] [INFO] [config.py:995:print] DeepSpeedEngine configuration:
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   amp_enabled .................. False
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   amp_params ................... False
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_results", 
    "exps_dir": "/vc_data/users/xwu/Token-Dropping/random-ltd-version1/DeepSpeedExamples-internal/random_ltd/vit_finetuning/autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   bfloat16_enabled ............. False
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   checkpoint_parallel_write_pipeline  False
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   checkpoint_tag_validation_enabled  True
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   checkpoint_tag_validation_fail  False
[2022-11-22 10:02:19,892] [INFO] [config.py:999:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8a686946d0>
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   communication_data_type ...... None
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   curriculum_enabled_legacy .... False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   curriculum_params_legacy ..... False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   data_efficiency_config ....... {'enabled': True, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': True, 'random_ltd': {'enabled': True, 'layer_token_lr_schedule': {'enabled': False}, 'total_layer_num': 12, 'random_ltd_layer_num': 10, 'random_ltd_layer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'model_mask_name': None, 'model_type': 'decoder', 'hidden_state_order': 'batch_seq_dim', 'random_ltd_schedule': {'min_value': 32, 'max_value': 197, 'schedule_type': 'fixed_linear', 'schedule_config': {'require_steps': 3910, 'seq_per_step': 8}}, 'global_batch_size': 32, 'micro_batch_size': 32}}}
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   data_efficiency_enabled ...... True
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   dataloader_drop_last ......... False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   disable_allgather ............ False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   dump_state ................... False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   dynamic_loss_scale_args ...... None
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   eigenvalue_enabled ........... False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   eigenvalue_gas_boundary_resolution  1
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   eigenvalue_layer_num ......... 0
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   eigenvalue_max_iter .......... 100
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   eigenvalue_stability ......... 1e-06
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   eigenvalue_tol ............... 0.01
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   eigenvalue_verbose ........... False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   elasticity_enabled ........... False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   fp16_auto_cast ............... None
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   fp16_enabled ................. False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   fp16_master_weights_and_gradients  False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   global_rank .................. 0
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   gradient_accumulation_steps .. 1
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   gradient_clipping ............ 1.0
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   gradient_predivide_factor .... 1.0
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   initial_dynamic_scale ........ 4294967296
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   load_universal_checkpoint .... False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   loss_scale ................... 0
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   memory_breakdown ............. False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7f8a68694910>
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   optimizer_legacy_fusion ...... False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   optimizer_name ............... adam
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   optimizer_params ............. {'lr': 0.0001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   pld_enabled .................. False
[2022-11-22 10:02:19,893] [INFO] [config.py:999:print]   pld_params ................... False
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   prescale_gradients ........... True
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   scheduler_name ............... None
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   scheduler_params ............. None
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   sparse_attention ............. None
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   sparse_gradients_enabled ..... False
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   steps_per_print .............. 200
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   train_batch_size ............. 32
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   train_micro_batch_size_per_gpu  32
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   use_node_local_storage ....... False
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   wall_clock_breakdown ......... False
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   world_size ................... 1
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   zero_allow_untested_optimizer  False
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   zero_enabled ................. False
[2022-11-22 10:02:19,894] [INFO] [config.py:999:print]   zero_optimization_stage ...... 0
[2022-11-22 10:02:19,894] [INFO] [config.py:984:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": 200, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0001, 
            "betas": [0.8, 0.999], 
            "eps": 1e-08, 
            "weight_decay": 3e-07
        }
    }, 
    "zero_optimization": {
        "stage": 0
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": true, 
    "wall_clock_breakdown": false, 
    "data_efficiency": {
        "enabled": true, 
        "data_routing": {
            "enabled": true, 
            "random_ltd": {
                "enabled": true, 
                "total_layer_num": 12, 
                "random_ltd_layer_num": 10, 
                "random_ltd_layer_id": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 
                "model_mask_name": null, 
                "model_type": "decoder", 
                "hidden_state_order": "batch_seq_dim", 
                "random_ltd_schedule": {
                    "min_value": 32, 
                    "max_value": 197, 
                    "schedule_type": "fixed_linear", 
                    "schedule_config": {
                        "require_steps": 3.910000e+03, 
                        "seq_per_step": 8
                    }
                }
            }
        }, 
        "data_sampling": {
            "curriculum_learning": {
            }
        }
    }
}
Using /home/xiaoxiawu/.cache/torch_extensions/py38_cu113 as PyTorch extensions root...
Emitting ninja build file /home/xiaoxiawu/.cache/torch_extensions/py38_cu113/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.8609664440155029 seconds
Epoch: [0][  0/391]	Time  4.268 ( 4.268)	Loss 3.4360e+00 (3.4360e+00)	Acc@1   7.81 (  7.81)	Acc@5  53.12 ( 53.12)
[2022-11-22 10:03:37,041] [INFO] [logging.py:68:log_dist] [Rank 0] step=200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:03:37,042] [INFO] [timer.py:198:stop] 0/200, RunningAvgSamplesPerSec=90.31663802675355, CurrSamplesPerSec=82.74966845933933, MemAllocated=0.72GB, MaxMemAllocated=7.0GB
val[ 0/40]	Time  2.986 ( 2.986)	Loss 3.6274e+00 (3.6274e+00)	Acc@1   8.98 (  8.98)	Acc@5  49.22 ( 49.22)
0 epoch at time 185.19143652915955s | researved_length 48
iter 391 | LR [0.0001]| val_acc 10.969999313354492 | layer_token 9476288
Epoch: [1][  0/391]	Time  1.505 ( 1.505)	Loss 2.2442e+00 (2.2442e+00)	Acc@1  14.06 ( 14.06)	Acc@5  61.72 ( 61.72)
[2022-11-22 10:05:30,951] [INFO] [logging.py:68:log_dist] [Rank 0] step=400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:05:30,952] [INFO] [timer.py:198:stop] 0/400, RunningAvgSamplesPerSec=85.55873280400775, CurrSamplesPerSec=74.4479834305781, MemAllocated=0.72GB, MaxMemAllocated=7.52GB
[2022-11-22 10:06:59,989] [INFO] [logging.py:68:log_dist] [Rank 0] step=600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:06:59,990] [INFO] [timer.py:198:stop] 0/600, RunningAvgSamplesPerSec=80.94502100126826, CurrSamplesPerSec=67.97262614675995, MemAllocated=0.72GB, MaxMemAllocated=8.03GB
val[ 0/40]	Time  2.051 ( 2.051)	Loss 3.5924e+00 (3.5924e+00)	Acc@1  10.55 ( 10.55)	Acc@5  47.27 ( 47.27)
1 epoch at time 213.16975092887878s | researved_length 64
iter 782 | LR [0.0001]| val_acc 11.920000076293945 | layer_token 21015936
Epoch: [2][  0/391]	Time  1.544 ( 1.544)	Loss 2.0863e+00 (2.0863e+00)	Acc@1  25.00 ( 25.00)	Acc@5  71.09 ( 71.09)
[2022-11-22 10:09:09,305] [INFO] [logging.py:68:log_dist] [Rank 0] step=800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:09:09,306] [INFO] [timer.py:198:stop] 0/800, RunningAvgSamplesPerSec=76.94541157286308, CurrSamplesPerSec=63.893518520722424, MemAllocated=0.72GB, MaxMemAllocated=8.55GB
[2022-11-22 10:10:53,150] [INFO] [logging.py:68:log_dist] [Rank 0] step=1000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:10:53,151] [INFO] [timer.py:198:stop] 0/1000, RunningAvgSamplesPerSec=73.54501012954583, CurrSamplesPerSec=59.176048417426145, MemAllocated=0.72GB, MaxMemAllocated=9.09GB
val[ 0/40]	Time  2.029 ( 2.029)	Loss 3.5508e+00 (3.5508e+00)	Acc@1   9.77 (  9.77)	Acc@5  51.56 ( 51.56)
2 epoch at time 241.11620593070984s | researved_length 80
iter 1173 | LR [0.0001]| val_acc 12.519999504089355 | layer_token 34618944
Epoch: [3][  0/391]	Time  1.612 ( 1.612)	Loss 2.0441e+00 (2.0441e+00)	Acc@1  21.09 ( 21.09)	Acc@5  80.47 ( 80.47)
[2022-11-22 10:13:16,878] [INFO] [logging.py:68:log_dist] [Rank 0] step=1200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:13:16,879] [INFO] [timer.py:198:stop] 0/1200, RunningAvgSamplesPerSec=70.45535337435912, CurrSamplesPerSec=56.14690977605278, MemAllocated=0.72GB, MaxMemAllocated=9.62GB
[2022-11-22 10:15:15,710] [INFO] [logging.py:68:log_dist] [Rank 0] step=1400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:15:15,711] [INFO] [timer.py:198:stop] 0/1400, RunningAvgSamplesPerSec=67.63171133558585, CurrSamplesPerSec=51.93513222362125, MemAllocated=0.72GB, MaxMemAllocated=10.17GB
val[ 0/40]	Time  2.124 ( 2.124)	Loss 3.5127e+00 (3.5127e+00)	Acc@1  10.55 ( 10.55)	Acc@5  53.91 ( 53.91)
3 epoch at time 270.82587814331055s | researved_length 96
iter 1564 | LR [0.0001]| val_acc 13.210000038146973 | layer_token 50282752
Epoch: [4][  0/391]	Time  1.637 ( 1.637)	Loss 2.0212e+00 (2.0212e+00)	Acc@1  24.22 ( 24.22)	Acc@5  78.91 ( 78.91)
[2022-11-22 10:17:55,858] [INFO] [logging.py:68:log_dist] [Rank 0] step=1600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:17:55,858] [INFO] [timer.py:198:stop] 0/1600, RunningAvgSamplesPerSec=64.91657996957399, CurrSamplesPerSec=48.94036518108643, MemAllocated=0.72GB, MaxMemAllocated=10.72GB
[2022-11-22 10:20:10,389] [INFO] [logging.py:68:log_dist] [Rank 0] step=1800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:20:10,389] [INFO] [timer.py:198:stop] 0/1800, RunningAvgSamplesPerSec=62.48671136083536, CurrSamplesPerSec=47.3198796217166, MemAllocated=0.72GB, MaxMemAllocated=11.28GB
val[ 0/40]	Time  2.029 ( 2.029)	Loss 3.3991e+00 (3.3991e+00)	Acc@1  12.89 ( 12.89)	Acc@5  57.03 ( 57.03)
4 epoch at time 299.80421257019043s | researved_length 112
iter 1955 | LR [0.0001]| val_acc 14.9399995803833 | layer_token 68009920
Epoch: [5][  0/391]	Time  1.721 ( 1.721)	Loss 1.8469e+00 (1.8469e+00)	Acc@1  33.59 ( 33.59)	Acc@5  84.38 ( 84.38)
[2022-11-22 10:23:05,069] [INFO] [logging.py:68:log_dist] [Rank 0] step=2000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:23:05,069] [INFO] [timer.py:198:stop] 0/2000, RunningAvgSamplesPerSec=60.22394920001411, CurrSamplesPerSec=43.90118370349485, MemAllocated=0.72GB, MaxMemAllocated=11.85GB
[2022-11-22 10:25:36,977] [INFO] [logging.py:68:log_dist] [Rank 0] step=2200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:25:36,977] [INFO] [timer.py:198:stop] 0/2200, RunningAvgSamplesPerSec=58.0302711211572, CurrSamplesPerSec=41.69454053839119, MemAllocated=0.72GB, MaxMemAllocated=12.42GB
val[ 0/40]	Time  2.085 ( 2.085)	Loss 3.1699e+00 (3.1699e+00)	Acc@1  15.62 ( 15.62)	Acc@5  64.06 ( 64.06)
5 epoch at time 331.90209555625916s | researved_length 128
iter 2346 | LR [0.0001]| val_acc 17.3799991607666 | layer_token 87800448
Epoch: [6][  0/391]	Time  1.752 ( 1.752)	Loss 1.8112e+00 (1.8112e+00)	Acc@1  39.06 ( 39.06)	Acc@5  82.81 ( 82.81)
[2022-11-22 10:28:46,739] [INFO] [logging.py:68:log_dist] [Rank 0] step=2400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:28:46,740] [INFO] [timer.py:198:stop] 0/2400, RunningAvgSamplesPerSec=56.094513245054095, CurrSamplesPerSec=40.58047448091367, MemAllocated=0.72GB, MaxMemAllocated=13.01GB
[2022-11-22 10:31:35,571] [INFO] [logging.py:68:log_dist] [Rank 0] step=2600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:31:35,572] [INFO] [timer.py:198:stop] 0/2600, RunningAvgSamplesPerSec=54.14851211437061, CurrSamplesPerSec=37.19453052125877, MemAllocated=0.72GB, MaxMemAllocated=13.6GB
val[ 0/40]	Time  2.104 ( 2.104)	Loss 2.7670e+00 (2.7670e+00)	Acc@1  19.14 ( 19.14)	Acc@5  74.22 ( 74.22)
6 epoch at time 365.16202425956726s | researved_length 144
iter 2737 | LR [0.0001]| val_acc 21.799999237060547 | layer_token 109651776
Epoch: [7][  0/391]	Time  1.914 ( 1.914)	Loss 1.5624e+00 (1.5624e+00)	Acc@1  36.72 ( 36.72)	Acc@5  96.09 ( 96.09)
[2022-11-22 10:35:05,442] [INFO] [logging.py:68:log_dist] [Rank 0] step=2800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:35:05,443] [INFO] [timer.py:198:stop] 0/2800, RunningAvgSamplesPerSec=52.32241990113161, CurrSamplesPerSec=35.964618919178186, MemAllocated=0.72GB, MaxMemAllocated=14.19GB
[2022-11-22 10:38:07,794] [INFO] [logging.py:68:log_dist] [Rank 0] step=3000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:38:07,795] [INFO] [timer.py:198:stop] 0/3000, RunningAvgSamplesPerSec=50.70310735297397, CurrSamplesPerSec=35.352774615530095, MemAllocated=0.72GB, MaxMemAllocated=14.8GB
val[ 0/40]	Time  2.179 ( 2.179)	Loss 2.0598e+00 (2.0598e+00)	Acc@1  35.16 ( 35.16)	Acc@5  83.59 ( 83.59)
7 epoch at time 390.96979331970215s | researved_length 160
iter 3128 | LR [0.0001]| val_acc 33.2599983215332 | layer_token 133566464
Epoch: [8][  0/391]	Time  2.013 ( 2.013)	Loss 1.6446e+00 (1.6446e+00)	Acc@1  42.19 ( 42.19)	Acc@5  86.72 ( 86.72)
[2022-11-22 10:41:48,100] [INFO] [logging.py:68:log_dist] [Rank 0] step=3200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:41:48,101] [INFO] [timer.py:198:stop] 0/3200, RunningAvgSamplesPerSec=49.237104426155284, CurrSamplesPerSec=34.13426217805304, MemAllocated=0.72GB, MaxMemAllocated=15.41GB
[2022-11-22 10:45:09,381] [INFO] [logging.py:68:log_dist] [Rank 0] step=3400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:45:09,382] [INFO] [timer.py:198:stop] 0/3400, RunningAvgSamplesPerSec=47.72817142090195, CurrSamplesPerSec=31.80557087961357, MemAllocated=0.72GB, MaxMemAllocated=16.03GB
val[ 0/40]	Time  2.216 ( 2.216)	Loss 1.0670e+00 (1.0670e+00)	Acc@1  66.80 ( 66.80)	Acc@5  96.09 ( 96.09)
8 epoch at time 424.1727337837219s | researved_length 176
iter 3519 | LR [0.0001]| val_acc 63.689998626708984 | layer_token 159544512
Epoch: [9][  0/391]	Time  2.096 ( 2.096)	Loss 8.8429e-01 (8.8429e-01)	Acc@1  66.41 ( 66.41)	Acc@5  98.44 ( 98.44)
[2022-11-22 10:49:07,673] [INFO] [logging.py:68:log_dist] [Rank 0] step=3600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:49:07,674] [INFO] [timer.py:198:stop] 0/3600, RunningAvgSamplesPerSec=46.38046720293777, CurrSamplesPerSec=31.30438254780285, MemAllocated=0.72GB, MaxMemAllocated=16.65GB
[2022-11-22 10:52:39,461] [INFO] [logging.py:68:log_dist] [Rank 0] step=3800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:52:39,462] [INFO] [timer.py:198:stop] 0/3800, RunningAvgSamplesPerSec=45.13502570171775, CurrSamplesPerSec=29.14035960359582, MemAllocated=0.72GB, MaxMemAllocated=17.93GB
val[ 0/40]	Time  2.054 ( 2.054)	Loss 3.5701e-01 (3.5701e-01)	Acc@1  89.06 ( 89.06)	Acc@5 100.00 (100.00)
9 epoch at time 448.95574712753296s | researved_length 192
iter 3910 | LR [0.0001]| val_acc 90.90999603271484 | layer_token 187585920
Epoch: [10][  0/391]	Time  2.058 ( 2.058)	Loss 3.2708e-01 (3.2708e-01)	Acc@1  91.41 ( 91.41)	Acc@5  99.22 ( 99.22)
[2022-11-22 10:56:53,186] [INFO] [logging.py:68:log_dist] [Rank 0] step=4000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 10:56:53,187] [INFO] [timer.py:198:stop] 0/4000, RunningAvgSamplesPerSec=43.924403068564054, CurrSamplesPerSec=28.096997618978836, MemAllocated=0.72GB, MaxMemAllocated=17.93GB
[2022-11-22 11:00:42,498] [INFO] [logging.py:68:log_dist] [Rank 0] step=4200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 11:00:42,499] [INFO] [timer.py:198:stop] 0/4200, RunningAvgSamplesPerSec=42.77566538448087, CurrSamplesPerSec=28.048574047963413, MemAllocated=0.72GB, MaxMemAllocated=17.93GB
val[ 0/40]	Time  2.156 ( 2.156)	Loss 1.5025e-01 (1.5025e-01)	Acc@1  96.48 ( 96.48)	Acc@5 100.00 (100.00)
10 epoch at time 477.3163368701935s | researved_length 197
iter 4301 | LR [0.0001]| val_acc 96.0999984741211 | layer_token 217049088
Epoch: [11][  0/391]	Time  2.070 ( 2.070)	Loss 7.7886e-02 (7.7886e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
[2022-11-22 11:05:03,825] [INFO] [logging.py:68:log_dist] [Rank 0] step=4400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 11:05:03,826] [INFO] [timer.py:198:stop] 0/4400, RunningAvgSamplesPerSec=41.78839027909469, CurrSamplesPerSec=28.109796352366512, MemAllocated=0.72GB, MaxMemAllocated=17.93GB
[2022-11-22 11:08:53,081] [INFO] [logging.py:68:log_dist] [Rank 0] step=4600, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 11:08:53,081] [INFO] [timer.py:198:stop] 0/4600, RunningAvgSamplesPerSec=40.92120350947847, CurrSamplesPerSec=28.093645395343852, MemAllocated=0.72GB, MaxMemAllocated=17.93GB
val[ 0/40]	Time  2.184 ( 2.184)	Loss 1.0392e-01 (1.0392e-01)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
11 epoch at time 480.4685637950897s | researved_length 197
iter 4692 | LR [0.0001]| val_acc 97.22000122070312 | layer_token 246627456
Epoch: [12][  0/391]	Time  2.175 ( 2.175)	Loss 1.4460e-01 (1.4460e-01)	Acc@1  94.53 ( 94.53)	Acc@5 100.00 (100.00)
[2022-11-22 11:13:14,678] [INFO] [logging.py:68:log_dist] [Rank 0] step=4800, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 11:13:14,679] [INFO] [timer.py:198:stop] 0/4800, RunningAvgSamplesPerSec=40.16016411440734, CurrSamplesPerSec=28.033061275895566, MemAllocated=0.72GB, MaxMemAllocated=17.93GB
[2022-11-22 11:17:04,090] [INFO] [logging.py:68:log_dist] [Rank 0] step=5000, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 11:17:04,091] [INFO] [timer.py:198:stop] 0/5000, RunningAvgSamplesPerSec=39.48047398366816, CurrSamplesPerSec=28.152112073395575, MemAllocated=0.72GB, MaxMemAllocated=17.93GB
val[ 0/40]	Time  2.093 ( 2.093)	Loss 8.0803e-02 (8.0803e-02)	Acc@1  97.27 ( 97.27)	Acc@5 100.00 (100.00)
12 epoch at time 480.5284731388092s | researved_length 197
iter 5083 | LR [0.0001]| val_acc 97.69999694824219 | layer_token 276205824
Epoch: [13][  0/391]	Time  2.094 ( 2.094)	Loss 5.6260e-02 (5.6260e-02)	Acc@1  96.88 ( 96.88)	Acc@5 100.00 (100.00)
[2022-11-22 11:21:25,587] [INFO] [logging.py:68:log_dist] [Rank 0] step=5200, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 11:21:25,588] [INFO] [timer.py:198:stop] 0/5200, RunningAvgSamplesPerSec=38.876190250499064, CurrSamplesPerSec=28.26498609786438, MemAllocated=0.72GB, MaxMemAllocated=17.93GB
[2022-11-22 11:25:15,036] [INFO] [logging.py:68:log_dist] [Rank 0] step=5400, skipped=0, lr=[0.0001], mom=[0.9]
[2022-11-22 11:25:15,037] [INFO] [timer.py:198:stop] 0/5400, RunningAvgSamplesPerSec=38.32984362432623, CurrSamplesPerSec=28.04859749414077, MemAllocated=0.72GB, MaxMemAllocated=17.93GB
val[ 0/40]	Time  2.171 ( 2.171)	Loss 7.1221e-02 (7.1221e-02)	Acc@1  98.44 ( 98.44)	Acc@5 100.00 (100.00)
13 epoch at time 480.6546013355255s | researved_length 197
iter 5474 | LR [0.0001]| val_acc 97.97000122070312 | layer_token 305784192
[2022-11-22 11:27:14,442] [INFO] [launch.py:350:main] Process 29248 exits successfully.
